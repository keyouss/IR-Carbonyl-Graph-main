{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4880b7a0",
   "metadata": {},
   "source": [
    "# 单纯的两个节点 实验可解释性 修改了网络结构 把环境特征弄成节点特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f11f0de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# from collections import OrderedDict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit.Chem import rdchem\n",
    "# import seaborn\n",
    "from tqdm import tqdm\n",
    "\n",
    "from torch_geometric.loader import DataLoader\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "# from torch.optim.lr_scheduler import StepLR\n",
    "from torch import nn\n",
    "# from torch_geometric.nn import MessagePassing\n",
    "import torch.nn.functional as F\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a20c0c4",
   "metadata": {},
   "source": [
    "## prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c228178",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit import Chem\n",
    "\n",
    "def canonicalize_smiles(smiles):\n",
    "    try:\n",
    "        mol = Chem.MolFromSmiles(smiles)  # 将 SMILES 转换为分子对象\n",
    "        if mol:\n",
    "            canon_smiles = Chem.MolToSmiles(mol, canonical=True)  # 生成规范化的 SMILES\n",
    "            return canon_smiles\n",
    "        else:\n",
    "            return None\n",
    "    except:\n",
    "        return None\n",
    "    \n",
    "excel_file = r'D:\\Jupyter\\carbonyl_group.xlsx'   # IR-DIAZO-KETONE-main\\\\\n",
    "df = pd.read_excel(excel_file)\n",
    "# 创建新列存储规范化的 SMILES\n",
    "df['Canonical_SMILES'] = df['SMILES'].apply(canonicalize_smiles)\n",
    "\n",
    "def pre_process(df):\n",
    "    # 删除规范化 SMILES 为空的行\n",
    "    df = df[df['Canonical_SMILES'].notnull()]\n",
    "    # 计算每个 'Canonical_SMILES' 组中 'IR' 值的均值\n",
    "    df['IR_Characteristic_Peak'] = df.groupby('Canonical_SMILES')['IR_Characteristic_Peak'].transform('median')\n",
    "    # 删除重复项，只保留第一个出现的行\n",
    "    df_unique = df.drop_duplicates(subset='Canonical_SMILES', keep='first')\n",
    "    # 重置索引\n",
    "    df_unique.reset_index(drop=True, inplace=True)\n",
    "    # 显示去重后的数据集信息\n",
    "    print(f\"原始数据集大小：{len(df)}\")\n",
    "    print(f\"去重后数据集大小：{len(df_unique)}\")\n",
    "    return df_unique\n",
    "df_unique = pre_process(df) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e22695",
   "metadata": {},
   "source": [
    "## construct dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd272d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 环境特征合并 16，尝试多基团 7+9\n",
    "import torch\n",
    "from torch_geometric.data import Data, Dataset\n",
    "from rdkit import Chem\n",
    "import numpy as np\n",
    "\n",
    "def extract_carbonyl_features(mol):\n",
    "    \"\"\"\n",
    "    提取羰基相关特征\n",
    "    返回：\n",
    "    - carbonyl_mask: 标记羰基氧及其周围半径1和2范围内的原子（0表示非相关，0.8表示羰基氧，1表示半径1，2表示半径2）\n",
    "    - carbonyl_env: 每个原子的周围环境特征\n",
    "    \"\"\"\n",
    "    carbonyl_mask = torch.zeros(mol.GetNumAtoms(), dtype=torch.float)\n",
    "    carbonyl_env = []\n",
    "\n",
    "    # Step 1: 识别所有羰基键（C=O 或 O=C）\n",
    "    carbonyl_bonds = []\n",
    "    for bond in mol.GetBonds():\n",
    "        if bond.GetBondType() == Chem.BondType.DOUBLE:\n",
    "            begin_atom = bond.GetBeginAtom()\n",
    "            end_atom = bond.GetEndAtom()\n",
    "            # 检查是否为C=O或O=C键\n",
    "            if (begin_atom.GetAtomicNum() == 6 and end_atom.GetAtomicNum() == 8) or \\\n",
    "               (end_atom.GetAtomicNum() == 6 and begin_atom.GetAtomicNum() == 8):\n",
    "                carbonyl_bonds.append(bond)\n",
    "\n",
    "    # Step 2: 收集所有需要标记的原子（羰基碳周围半径1和2）\n",
    "    surrounding_atoms = set()\n",
    "    for bond in carbonyl_bonds:\n",
    "        begin_atom = bond.GetBeginAtom()\n",
    "        end_atom = bond.GetEndAtom()\n",
    "        \n",
    "        # 确定羰基碳的索引\n",
    "        if begin_atom.GetAtomicNum() == 6:\n",
    "            center_idx = begin_atom.GetIdx()  # 碳在开始原子\n",
    "        else:\n",
    "            center_idx = end_atom.GetIdx()    # 碳在结束原子\n",
    "        # 使用BFS遍历半径2范围内的原子\n",
    "        queue = [(center_idx, 0)]\n",
    "        visited = set()\n",
    "        while queue:\n",
    "            current_idx, current_dist = queue.pop(0)\n",
    "            if current_idx in visited:\n",
    "                continue\n",
    "            visited.add(current_idx)\n",
    "            \n",
    "            if current_dist == 1:\n",
    "                surrounding_atoms.add((current_idx, 1))  # 半径1\n",
    "            elif current_dist == 2:\n",
    "                surrounding_atoms.add((current_idx, 2))  # 半径2\n",
    "            # 继续扩展未达半径限制的原子\n",
    "            if current_dist < 2:\n",
    "                current_atom = mol.GetAtomWithIdx(current_idx)\n",
    "                for neighbor in current_atom.GetNeighbors():\n",
    "                    neighbor_idx = neighbor.GetIdx()\n",
    "                    if neighbor_idx not in visited:\n",
    "                        queue.append((neighbor_idx, current_dist + 1))\n",
    "\n",
    "    # Step 3: 设置mask\n",
    "    for idx, dist in surrounding_atoms:\n",
    "        if dist == 1:\n",
    "            carbonyl_mask[idx] = 1.0\n",
    "        elif dist == 2:\n",
    "            carbonyl_mask[idx] = 2.0\n",
    "    # Step 4: 标记羰基氧和羰基碳\n",
    "    for i, bond in enumerate(carbonyl_bonds):\n",
    "        begin_atom = bond.GetBeginAtom()\n",
    "        end_atom = bond.GetEndAtom()\n",
    "        \n",
    "        oxygen_idx = begin_atom.GetIdx() if begin_atom.GetAtomicNum() == 8 else end_atom.GetIdx()\n",
    "        carbon_idx = end_atom.GetIdx() if begin_atom.GetAtomicNum() == 8 else begin_atom.GetIdx()\n",
    "        # 设置羰基氧的mask为0.8\n",
    "        carbonyl_mask[oxygen_idx] = 0.8 + i\n",
    "        # 设置羰基碳的mask为0.6\n",
    "        carbonyl_mask[carbon_idx] = 0.6 + i\n",
    "    \n",
    "    # Step 5: 提取每个原子的环境特征（原逻辑不变）\n",
    "    for atom in mol.GetAtoms():\n",
    "        env_feats = extract_environment_features(mol, atom.GetIdx())\n",
    "        carbonyl_env.append(env_feats)\n",
    "    \n",
    "    carbonyl_env = torch.tensor(carbonyl_env, dtype=torch.float)\n",
    "    \n",
    "    return carbonyl_mask, carbonyl_env\n",
    "\n",
    "def extract_environment_features(mol, center_idx, radius=1):\n",
    "    \"\"\"\n",
    "    提取羰基周围环境的特征\n",
    "    \"\"\"\n",
    "    env_feats = []\n",
    "    center_atom = mol.GetAtomWithIdx(center_idx)\n",
    "    center_atomic_num = center_atom.GetAtomicNum()\n",
    "\n",
    "    # 获取环信息\n",
    "    ring_info = mol.GetRingInfo()\n",
    "    # 1. 中心原子本身特征\n",
    "    ring_size = 0\n",
    "    for ring in ring_info.AtomRings():\n",
    "        if center_idx in ring:\n",
    "            ring_size = len(ring)\n",
    "            break\n",
    "    env_feats.extend([\n",
    "        # center_atom.GetDegree(),  # 连接数\n",
    "        int(center_atom.GetIsAromatic()),  # 是否芳香原子\n",
    "        center_atom.GetFormalCharge(),  # 形式电荷\n",
    "        ring_size,         # 所在环的大小（不在环中为0）\n",
    "    ])\n",
    "    # 2. 获取邻域原子\n",
    "    neighbors = Chem.FindAtomEnvironmentOfRadiusN(mol, radius, center_idx)\n",
    "    neighbor_atoms = set()\n",
    "    for bond_idx in neighbors:\n",
    "        bond = mol.GetBondWithIdx(bond_idx)\n",
    "        neighbor_atoms.add(bond.GetBeginAtomIdx())\n",
    "        neighbor_atoms.add(bond.GetEndAtomIdx())\n",
    "    \n",
    "    # 统计邻域特征\n",
    "    neighbor_feats = [0.0]*6\n",
    "    for idx in neighbor_atoms:\n",
    "        if idx == center_idx:\n",
    "            continue\n",
    "        atom = mol.GetAtomWithIdx(idx)\n",
    "        electronegativity = electronegativity_dict.get(atom.GetAtomicNum(), 0.0)\n",
    "        neighbor_feats[0] += electronegativity  # 电负性之和\n",
    "        neighbor_feats[1] += atom.GetDegree()    # 连接数和\n",
    "        neighbor_feats[2] += int(atom.GetIsAromatic())  # 芳香原子数\n",
    "        neighbor_feats[3] += int(atom.IsInRing())    # 环原子数\n",
    "        for bond in atom.GetBonds():\n",
    "            if bond.GetBondTypeAsDouble() == 2.0:  # 双键数\n",
    "                neighbor_feats[4] += 1\n",
    "            elif bond.GetBondTypeAsDouble() == 3.0:  # 三键数\n",
    "                neighbor_feats[5] += 1\n",
    "\n",
    "    env_feats.extend(neighbor_feats)\n",
    "    return env_feats\n",
    "# 定义电负性字典\n",
    "electronegativity_dict = {\n",
    "    1: 2.20, 5: 2.04, 6: 2.55, 7: 3.04, 8: 3.44, 9: 3.98, 14: 1.90, 15: 2.19, 16: 2.58, 17: 3.16, 19: 0.82, \n",
    "    26: 1.83, 32: 2.01, 34: 2.55, 35: 2.96, 50: 1.96, 52: 2.1, 53: 2.66\n",
    "}\n",
    "# 定义共价半径字典\n",
    "covalent_radius_dict = {\n",
    "    1: 3.7, 5: 8.2, 6: 7.7, 7: 7.5, 8: 7.3, 9: 7.1, 14: 11.1, 15: 10.6, 16: 10.2, 17: 9.9, 19: 22.7, \n",
    "    26: 12.6, 32: 12.2, 34: 19.8, 35: 11.4, 50: 14.0, 52: 14.0, 53: 13.3\n",
    "}\n",
    "class CarbonylIRDataset(Dataset):\n",
    "    def __init__(self, smiles_list, irc_values,doi,noise_level=0.0):\n",
    "        self.smiles_list = smiles_list\n",
    "        self.mean = np.mean(irc_values)\n",
    "        self.std = np.std(irc_values)\n",
    "        # self.irc_values = (add_noise(irc_values, noise_level) - self.mean) / self.std\n",
    "        self.irc_values = (irc_values - self.mean) / self.std\n",
    "        self.doi = doi\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.smiles_list)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        mol = Chem.MolFromSmiles(self.smiles_list[idx])\n",
    "        mol = Chem.AddHs(mol)\n",
    "        if mol is None:\n",
    "            return None\n",
    "        # 原子特征\n",
    "        atom_features = []\n",
    "        for atom in mol.GetAtoms():\n",
    "            atomic_num = atom.GetAtomicNum()\n",
    "            features = [\n",
    "              atomic_num,          # 原子序数\n",
    "              atom.GetDegree(),             # 连接数\n",
    "              atom.GetImplicitValence(),    # 隐式价\n",
    "              atom.IsInRing(),              # 是否在环中\n",
    "              atom.GetHybridization().real  # 杂化类型\n",
    "          ]\n",
    "            features.append(electronegativity_dict.get(atomic_num, 0.0))    # 电负性\n",
    "            features.append(covalent_radius_dict.get(atomic_num, 0.0))      # 共价半径\n",
    "            atom_features.append(features)\n",
    "        \n",
    "        # 边索引\n",
    "        edge_index = []\n",
    "        for bond in mol.GetBonds():\n",
    "            i = bond.GetBeginAtomIdx()\n",
    "            j = bond.GetEndAtomIdx()\n",
    "            edge_index.extend([[i, j], [j, i]])\n",
    "\n",
    "        # 边特征处理\n",
    "        edge_attr = []\n",
    "        for bond in mol.GetBonds():\n",
    "            features = [\n",
    "                bond.GetBondTypeAsDouble(),  # 键类型（单键=1.0，双键=2.0，三键=3.0）\n",
    "                int(bond.GetIsConjugated()), # 是否共轭\n",
    "                int(bond.IsInRing()),        # 是否在环中\n",
    "                int(bond.GetBondType() == Chem.rdchem.BondType.AROMATIC),  # 是否芳香键\n",
    "                bond.GetBoolProp('_IsPolar') if bond.HasProp('_IsPolar') else 0.0  # 极性\n",
    "    ]\n",
    "            # 双向边重复特征\n",
    "            edge_attr.extend([features, features.copy()])  \n",
    "        edge_attr = torch.tensor(edge_attr, dtype=torch.float)#.view(-1, 1)\n",
    "        \n",
    "        # 羰基特征\n",
    "        carbonyl_mask, carbonyl_env = extract_carbonyl_features(mol)\n",
    "        atom_features = torch.tensor(atom_features, dtype=torch.float)\n",
    "        atom_features = torch.cat([atom_features, carbonyl_env], dim=1)\n",
    "        return Data(\n",
    "            x=atom_features,\n",
    "            edge_index=torch.tensor(edge_index, dtype=torch.long).t().contiguous(),\n",
    "            edge_attr=edge_attr,\n",
    "            carbonyl_mask=carbonyl_mask,\n",
    "            doi = self.doi[idx],\n",
    "            smiles = self.smiles_list[idx],\n",
    "            y=torch.tensor([self.irc_values[idx]], dtype=torch.float))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3758013",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 环境特征分开 7+13\n",
    "import torch\n",
    "from torch_geometric.data import Data, Dataset\n",
    "from rdkit import Chem\n",
    "import numpy as np\n",
    "\n",
    "def extract_carbonyl_features(mol):\n",
    "    \"\"\"\n",
    "    提取羰基相关特征\n",
    "    返回：\n",
    "    - carbonyl_mask: 标记羰基氧及其周围半径1和2范围内的原子（0表示非相关，0.5表示羰基氧，1表示半径1，2表示半径2）\n",
    "    - carbonyl_env: 每个原子的周围环境特征\n",
    "    \"\"\"\n",
    "    carbonyl_mask = torch.zeros(mol.GetNumAtoms(), dtype=torch.float)\n",
    "    carbonyl_env = []\n",
    "\n",
    "    # Step 1: 识别所有羰基键（C=O 或 O=C）\n",
    "    carbonyl_bonds = []\n",
    "    for bond in mol.GetBonds():\n",
    "        if bond.GetBondType() == Chem.BondType.DOUBLE:\n",
    "            begin_atom = bond.GetBeginAtom()\n",
    "            end_atom = bond.GetEndAtom()\n",
    "            # 检查是否为C=O或O=C键\n",
    "            if (begin_atom.GetAtomicNum() == 6 and end_atom.GetAtomicNum() == 8) or \\\n",
    "               (end_atom.GetAtomicNum() == 6 and begin_atom.GetAtomicNum() == 8):\n",
    "                carbonyl_bonds.append(bond)\n",
    "\n",
    "    # Step 2: 收集所有需要标记的原子（羰基碳周围半径1和2）\n",
    "    surrounding_atoms = set()\n",
    "    for bond in carbonyl_bonds:\n",
    "        begin_atom = bond.GetBeginAtom()\n",
    "        end_atom = bond.GetEndAtom()\n",
    "        \n",
    "        # 确定羰基碳的索引\n",
    "        if begin_atom.GetAtomicNum() == 6:\n",
    "            center_idx = begin_atom.GetIdx()  # 碳在开始原子\n",
    "        else:\n",
    "            center_idx = end_atom.GetIdx()    # 碳在结束原子\n",
    "        # 使用BFS遍历半径2范围内的原子\n",
    "        queue = [(center_idx, 0)]\n",
    "        visited = set()\n",
    "        while queue:\n",
    "            current_idx, current_dist = queue.pop(0)\n",
    "            if current_idx in visited:\n",
    "                continue\n",
    "            visited.add(current_idx)\n",
    "            \n",
    "            if current_dist == 1:\n",
    "                surrounding_atoms.add((current_idx, 1))  # 半径1\n",
    "            elif current_dist == 2:\n",
    "                surrounding_atoms.add((current_idx, 2))  # 半径2\n",
    "            # 继续扩展未达半径限制的原子\n",
    "            if current_dist < 2:\n",
    "                current_atom = mol.GetAtomWithIdx(current_idx)\n",
    "                for neighbor in current_atom.GetNeighbors():\n",
    "                    neighbor_idx = neighbor.GetIdx()\n",
    "                    if neighbor_idx not in visited:\n",
    "                        queue.append((neighbor_idx, current_dist + 1))\n",
    "\n",
    "    # Step 3: 设置mask\n",
    "    for idx, dist in surrounding_atoms:\n",
    "        if dist == 1:\n",
    "            carbonyl_mask[idx] = 1.0\n",
    "        elif dist == 2:\n",
    "            carbonyl_mask[idx] = 2.0\n",
    "    # Step 4: 标记羰基氧和羰基碳\n",
    "    for bond in carbonyl_bonds:\n",
    "        begin_atom = bond.GetBeginAtom()\n",
    "        end_atom = bond.GetEndAtom()\n",
    "        \n",
    "        oxygen_idx = begin_atom.GetIdx() if begin_atom.GetAtomicNum() == 8 else end_atom.GetIdx()\n",
    "        carbon_idx = end_atom.GetIdx() if begin_atom.GetAtomicNum() == 8 else begin_atom.GetIdx()\n",
    "        # 设置羰基氧的mask为0.5\n",
    "        carbonyl_mask[oxygen_idx] = 0.8\n",
    "        # 设置羰基碳的mask为0\n",
    "        carbonyl_mask[carbon_idx] = 0.6\n",
    "    0\n",
    "    # Step 5: 提取每个原子的环境特征（原逻辑不变）\n",
    "    for atom in mol.GetAtoms():\n",
    "        env_feats = extract_environment_features(mol, atom.GetIdx())\n",
    "        carbonyl_env.append(env_feats)\n",
    "    000\n",
    "    carbonyl_env = torch.tensor(carbonyl_env, dtype=torch.float)\n",
    "    \n",
    "    return carbonyl_mask, carbonyl_env\n",
    "\n",
    "def extract_environment_features(mol, center_idx, radius=1):\n",
    "    \"\"\"\n",
    "    提取羰基周围环境的特征\n",
    "    \"\"\"\n",
    "    env_feats = []\n",
    "    center_atom = mol.GetAtomWithIdx(center_idx)\n",
    "    center_atomic_num = center_atom.GetAtomicNum()\n",
    "\n",
    "    # 获取环信息\n",
    "    ring_info = mol.GetRingInfo()\n",
    "    # 1. 中心原子本身特征\n",
    "    ring_size = 0\n",
    "    for ring in ring_info.AtomRings():\n",
    "        if center_idx in ring:\n",
    "            ring_size = len(ring)\n",
    "            break\n",
    "    env_feats.extend([\n",
    "        center_atom.GetDegree(),  # 连接数\n",
    "        center_atom.GetHybridization().real,  # 杂化类型\n",
    "        int(center_atom.GetIsAromatic()),  # 是否芳香原子\n",
    "        center_atom.GetFormalCharge(),  # 形式电荷\n",
    "        # int(center_atom.IsInRing()),  # 是否在环中\n",
    "        ring_size,         # 所在环的大小（不在环中为0）\n",
    "        electronegativity_dict.get(center_atomic_num, 0.0),  # 电负性\n",
    "        covalent_radius_dict.get(center_atomic_num, 0.0)   # 共价半径\n",
    "    ])\n",
    "    # 2. 获取邻域原子\n",
    "    neighbors = Chem.FindAtomEnvironmentOfRadiusN(mol, radius, center_idx)\n",
    "    neighbor_atoms = set()\n",
    "    for bond_idx in neighbors:\n",
    "        bond = mol.GetBondWithIdx(bond_idx)\n",
    "        neighbor_atoms.add(bond.GetBeginAtomIdx())\n",
    "        neighbor_atoms.add(bond.GetEndAtomIdx())\n",
    "    \n",
    "    # 统计邻域特征\n",
    "    neighbor_feats = [0.0]*6\n",
    "    for idx in neighbor_atoms:\n",
    "        if idx == center_idx:\n",
    "            continue\n",
    "        atom = mol.GetAtomWithIdx(idx)\n",
    "        electronegativity = electronegativity_dict.get(atom.GetAtomicNum(), 0.0)\n",
    "        neighbor_feats[0] += electronegativity  # 电负性之和\n",
    "        neighbor_feats[1] += atom.GetDegree()    # 连接数和\n",
    "        neighbor_feats[2] += int(atom.GetIsAromatic())  # 芳香原子数\n",
    "        neighbor_feats[3] += int(atom.IsInRing())    # 环原子数\n",
    "        for bond in atom.GetBonds():\n",
    "            if bond.GetBondTypeAsDouble() == 2.0:  # 双键数\n",
    "                neighbor_feats[4] += 1\n",
    "            elif bond.GetBondTypeAsDouble() == 3.0:  # 三键数\n",
    "                neighbor_feats[5] += 1\n",
    "\n",
    "    env_feats.extend(neighbor_feats)\n",
    "    return env_feats\n",
    "# 定义电负性字典\n",
    "electronegativity_dict = {\n",
    "    1: 2.20, 5: 2.04, 6: 2.55, 7: 3.04, 8: 3.44, 9: 3.98, 14: 1.90, 15: 2.19, 16: 2.58, 17: 3.16, 19: 0.82, \n",
    "    26: 1.83, 32: 2.01, 34: 2.55, 35: 2.96, 50: 1.96, 52: 2.1, 53: 2.66\n",
    "}\n",
    "# 定义共价半径字典\n",
    "covalent_radius_dict = {\n",
    "    1: 3.7, 5: 8.2, 6: 7.7, 7: 7.5, 8: 7.3, 9: 7.1, 14: 11.1, 15: 10.6, 16: 10.2, 17: 9.9, 19: 22.7, \n",
    "    26: 12.6, 32: 12.2, 34: 19.8, 35: 11.4, 50: 14.0, 52: 14.0, 53: 13.3\n",
    "}\n",
    "class CarbonylIRDataset(Dataset):\n",
    "    def __init__(self, smiles_list, irc_values,doi):\n",
    "        self.smiles_list = smiles_list\n",
    "        self.mean = np.mean(irc_values)\n",
    "        self.std = np.std(irc_values)\n",
    "        self.irc_values = (irc_values - self.mean) / self.std\n",
    "        self.doi = doi\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.smiles_list)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        mol = Chem.MolFromSmiles(self.smiles_list[idx])\n",
    "        mol = Chem.AddHs(mol)\n",
    "        if mol is None:\n",
    "            return None\n",
    "        # 原子特征\n",
    "        atom_features = []\n",
    "        for atom in mol.GetAtoms():\n",
    "            atomic_num = atom.GetAtomicNum()\n",
    "            features = [\n",
    "              atomic_num,          # 原子序数\n",
    "              atom.GetDegree(),             # 连接数\n",
    "              atom.GetImplicitValence(),    # 隐式价\n",
    "              atom.IsInRing(),              # 是否在环中\n",
    "              atom.GetHybridization().real  # 杂化类型\n",
    "          ]\n",
    "            features.append(electronegativity_dict.get(atomic_num, 0.0))    # 添加电负性\n",
    "            features.append(covalent_radius_dict.get(atomic_num, 0.0))      # 添加共价半径\n",
    "            atom_features.append(features)\n",
    "        \n",
    "        # 边索引\n",
    "        edge_index = []\n",
    "        for bond in mol.GetBonds():\n",
    "            i = bond.GetBeginAtomIdx()\n",
    "            j = bond.GetEndAtomIdx()\n",
    "            edge_index.extend([[i, j], [j, i]])\n",
    "\n",
    "        # 边特征处理\n",
    "        edge_attr = []\n",
    "        for bond in mol.GetBonds():\n",
    "            features = [\n",
    "                bond.GetBondTypeAsDouble(),  # 键类型（单键=1.0，双键=2.0，三键=3.0）\n",
    "                int(bond.GetIsConjugated()), # 是否共轭\n",
    "                int(bond.IsInRing()),        # 是否在环中\n",
    "                int(bond.GetBondType() == Chem.rdchem.BondType.AROMATIC),  # 是否芳香键\n",
    "                bond.GetBoolProp('_IsPolar') if bond.HasProp('_IsPolar') else 0.0  # 极性\n",
    "    ]\n",
    "            # 双向边重复特征\n",
    "            edge_attr.extend([features, features.copy()])  \n",
    "        edge_attr = torch.tensor(edge_attr, dtype=torch.float)#.view(-1, 1)\n",
    "        \n",
    "        # 羰基特征\n",
    "        carbonyl_mask, carbonyl_env = extract_carbonyl_features(mol)\n",
    "        \n",
    "        return Data(\n",
    "            x=torch.tensor(atom_features, dtype=torch.float),\n",
    "            edge_index=torch.tensor(edge_index, dtype=torch.long).t().contiguous(),\n",
    "            edge_attr=edge_attr,\n",
    "            carbonyl_mask=carbonyl_mask,\n",
    "            carbonyl_env=carbonyl_env,\n",
    "            doi = self.doi[idx],\n",
    "            smiles = self.smiles_list[idx],\n",
    "            y=torch.tensor([self.irc_values[idx]], dtype=torch.float))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb3f1c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 无环境特征分开 7\n",
    "import torch\n",
    "from torch_geometric.data import Data, Dataset\n",
    "from rdkit import Chem\n",
    "import numpy as np\n",
    "\n",
    "def extract_carbonyl_features(mol):\n",
    "    \"\"\"\n",
    "    提取羰基相关特征\n",
    "    返回：\n",
    "    - carbonyl_mask: 标记羰基氧及其周围半径1和2范围内的原子（0表示非相关，0.5表示羰基氧，1表示半径1，2表示半径2）\n",
    "    - carbonyl_env: 每个原子的周围环境特征\n",
    "    \"\"\"\n",
    "    carbonyl_mask = torch.zeros(mol.GetNumAtoms(), dtype=torch.float)\n",
    "    carbonyl_env = []\n",
    "\n",
    "    # Step 1: 识别所有羰基键（C=O 或 O=C）\n",
    "    carbonyl_bonds = []\n",
    "    for bond in mol.GetBonds():\n",
    "        if bond.GetBondType() == Chem.BondType.DOUBLE:\n",
    "            begin_atom = bond.GetBeginAtom()\n",
    "            end_atom = bond.GetEndAtom()\n",
    "            # 检查是否为C=O或O=C键\n",
    "            if (begin_atom.GetAtomicNum() == 6 and end_atom.GetAtomicNum() == 8) or \\\n",
    "               (end_atom.GetAtomicNum() == 6 and begin_atom.GetAtomicNum() == 8):\n",
    "                carbonyl_bonds.append(bond)\n",
    "\n",
    "    # Step 2: 收集所有需要标记的原子（羰基碳周围半径1和2）\n",
    "    surrounding_atoms = set()\n",
    "    for bond in carbonyl_bonds:\n",
    "        begin_atom = bond.GetBeginAtom()\n",
    "        end_atom = bond.GetEndAtom()\n",
    "        \n",
    "        # 确定羰基碳的索引\n",
    "        if begin_atom.GetAtomicNum() == 6:\n",
    "            center_idx = begin_atom.GetIdx()  # 碳在开始原子\n",
    "        else:\n",
    "            center_idx = end_atom.GetIdx()    # 碳在结束原子\n",
    "        # 使用BFS遍历半径2范围内的原子\n",
    "        queue = [(center_idx, 0)]\n",
    "        visited = set()\n",
    "        while queue:\n",
    "            current_idx, current_dist = queue.pop(0)\n",
    "            if current_idx in visited:\n",
    "                continue\n",
    "            visited.add(current_idx)\n",
    "            \n",
    "            if current_dist == 1:\n",
    "                surrounding_atoms.add((current_idx, 1))  # 半径1\n",
    "            elif current_dist == 2:\n",
    "                surrounding_atoms.add((current_idx, 2))  # 半径2\n",
    "            # 继续扩展未达半径限制的原子\n",
    "            if current_dist < 2:\n",
    "                current_atom = mol.GetAtomWithIdx(current_idx)\n",
    "                for neighbor in current_atom.GetNeighbors():\n",
    "                    neighbor_idx = neighbor.GetIdx()\n",
    "                    if neighbor_idx not in visited:\n",
    "                        queue.append((neighbor_idx, current_dist + 1))\n",
    "\n",
    "    # Step 3: 设置mask\n",
    "    for idx, dist in surrounding_atoms:\n",
    "        if dist == 1:\n",
    "            carbonyl_mask[idx] = 1.0\n",
    "        elif dist == 2:\n",
    "            carbonyl_mask[idx] = 2.0\n",
    "    # Step 4: 标记羰基氧和羰基碳\n",
    "    for bond in carbonyl_bonds:\n",
    "        begin_atom = bond.GetBeginAtom()\n",
    "        end_atom = bond.GetEndAtom()\n",
    "        \n",
    "        oxygen_idx = begin_atom.GetIdx() if begin_atom.GetAtomicNum() == 8 else end_atom.GetIdx()\n",
    "        carbon_idx = end_atom.GetIdx() if begin_atom.GetAtomicNum() == 8 else begin_atom.GetIdx()\n",
    "        # 设置羰基氧的mask为0.5\n",
    "        carbonyl_mask[oxygen_idx] = 0.8\n",
    "        # 设置羰基碳的mask为0\n",
    "        carbonyl_mask[carbon_idx] = 0.6\n",
    "    \n",
    "    # Step 5: 提取每个原子的环境特征（原逻辑不变）\n",
    "    for atom in mol.GetAtoms():\n",
    "        env_feats = extract_environment_features(mol, atom.GetIdx())\n",
    "        carbonyl_env.append(env_feats)\n",
    "    \n",
    "    carbonyl_env = torch.tensor(carbonyl_env, dtype=torch.float)\n",
    "    \n",
    "    return carbonyl_mask, carbonyl_env\n",
    "\n",
    "def extract_environment_features(mol, center_idx, radius=1):\n",
    "    \"\"\"\n",
    "    提取羰基周围环境的特征\n",
    "    \"\"\"\n",
    "    env_feats = []\n",
    "    center_atom = mol.GetAtomWithIdx(center_idx)\n",
    "    center_atomic_num = center_atom.GetAtomicNum()\n",
    "\n",
    "    # 获取环信息\n",
    "    ring_info = mol.GetRingInfo()\n",
    "    # 1. 中心原子本身特征\n",
    "    ring_size = 0\n",
    "    for ring in ring_info.AtomRings():\n",
    "        if center_idx in ring:\n",
    "            ring_size = len(ring)\n",
    "            break\n",
    "    env_feats.extend([\n",
    "        center_atom.GetDegree(),  # 连接数\n",
    "        center_atom.GetHybridization().real,  # 杂化类型\n",
    "        int(center_atom.GetIsAromatic()),  # 是否芳香原子\n",
    "        center_atom.GetFormalCharge(),  # 形式电荷\n",
    "        # int(center_atom.IsInRing()),  # 是否在环中\n",
    "        ring_size,         # 所在环的大小（不在环中为0）\n",
    "        electronegativity_dict.get(center_atomic_num, 0.0),  # 电负性\n",
    "        covalent_radius_dict.get(center_atomic_num, 0.0)   # 共价半径\n",
    "    ])\n",
    "    # 2. 获取邻域原子\n",
    "    neighbors = Chem.FindAtomEnvironmentOfRadiusN(mol, radius, center_idx)\n",
    "    neighbor_atoms = set()\n",
    "    for bond_idx in neighbors:\n",
    "        bond = mol.GetBondWithIdx(bond_idx)\n",
    "        neighbor_atoms.add(bond.GetBeginAtomIdx())\n",
    "        neighbor_atoms.add(bond.GetEndAtomIdx())\n",
    "    \n",
    "    # 统计邻域特征\n",
    "    neighbor_feats = [0.0]*6\n",
    "    for idx in neighbor_atoms:\n",
    "        if idx == center_idx:\n",
    "            continue\n",
    "        atom = mol.GetAtomWithIdx(idx)\n",
    "        electronegativity = electronegativity_dict.get(atom.GetAtomicNum(), 0.0)\n",
    "        neighbor_feats[0] += electronegativity  # 电负性之和\n",
    "        neighbor_feats[1] += atom.GetDegree()    # 连接数和\n",
    "        neighbor_feats[2] += int(atom.GetIsAromatic())  # 芳香原子数\n",
    "        neighbor_feats[3] += int(atom.IsInRing())    # 环原子数\n",
    "        for bond in atom.GetBonds():\n",
    "            if bond.GetBondTypeAsDouble() == 2.0:  # 双键数\n",
    "                neighbor_feats[4] += 1\n",
    "            elif bond.GetBondTypeAsDouble() == 3.0:  # 三键数\n",
    "                neighbor_feats[5] += 1\n",
    "\n",
    "    env_feats.extend(neighbor_feats)\n",
    "    return env_feats\n",
    "# 定义电负性字典\n",
    "electronegativity_dict = {\n",
    "    1: 2.20, 5: 2.04, 6: 2.55, 7: 3.04, 8: 3.44, 9: 3.98, 14: 1.90, 15: 2.19, 16: 2.58, 17: 3.16, 19: 0.82, \n",
    "    26: 1.83, 32: 2.01, 34: 2.55, 35: 2.96, 50: 1.96, 52: 2.1, 53: 2.66\n",
    "}\n",
    "# 定义共价半径字典\n",
    "covalent_radius_dict = {\n",
    "    1: 3.7, 5: 8.2, 6: 7.7, 7: 7.5, 8: 7.3, 9: 7.1, 14: 11.1, 15: 10.6, 16: 10.2, 17: 9.9, 19: 22.7, \n",
    "    26: 12.6, 32: 12.2, 34: 19.8, 35: 11.4, 50: 14.0, 52: 14.0, 53: 13.3\n",
    "}\n",
    "class CarbonylIRDataset(Dataset):\n",
    "    def __init__(self, smiles_list, irc_values,doi):\n",
    "        self.smiles_list = smiles_list\n",
    "        self.mean = np.mean(irc_values)\n",
    "        self.std = np.std(irc_values)\n",
    "        self.irc_values = (irc_values - self.mean) / self.std\n",
    "        self.doi = doi\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.smiles_list)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        mol = Chem.MolFromSmiles(self.smiles_list[idx])\n",
    "        mol = Chem.AddHs(mol)\n",
    "        if mol is None:\n",
    "            return None\n",
    "        # 原子特征\n",
    "        atom_features = []\n",
    "        for atom in mol.GetAtoms():\n",
    "            atomic_num = atom.GetAtomicNum()\n",
    "            features = [\n",
    "              atomic_num,          # 原子序数\n",
    "              atom.GetDegree(),             # 连接数\n",
    "              atom.GetImplicitValence(),    # 隐式价\n",
    "              atom.IsInRing(),              # 是否在环中\n",
    "              atom.GetHybridization().real  # 杂化类型\n",
    "          ]\n",
    "            features.append(electronegativity_dict.get(atomic_num, 0.0))    # 添加电负性\n",
    "            features.append(covalent_radius_dict.get(atomic_num, 0.0))      # 添加共价半径\n",
    "            atom_features.append(features)\n",
    "        \n",
    "        # 边索引\n",
    "        edge_index = []\n",
    "        for bond in mol.GetBonds():\n",
    "            i = bond.GetBeginAtomIdx()\n",
    "            j = bond.GetEndAtomIdx()\n",
    "            edge_index.extend([[i, j], [j, i]])\n",
    "\n",
    "        # 边特征处理\n",
    "        edge_attr = []\n",
    "        for bond in mol.GetBonds():\n",
    "            features = [\n",
    "                bond.GetBondTypeAsDouble(),  # 键类型（单键=1.0，双键=2.0，三键=3.0）\n",
    "                int(bond.GetIsConjugated()), # 是否共轭\n",
    "                int(bond.IsInRing()),        # 是否在环中\n",
    "                int(bond.GetBondType() == Chem.rdchem.BondType.AROMATIC),  # 是否芳香键\n",
    "                bond.GetBoolProp('_IsPolar') if bond.HasProp('_IsPolar') else 0.0  # 极性\n",
    "    ]\n",
    "            # 双向边重复特征\n",
    "            edge_attr.extend([features, features.copy()])  \n",
    "        edge_attr = torch.tensor(edge_attr, dtype=torch.float)#.view(-1, 1)\n",
    "        \n",
    "        # 羰基特征\n",
    "        carbonyl_mask, carbonyl_env = extract_carbonyl_features(mol)\n",
    "        \n",
    "        return Data(\n",
    "            x=torch.tensor(atom_features, dtype=torch.float),\n",
    "            edge_index=torch.tensor(edge_index, dtype=torch.long).t().contiguous(),\n",
    "            edge_attr=edge_attr,\n",
    "            carbonyl_mask=carbonyl_mask,\n",
    "            # carbonyl_env=carbonyl_env,\n",
    "            doi = self.doi[idx],\n",
    "            smiles = self.smiles_list[idx],\n",
    "            y=torch.tensor([self.irc_values[idx]], dtype=torch.float))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cdf6e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "# graph_IR_dataset = CarbonylIRDataset(df_unique['Canonical_SMILES'],df_unique['IR_Characteristic_Peak'],df_unique['DOI'])\n",
    "# torch.save(graph_IR_dataset, 'dataset/primary_graph_IR_dataset_neighbor.pt')\n",
    "graph_IR_dataset = torch.load('dataset/primary_graph_IR_dataset_neighbor.pt')\n",
    "len(graph_IR_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87462f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "# graph_IR_dataset = CarbonylIRDataset(df_unique['Canonical_SMILES'],df_unique['IR_Characteristic_Peak'],df_unique['DOI'])\n",
    "# torch.save(graph_IR_dataset, 'dataset/mutiple_graph_IR_dataset_neighbor.pt')\n",
    "graph_IR_dataset = torch.load('dataset/mutiple_graph_IR_dataset_neighbor.pt')\n",
    "len(graph_IR_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57071cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "# graph_IR_dataset = CarbonylIRDataset(df_unique['Canonical_SMILES'],df_unique['IR_Characteristic_Peak'],df_unique['DOI'])\n",
    "# torch.save(graph_IR_dataset, 'dataset/primary_graph_IR_dataset_neighbor_noenv.pt')\n",
    "graph_IR_dataset = torch.load('dataset/primary_graph_IR_dataset_neighbor_noenv.pt')\n",
    "len(graph_IR_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fca1472a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for ir in graph_IR_dataset:\n",
    "#     print(ir)\n",
    "i = 2\n",
    "print(graph_IR_dataset[i])\n",
    "# print(graph_IR_dataset[i].x)\n",
    "# print(graph_IR_dataset[i].edge_index)\n",
    "# print(graph_IR_dataset[i].edge_attr)\n",
    "# print(graph_IR_dataset[i].y)\n",
    "print(graph_IR_dataset[i].carbonyl_mask)\n",
    "print(graph_IR_dataset[i].carbonyl_env)\n",
    "# print(graph_IR_dataset[i].doi)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a049ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def extract_amide_molecules(    dataset,     r1,     r2,     max_count: int = 500,     random_seed: int = 42) -> list:\n",
    "\n",
    "    if random_seed is not None:\n",
    "        random.seed(random_seed)\n",
    "    \n",
    "    # 将r1和r2统一转换为集合形式\n",
    "    r1_set = {r1} if isinstance(r1, int) else set(r1)\n",
    "    r2_set = {r2} if isinstance(r2, int) else set(r2)\n",
    "    \n",
    "    # 收集所有符合条件的分子\n",
    "    all_valid_molecules = []\n",
    "    \n",
    "    for data in dataset:\n",
    "        atomic_numbers = data.x[:, 0]  # 假设原子序数是x的第一列\n",
    "        carbonyl_neighbor_indices = torch.where(data.carbonyl_mask == 1)[0]\n",
    "        \n",
    "        # 必须恰好有两个邻接原子\n",
    "        if len(carbonyl_neighbor_indices) != 2:\n",
    "            continue\n",
    "        \n",
    "        # 获取两个邻接原子的原子序数\n",
    "        neighbor1_z = atomic_numbers[carbonyl_neighbor_indices[0]].item()\n",
    "        neighbor2_z = atomic_numbers[carbonyl_neighbor_indices[1]].item()\n",
    "        \n",
    "        # 检查是否匹配任一组合 (顺序无关)\n",
    "        if (\n",
    "            (neighbor1_z in r1_set and neighbor2_z in r2_set) or \n",
    "            (neighbor1_z in r2_set and neighbor2_z in r1_set)\n",
    "        ):\n",
    "            all_valid_molecules.append(data)\n",
    "    \n",
    "    # 检查是否有足够多的分子\n",
    "    if len(all_valid_molecules) == 0:\n",
    "        print(\"警告: 没有找到任何符合条件的分子\")\n",
    "        return []\n",
    "    \n",
    "    # 去重采样\n",
    "    selected_molecules = []\n",
    "    selected_ids = set()\n",
    "    total_molecules = len(all_valid_molecules)\n",
    "    \n",
    "    while len(selected_molecules) < min(max_count, total_molecules):\n",
    "        remaining_molecules = [m for m in all_valid_molecules if id(m) not in selected_ids]\n",
    "        \n",
    "        if not remaining_molecules:  # 所有非重复元素已取完\n",
    "            break\n",
    "            \n",
    "        new_molecule = random.choice(remaining_molecules)\n",
    "        selected_molecules.append(new_molecule)\n",
    "        selected_ids.add(id(new_molecule))\n",
    "    \n",
    "    print(f\"采样完成: 从 {total_molecules} 个有效分子中选取了 {len(selected_molecules)} 个非重复分子\")\n",
    "    return selected_molecules\n",
    "amide_moleculesN = extract_amide_molecules(graph_IR_dataset,6,7)\n",
    "amide_moleculesO = extract_amide_molecules(graph_IR_dataset,6,8)\n",
    "amide_moleculesF = extract_amide_molecules(graph_IR_dataset,6,[9,17,35,53])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65927939",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 3\n",
    "# print(amide_molecules[i])\n",
    "# print(amide_molecules[i].x)\n",
    "# print(amide_molecules[i].edge_index)\n",
    "# print(amide_molecules[i].edge_attr)\n",
    "# print(amide_molecules[i].y)\n",
    "# print(amide_molecules[i].carbonyl_mask)\n",
    "# print(amide_molecules[i].carbonyl_env)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44ee8128",
   "metadata": {},
   "source": [
    "## network struct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add4cfd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 环境特征合并 16\n",
    "from torch_geometric.nn import GINEConv,GINConv\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv, GATConv, GINEConv\n",
    "from torch_geometric.utils import scatter\n",
    "\n",
    "class GCNEConv(nn.Module):\n",
    "    \"\"\"支持边特征的GCN变体\"\"\"\n",
    "    def __init__(self, in_dim, out_dim):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(in_dim, out_dim)\n",
    "        self.edge_encoder = nn.Linear(in_dim, out_dim)\n",
    "    \n",
    "    def forward(self, x, edge_index, edge_attr):\n",
    "        row, col = edge_index\n",
    "        # 边特征传播\n",
    "        edge_emb = self.edge_encoder(edge_attr)\n",
    "        out = scatter(edge_emb * x[row], col, dim=0, reduce='sum')\n",
    "        # 节点特征变换\n",
    "        return F.leaky_relu(self.linear(x) + out, 0.1)\n",
    "\n",
    "class GATEConv(nn.Module):\n",
    "    \"\"\"修正后的支持边特征的GAT变体\"\"\"\n",
    "    def __init__(self, in_dim, out_dim, heads=4):\n",
    "        super().__init__()\n",
    "        self.heads = heads\n",
    "        self.out_dim = out_dim\n",
    "        \n",
    "        # 注意力计算层\n",
    "        self.attn = nn.Linear(3 * in_dim, heads)  # 输入: [x_i || x_j || e_ij]\n",
    "        \n",
    "        # 特征变换层\n",
    "        self.linear = nn.Linear(in_dim, out_dim)\n",
    "        self.edge_encoder = nn.Linear(in_dim, out_dim)\n",
    "        \n",
    "    def forward(self, x, edge_index, edge_attr):\n",
    "        row, col = edge_index\n",
    "        \n",
    "        # 边特征编码\n",
    "        edge_emb = self.edge_encoder(edge_attr)  # [E, out_dim]\n",
    "        \n",
    "        # 拼接节点和边特征 [x_i || x_j || e_ij]\n",
    "        x_cat = torch.cat([x[row], x[col], edge_emb], dim=-1)  # [E, 3*in_dim]\n",
    "        \n",
    "        # 计算注意力分数 [E, heads]\n",
    "        alpha = F.softmax(self.attn(x_cat), dim=0)  # 按边归一化\n",
    "        \n",
    "        # 多头特征变换\n",
    "        h_node = self.linear(x)  # [N, out_dim]\n",
    "        h_edge = edge_emb        # [E, out_dim]\n",
    "        \n",
    "        # 加权聚合 (分头处理)\n",
    "        out = torch.zeros(x.size(0), self.heads, self.out_dim, device=x.device)\n",
    "        alpha = alpha.unsqueeze(-1)  # [E, heads, 1]\n",
    "        weighted = (x[row] + h_edge).unsqueeze(1) * alpha  # [E, heads, out_dim]\n",
    "        out = scatter(weighted, col, dim=0, reduce='sum')  # [N, heads, out_dim]\n",
    "        \n",
    "        # 合并多头并残差连接\n",
    "        return F.leaky_relu(h_node + out.mean(dim=1), 0.1)  # [N, out_dim]\n",
    "class GNNGraph(nn.Module):\n",
    "    def __init__(self, node_dim=16, edge_dim=5, hidden_dim=128,num_layers=4, num_nodes=2, conv_type='GIN'):\n",
    "        super().__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_nodes = num_nodes\n",
    "        self.conv_type = conv_type.upper()  # 统一转为大写\n",
    "        # 公共编码器\n",
    "        self.node_encoder = nn.Sequential(\n",
    "            nn.Linear(node_dim, hidden_dim),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.LeakyReLU(0.1),\n",
    "        )\n",
    "        \n",
    "        # 边编码器（GIN/GCNE/GATE需要）\n",
    "        if self.conv_type in ['GINE', 'GCNE', 'GATE']:\n",
    "            self.edge_encoder = nn.Sequential(\n",
    "                nn.Linear(edge_dim, hidden_dim),\n",
    "                nn.BatchNorm1d(hidden_dim),\n",
    "                nn.LeakyReLU(0.1),\n",
    "            )\n",
    "        else:\n",
    "            self.edge_encoder = None\n",
    "        \n",
    "        # 卷积层选择\n",
    "        self.convs = nn.ModuleList()\n",
    "        for _ in range(num_layers):\n",
    "            if self.conv_type == 'GCN':\n",
    "                conv = GCNConv(hidden_dim, hidden_dim)\n",
    "            elif self.conv_type == 'GAT':\n",
    "                conv = GATConv(hidden_dim, hidden_dim, heads=4, concat=False)\n",
    "            elif self.conv_type == 'GIN':\n",
    "                conv = GINConv(\n",
    "                    nn.Sequential(\n",
    "                        nn.Linear(hidden_dim, hidden_dim),\n",
    "                        nn.BatchNorm1d(hidden_dim),\n",
    "                        nn.LeakyReLU(0.1),\n",
    "                    ),\n",
    "                    train_eps=True \n",
    "                )\n",
    "            elif self.conv_type == 'GINE':\n",
    "                conv = GINEConv(\n",
    "                    nn.Sequential(\n",
    "                        nn.Linear(hidden_dim, hidden_dim),\n",
    "                        nn.BatchNorm1d(hidden_dim),\n",
    "                        nn.LeakyReLU(0.1),\n",
    "                    ),\n",
    "                    edge_dim=hidden_dim,\n",
    "                    train_eps=True\n",
    "                )\n",
    "            elif self.conv_type == 'GCNE':\n",
    "                conv = GCNEConv(hidden_dim, hidden_dim)\n",
    "            elif self.conv_type == 'GATE':\n",
    "                conv = GATEConv(hidden_dim, hidden_dim)\n",
    "            else:\n",
    "                raise ValueError(f\"Unsupported conv_type: {conv_type}\")\n",
    "            self.convs.append(conv)\n",
    "        \n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr,data):\n",
    "        # data.x, data.edge_index, data.edge_attr\n",
    "        \n",
    "        # 节点特征、边特征编码 \n",
    "        h  = self.node_encoder(x)  # 使用节点特征编码器\n",
    "        edge_emb = self.edge_encoder(edge_attr) if self.edge_encoder else None\n",
    "\n",
    "        # 图卷积层（添加残差连接）\n",
    "          # 使用编码后的节点特征\n",
    "        for conv in self.convs:\n",
    "            if self.conv_type in ['GINE', 'GCNE', 'GATE']:\n",
    "                h = conv(h, edge_index, edge_emb)\n",
    "            else:\n",
    "                h = conv(h, edge_index)\n",
    "            h = self.dropout(h)\n",
    "\n",
    "        # 环境特征处理\n",
    "        carbonyl_mask = data.carbonyl_mask.view(-1, 1).float()\n",
    "        # 注意力机制改进（缩放点积）\n",
    "        if self.num_nodes ==2:\n",
    "            selected_nodes = carbonyl_mask.squeeze() == 1\n",
    "            graph_embed = h[selected_nodes].view(-1, self.hidden_dim * 2 )  # 将选中节点特征展平\n",
    "        elif self.num_nodes ==1:\n",
    "            selected_nodes = carbonyl_mask.squeeze() == 0.6\n",
    "            graph_embed = h[selected_nodes].view(-1, self.hidden_dim)\n",
    "        return graph_embed\n",
    "\n",
    "class GNNPredictor(nn.Module):\n",
    "    def __init__(self, node_dim=16, edge_dim=5, hidden_dim=128,num_layers=4,num_nodes=2,env_num=0,conv_type='GINE'):\n",
    "        super().__init__()\n",
    "        self.conv_type=conv_type\n",
    "        self.gnn = GNNGraph(node_dim, edge_dim, hidden_dim,num_layers, num_nodes , conv_type)\n",
    "        init_fn = lambda m: (\n",
    "            nn.init.xavier_normal_(m.weight) if isinstance(m, nn.Linear) else None\n",
    "        )\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.dropout = nn.Dropout(0.2)  # 添加Dropout层\n",
    "        # self.num_nodes=num_nodes\n",
    "        # self.env_num=env_num\n",
    "        self.predict = nn.Sequential(\n",
    "            nn.BatchNorm1d(self.hidden_dim * num_nodes + 13*env_num),\n",
    "            nn.Linear(self.hidden_dim * num_nodes + 13*env_num,self.hidden_dim * num_nodes + 13*env_num),\n",
    "            nn.BatchNorm1d(self.hidden_dim * num_nodes + 13*env_num),  # 替换为BatchNorm\n",
    "            nn.LeakyReLU(0.1),\n",
    "            self.dropout,\n",
    "            nn.Linear(self.hidden_dim * num_nodes + 13*env_num, 1)\n",
    "        )\n",
    "        self.gnn.apply(init_fn)\n",
    "        self.predict.apply(init_fn)\n",
    "    def forward(self, x, edge_index, edge_attr,data):\n",
    "        graph_embed = self.gnn(x, edge_index, edge_attr,data)\n",
    "\n",
    "        return self.predict(graph_embed).squeeze(-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "311b3cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 环境特征合并 16， 尝试多个基团\n",
    "class GNNGraph(nn.Module):\n",
    "    def __init__(self, node_dim=17, edge_dim=5, hidden_dim=128,num_layers=4, num_nodes=2, conv_type='GIN'):\n",
    "        super().__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_nodes = num_nodes\n",
    "        self.conv_type = conv_type.upper()  # 统一转为大写\n",
    "        # 公共编码器\n",
    "        self.node_encoder = nn.Sequential(\n",
    "            nn.Linear(node_dim, hidden_dim),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.LeakyReLU(0.1),\n",
    "        )\n",
    "        \n",
    "        # 边编码器（GIN/GCNE/GATE需要）\n",
    "        if self.conv_type in ['GINE', 'GCNE', 'GATE']:\n",
    "            self.edge_encoder = nn.Sequential(\n",
    "                nn.Linear(edge_dim, hidden_dim),\n",
    "                nn.BatchNorm1d(hidden_dim),\n",
    "                nn.LeakyReLU(0.1),\n",
    "            )\n",
    "        else:\n",
    "            self.edge_encoder = None\n",
    "        \n",
    "        # 卷积层选择\n",
    "        self.convs = nn.ModuleList()\n",
    "        for _ in range(num_layers):\n",
    "            if self.conv_type == 'GCN':\n",
    "                conv = GCNConv(hidden_dim, hidden_dim)\n",
    "            elif self.conv_type == 'GAT':\n",
    "                conv = GATConv(hidden_dim, hidden_dim, heads=4, concat=False)\n",
    "            elif self.conv_type == 'GIN':\n",
    "                conv = GINConv(\n",
    "                    nn.Sequential(\n",
    "                        nn.Linear(hidden_dim, hidden_dim),\n",
    "                        nn.BatchNorm1d(hidden_dim),\n",
    "                        nn.LeakyReLU(0.1),\n",
    "                    ),\n",
    "                    train_eps=True \n",
    "                )\n",
    "            elif self.conv_type == 'GINE':\n",
    "                conv = GINEConv(\n",
    "                    nn.Sequential(\n",
    "                        nn.Linear(hidden_dim, hidden_dim),\n",
    "                        nn.BatchNorm1d(hidden_dim),\n",
    "                        nn.LeakyReLU(0.1),\n",
    "                    ),\n",
    "                    edge_dim=hidden_dim,\n",
    "                    train_eps=True\n",
    "                )\n",
    "            elif self.conv_type == 'GCNE':\n",
    "                conv = GCNEConv(hidden_dim, hidden_dim)\n",
    "            elif self.conv_type == 'GATE':\n",
    "                conv = GATEConv(hidden_dim, hidden_dim)\n",
    "            else:\n",
    "                raise ValueError(f\"Unsupported conv_type: {conv_type}\")\n",
    "            self.convs.append(conv)\n",
    "        \n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr,data):\n",
    "        # data.x, data.edge_index, data.edge_attr\n",
    "        \n",
    "        # 节点特征、边特征编码 \n",
    "        h  = self.node_encoder(x)  # 使用节点特征编码器\n",
    "        edge_emb = self.edge_encoder(edge_attr) if self.edge_encoder else None\n",
    "\n",
    "        # 图卷积层（添加残差连接）\n",
    "          # 使用编码后的节点特征\n",
    "        for conv in self.convs:\n",
    "            if self.conv_type in ['GINE', 'GCNE', 'GATE']:\n",
    "                h = conv(h, edge_index, edge_emb)\n",
    "            else:\n",
    "                h = conv(h, edge_index)\n",
    "            h = self.dropout(h)\n",
    "\n",
    "        # 环境特征处理\n",
    "        carbonyl_mask = data.carbonyl_mask.view(-1, 1).float()\n",
    "        # 注意力机制改进（缩放点积）\n",
    "        if self.num_nodes ==2:\n",
    "            selected_nodes = carbonyl_mask.squeeze() == 1\n",
    "            graph_embed = h[selected_nodes].view(-1, self.hidden_dim * 2 )  # 将选中节点特征展平\n",
    "        elif self.num_nodes ==1:\n",
    "            selected_nodes = carbonyl_mask.squeeze()%1 == 0.6\n",
    "            graph_embed = h[selected_nodes].view(-1, self.hidden_dim)\n",
    "        return graph_embed\n",
    "\n",
    "class GNNPredictor(nn.Module):\n",
    "    def __init__(self, node_dim=16, edge_dim=5, hidden_dim=128,num_layers=4,num_nodes=2,env_num=0,conv_type='GINE'):\n",
    "        super().__init__()\n",
    "        self.conv_type=conv_type\n",
    "        self.gnn = GNNGraph(node_dim, edge_dim, hidden_dim,num_layers, num_nodes , conv_type)\n",
    "        init_fn = lambda m: (\n",
    "            nn.init.xavier_normal_(m.weight) if isinstance(m, nn.Linear) else None\n",
    "        )\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.dropout = nn.Dropout(0.2)  # 添加Dropout层\n",
    "        # self.num_nodes=num_nodes\n",
    "        # self.env_num=env_num\n",
    "        self.predict = nn.Sequential(\n",
    "            nn.BatchNorm1d(self.hidden_dim * num_nodes + 13*env_num),\n",
    "            nn.Linear(self.hidden_dim * num_nodes + 13*env_num,self.hidden_dim * num_nodes + 13*env_num),\n",
    "            nn.BatchNorm1d(self.hidden_dim * num_nodes + 13*env_num),  # 替换为BatchNorm\n",
    "            nn.LeakyReLU(0.1),\n",
    "            self.dropout,\n",
    "            nn.Linear(self.hidden_dim * num_nodes + 13*env_num, 1)\n",
    "        )\n",
    "        self.gnn.apply(init_fn)\n",
    "        self.predict.apply(init_fn)\n",
    "    def forward(self, x, edge_index, edge_attr,data):\n",
    "        graph_embed = self.gnn(x, edge_index, edge_attr,data)\n",
    "\n",
    "        return self.predict(graph_embed).squeeze(-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d650ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 取多个的基团\n",
    "from torch_geometric.nn import GINEConv\n",
    "from torch import nn\n",
    "class GNNGraph(nn.Module):\n",
    "    def __init__(self, node_dim=7, edge_dim=5, hidden_dim=128, num_layers=4 ,use_neibors=True):\n",
    "        super().__init__()\n",
    "        # 保持原有初始化不变\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        self.use_neibors = use_neibors\n",
    "        self.node_encoder = nn.Sequential(\n",
    "            nn.Linear(node_dim, hidden_dim),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.LeakyReLU(0.1),\n",
    "        )\n",
    "        self.edge_encoder = nn.Sequential(\n",
    "            nn.Linear(edge_dim, hidden_dim),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.LeakyReLU(0.1),\n",
    "        )\n",
    "        self.convs = nn.ModuleList([\n",
    "            GINEConv(\n",
    "                nn.Sequential(\n",
    "                    nn.Linear(hidden_dim, hidden_dim),\n",
    "                    nn.BatchNorm1d(hidden_dim),\n",
    "                    nn.LeakyReLU(0.1),\n",
    "                ),\n",
    "                edge_dim=hidden_dim,\n",
    "                train_eps=True\n",
    "            ) for _ in range(num_layers)\n",
    "        ])\n",
    "\n",
    "    def get_neighbor_nodes(self, data, target_mask=0.6, exclude_mask=0.8):\n",
    "        edge_index = data.edge_index\n",
    "        carbonyl_mask = data.carbonyl_mask\n",
    "        atomic_nums = data.x[:, 0]  # 假设原子序数是node特征的第一维\n",
    "        \n",
    "        # 找到目标节点(mask > target_mask)\n",
    "        target_nodes = (carbonyl_mask %1== target_mask).nonzero().squeeze()\n",
    "        neighbor_nodes = []\n",
    "        \n",
    "        # 对每个目标节点单独处理\n",
    "        for carbon_idx in target_nodes:\n",
    "            # 获取当前目标节点的所有邻居\n",
    "            neighbors = edge_index[1, edge_index[0] == carbon_idx]\n",
    "            \n",
    "            # 筛选符合条件的邻居:\n",
    "            # 1. carbonyl_mask != exclude_mask\n",
    "            # 2. 不是目标节点本身(避免自环)\n",
    "            valid_neighbors = [\n",
    "                n for n in neighbors \n",
    "                if (carbonyl_mask[n] %1 != exclude_mask) and (n != carbon_idx)\n",
    "            ]\n",
    "            \n",
    "            # 按原子序数从大到小排序(仅当前子图的邻居)\n",
    "            sorted_neighbors = sorted(\n",
    "                valid_neighbors,\n",
    "                key=lambda x: atomic_nums[x],\n",
    "                reverse=True\n",
    "            )\n",
    "            \n",
    "            # 只取前两个节点(如果存在)\n",
    "            neighbor_nodes.extend(sorted_neighbors[:2])\n",
    "        \n",
    "        return torch.tensor(neighbor_nodes, dtype=torch.long) if neighbor_nodes else torch.tensor([], dtype=torch.long)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr, data):\n",
    "        # 特征编码\n",
    "        node_emb = self.node_encoder(x)\n",
    "        edge_emb = self.edge_encoder(edge_attr)\n",
    "\n",
    "        # 图卷积\n",
    "        h = node_emb\n",
    "        for conv in self.convs:\n",
    "            h = conv(h, edge_index, edge_emb)\n",
    "        \n",
    "        # 获取目标节点索引\n",
    "        target_nodes = self.get_neighbor_nodes(data)\n",
    "        \n",
    "        # 拼接特征\n",
    "        if len(target_nodes) > 0 and self.use_neibors:\n",
    "            # 确保每个子图贡献两个节点特征\n",
    "            graph_embed = h[target_nodes].view(-1, self.hidden_dim * 2)\n",
    "        else:\n",
    "            # 如果没有符合条件的节点，返回零向量\n",
    "            graph_embed = torch.zeros(1, self.hidden_dim * 2, device=h.device)\n",
    "        \n",
    "        return graph_embed\n",
    "class GNNPredictor(nn.Module):\n",
    "    def __init__(self, node_dim=7, edge_dim=5, hidden_dim=128,num_layers=4,node_num=2,env_num=3):\n",
    "        super().__init__()\n",
    "        self.gnn = GNNGraph(node_dim, edge_dim, hidden_dim,num_layers)\n",
    "        init_fn = lambda m: (\n",
    "            nn.init.xavier_normal_(m.weight) if isinstance(m, nn.Linear) else None\n",
    "        )\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.dropout = nn.Dropout(0.2)  # 添加Dropout层\n",
    "        # self.node_num=node_num\n",
    "        # self.env_num=env_num\n",
    "        self.predict = nn.Sequential(\n",
    "            nn.BatchNorm1d(self.hidden_dim * node_num + 13*env_num),\n",
    "            nn.Linear(self.hidden_dim * node_num + 13*env_num,self.hidden_dim * node_num + 13*env_num),\n",
    "            nn.BatchNorm1d(self.hidden_dim * node_num + 13*env_num),  # 替换为BatchNorm\n",
    "            nn.LeakyReLU(0.1),\n",
    "            self.dropout,\n",
    "            nn.Linear(self.hidden_dim * node_num + 13*env_num, 1)\n",
    "        )\n",
    "        self.gnn.apply(init_fn)\n",
    "        self.predict.apply(init_fn)\n",
    "    def forward(self, x, edge_index, edge_attr,data):\n",
    "        graph_embed = self.gnn(x, edge_index, edge_attr,data)\n",
    "\n",
    "        return self.predict(graph_embed).squeeze(-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b49913b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 环境特征分开 7+13\n",
    "from torch_geometric.nn import GINEConv\n",
    "from torch import nn\n",
    "class GINGraph(nn.Module):\n",
    "    def __init__(self, node_dim=7, edge_dim=5, hidden_dim=128,num_layers=4):\n",
    "        super().__init__()\n",
    "        \n",
    "        # 初始化配置\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.dropout = nn.Dropout(0.2)  # 添加Dropout层\n",
    "        # 节点特征编码器\n",
    "        self.node_encoder = nn.Sequential(\n",
    "            nn.Linear(node_dim, hidden_dim),\n",
    "            nn.BatchNorm1d(self.hidden_dim),\n",
    "            nn.LeakyReLU(0.1),\n",
    "        )\n",
    "        # 边特征编码器\n",
    "        self.edge_encoder = nn.Sequential(\n",
    "            nn.Linear(edge_dim, self.hidden_dim),\n",
    "            nn.BatchNorm1d(self.hidden_dim),  # 替换为BatchNorm\n",
    "            nn.LeakyReLU(0.1),  # 改用LeakyReLU\n",
    "        )\n",
    "        # 卷积层\n",
    "        self.convs = nn.ModuleList()\n",
    "        for layer in range(num_layers):\n",
    "            self.convs.append(\n",
    "                GINEConv(\n",
    "                    nn.Sequential(\n",
    "                        nn.Linear(hidden_dim, hidden_dim),  # 去掉第一层的映射\n",
    "                        nn.BatchNorm1d(hidden_dim),\n",
    "                        nn.LeakyReLU(0.1),\n",
    "#                         self.dropout\n",
    "                    ),\n",
    "                    edge_dim=hidden_dim,\n",
    "                    train_eps=True\n",
    "                )\n",
    "            )\n",
    "    def forward(self, data):\n",
    "        x, edge_index, edge_attr = data.x, data.edge_index, data.edge_attr\n",
    "        # batch = data.batch\n",
    "        \n",
    "        # 节点特征、边特征编码 \n",
    "        node_emb = self.node_encoder(x)  # 使用节点特征编码器\n",
    "        edge_emb = self.edge_encoder(edge_attr)\n",
    "\n",
    "        # 图卷积层（添加残差连接）\n",
    "        h = node_emb  # 使用编码后的节点特征\n",
    "        for conv in self.convs:\n",
    "            h = conv(h, edge_index, edge_emb)# + h  # 残差连接\n",
    "\n",
    "        # 环境特征处理\n",
    "        carbonyl_env = data.carbonyl_env\n",
    "        carbonyl_mask = data.carbonyl_mask.view(-1, 1).float()\n",
    "        # print(carbonyl_env[0],carbonyl_env.shape,h.shape)\n",
    "        # print(carbonyl_mask,carbonyl_mask.shape)\n",
    "        # env_features = carbonyl_env[batch]\n",
    "        # print(env_features[0],env_features.shape)\n",
    "        # 注意力机制改进（缩放点积）\n",
    "        combined = torch.cat([h, carbonyl_env], dim=1)# / (self.hidden_dim ** 0.25)  # 缩放输入\n",
    "        selected_nodes = carbonyl_mask.squeeze() == 1\n",
    "        graph_embed = combined[selected_nodes].view(-1, self.hidden_dim * 2 + 13*2)  # 将选中节点特征展平\n",
    "        carbonyl_nodes = carbonyl_mask.squeeze() == 0.9\n",
    "        graph_embed = torch.cat([combined[carbonyl_nodes],graph_embed], dim=1)\n",
    "        # print(combined[selected_nodes][0][-13:])\n",
    "        # print(carbonyl_env[selected_nodes][0])\n",
    "        return graph_embed\n",
    "\n",
    "class GNNPredictor(nn.Module):\n",
    "    def __init__(self, node_dim=7, edge_dim=5, hidden_dim=128,num_layers=4,node_num=2,env_num=3):\n",
    "        super().__init__()\n",
    "        self.gnn = GINGraph(node_dim, edge_dim, hidden_dim,num_layers)\n",
    "        init_fn = lambda m: (\n",
    "            nn.init.xavier_normal_(m.weight) if isinstance(m, nn.Linear) else None\n",
    "        )\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.dropout = nn.Dropout(0.2)  # 添加Dropout层\n",
    "        # self.node_num=node_num\n",
    "        # self.env_num=env_num\n",
    "        self.predict = nn.Sequential(\n",
    "            nn.BatchNorm1d(self.hidden_dim * node_num + 13*env_num),\n",
    "            nn.Linear(self.hidden_dim * node_num + 13*env_num,self.hidden_dim * node_num + 13*env_num),\n",
    "            nn.BatchNorm1d(self.hidden_dim * num_nodes + 13*env_num),  # 替换为BatchNorm\n",
    "            nn.LeakyReLU(0.1),\n",
    "            self.dropout,\n",
    "            nn.Linear(self.hidden_dim * node_num + 13*env_num, 1)\n",
    "        )\n",
    "        self.gnn.apply(init_fn)\n",
    "        self.predict.apply(init_fn)\n",
    "    def forward(self, data):\n",
    "        graph_embed = self.gnn(data)\n",
    "\n",
    "        return self.predict(graph_embed).squeeze(-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0143ca95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置打印选项：禁用科学计数法，显示完整张量\n",
    "torch.set_printoptions(threshold=float('inf'), sci_mode=False)\n",
    "\n",
    "model = GINGraph(node_dim=17,hidden_dim=128,num_layers=4).to(device)\n",
    "# criterion_fn = torch.nn.MSELoss()\n",
    "# optimizer = optim.AdamW(model.parameters(), lr=0.01, weight_decay=0.001)\n",
    "test1_graph_IR_loader = DataLoader(test_graph_IR_dataset[:8],batch_size=4,shuffle=False, num_workers=1)\n",
    "for step, batch in enumerate(test1_graph_IR_loader):\n",
    "    batch_atom_bond = batch\n",
    "    batch_atom_bond = batch_atom_bond.to(device)\n",
    "    pred = model(batch_atom_bond.x, batch_atom_bond.edge_index, batch_atom_bond.edge_attr,batch_atom_bond)\n",
    "    print(step,pred[0][-13:],pred.shape)\n",
    "\n",
    "# loss = test111(model, device, test1_graph_IR_loader, optimizer, criterion_fn)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad9d400d",
   "metadata": {},
   "source": [
    "## training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf6949f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(model, device, loader_atom_bond):\n",
    "    model.eval()\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for _, batch in enumerate(loader_atom_bond):\n",
    "            batch_atom_bond = batch\n",
    "            batch_atom_bond = batch_atom_bond.to(device)\n",
    "            pred = model(batch_atom_bond.x, batch_atom_bond.edge_index, batch_atom_bond.edge_attr,batch_atom_bond)\n",
    "            y_true.append(batch_atom_bond.y.detach().cpu().reshape(-1))\n",
    "            y_pred.append(pred[:].detach().cpu())\n",
    "\n",
    "    y_true = torch.cat(y_true, dim=0) * graph_IR_dataset.std + graph_IR_dataset.mean\n",
    "    y_pred = torch.cat(y_pred, dim=0) * graph_IR_dataset.std + graph_IR_dataset.mean\n",
    "    # print(y_true[:4],y_pred[:4])\n",
    "    # input_dict = {\"y_true\": y_true, \"y_pred\": y_pred}\n",
    "    return torch.sqrt(torch.mean((y_true - y_pred) ** 2)).data.numpy()\n",
    "def test(model, device, loader_atom_bond,save_fig_dir= None,model_name = 'model_name'):\n",
    "    model.eval()\n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "    with torch.no_grad():\n",
    "        for _, batch in enumerate(loader_atom_bond):\n",
    "            batch_atom_bond = batch\n",
    "            batch_atom_bond = batch_atom_bond.to(device)\n",
    "            pred = model(batch_atom_bond.x, batch_atom_bond.edge_index, batch_atom_bond.edge_attr,batch_atom_bond)\n",
    "            y_true.append(batch_atom_bond.y.detach().cpu().reshape(-1,))\n",
    "            y_pred.append(pred[:].detach().cpu())\n",
    "            \n",
    "    y_true = torch.cat(y_true, dim=0) * graph_IR_dataset.std + graph_IR_dataset.mean\n",
    "    y_pred = torch.cat(y_pred, dim=0) * graph_IR_dataset.std + graph_IR_dataset.mean\n",
    "\n",
    "    R_square = 1 - (((y_true - y_pred) ** 2).sum() / ((y_true - y_true.mean()) ** 2).sum())\n",
    "    test_mae = torch.mean(torch.abs(y_true - y_pred))\n",
    "    test_rmse = torch.sqrt(torch.mean((y_true - y_pred) ** 2))\n",
    "    print(R_square)\n",
    "    if save_fig_dir:\n",
    "        fig = plot_prediction_scatter(y_true, y_pred, f'{model_name}', figsize=(6/2.54, 6/2.54), alpha=0.2)\n",
    "        fig.savefig(f'{save_fig_dir}\\{model_name}.pdf', bbox_inches='tight', dpi=300)\n",
    "        fig = plot_prediction_scatter2(y_true, y_pred, f'{model_name}', figsize=(6/2.54, 6/2.54), alpha=0.2)\n",
    "        fig.savefig(f'{save_fig_dir}\\{model_name} 2.pdf', bbox_inches='tight', dpi=300)\n",
    "        # plt.show()\n",
    "    return y_pred, y_true,R_square,test_mae,test_rmse\n",
    "def train(model, device, loader_atom_bond, optimizer, criterion_fn):\n",
    "    model.train()\n",
    "    loss_accum = 0\n",
    "\n",
    "    for step, batch in enumerate(loader_atom_bond):\n",
    "        batch_atom_bond = batch\n",
    "        batch_atom_bond = batch_atom_bond.to(device)\n",
    "\n",
    "        pred = model(batch_atom_bond.x, batch_atom_bond.edge_index, batch_atom_bond.edge_attr,batch_atom_bond)#.view(-1, )\n",
    "        true=batch_atom_bond.y\n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion_fn(pred, true)\n",
    "        # print(\"Loss:\", loss.item())\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_accum += loss.detach().cpu().item()\n",
    "        avg_loss = loss_accum / (step + 1)\n",
    "        # print(\"Average Loss:\", avg_loss, \"Steps:\", step + 1,'\\n')\n",
    "            \n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ae56f4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "total_num = len(graph_IR_dataset)\n",
    "print('data num:',total_num)\n",
    "def data_split(random_seed=42,train_ratio = 0.9,validate_ratio = 0.05,test_ratio=0.05):\n",
    "    data_array = np.arange(0, total_num, 1)\n",
    "    np.random.seed(random_seed)\n",
    "    np.random.shuffle(data_array)\n",
    "    # torch.random.manual_seed(42)\n",
    "    train_num = int(len(data_array) * train_ratio)\n",
    "    test_num = int(len(data_array) * test_ratio)\n",
    "    val_num = int(len(data_array) - train_num-test_num)\n",
    "    # (train_graph_IR_dataset, valid_graph_IR_dataset, test_graph_IR_dataset) = torch.utils.data.random_split(graph_IR_dataset,[train_num, val_num, test_num],generator=torch.Generator().manual_seed(42))\n",
    "    train_index = data_array[0:train_num]\n",
    "    valid_index = data_array[train_num:train_num + val_num]\n",
    "    test_index = data_array[train_num + val_num:train_num + val_num + test_num]\n",
    "    test_graph_IR_dataset,valid_graph_IR_dataset,train_graph_IR_dataset=[],[],[]\n",
    "    for i in test_index:\n",
    "        test_graph_IR_dataset.append(graph_IR_dataset[i])\n",
    "    for i in valid_index:\n",
    "        valid_graph_IR_dataset.append(graph_IR_dataset[i])\n",
    "    for i in train_index:\n",
    "        train_graph_IR_dataset.append(graph_IR_dataset[i])\n",
    "    train_graph_IR_loader = DataLoader(train_graph_IR_dataset, batch_size=128,shuffle=True, num_workers=1)\n",
    "    valid_graph_IR_loader = DataLoader(valid_graph_IR_dataset, batch_size=128,shuffle=False, num_workers=1)\n",
    "    test_graph_IR_loader = DataLoader(test_graph_IR_dataset, batch_size=128,shuffle=False, num_workers=1)\n",
    "    return train_graph_IR_loader,valid_graph_IR_loader,test_graph_IR_loader,test_graph_IR_dataset\n",
    "train_graph_IR_loader,valid_graph_IR_loader,test_graph_IR_loader,test_graph_IR_dataset=data_split(random_seed=42,train_ratio = 0.9,validate_ratio = 0.05,test_ratio=0.05)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc693f47",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "conv_types = ['GATE', 'GAT', 'GCNE', 'GCN', 'GIN', 'GINE']\n",
    "def training(save_path='saves',conv_type='GINE'):\n",
    "    if not os.path.exists(save_path):\n",
    "        os.makedirs(save_path)\n",
    "    model = GNNPredictor(node_dim=16,hidden_dim=256,num_layers=5,num_nodes=1,env_num=0,conv_type=conv_type).to(device)\n",
    "    # model.load_state_dict(torch.load('ablation/GATE/model_save_75.pth'))\n",
    "\n",
    "    criterion_fn = torch.nn.MSELoss()\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=0.004, weight_decay=0.0001)\n",
    "    patience = 25\n",
    "    best_loss = float('inf')\n",
    "    patience_counter = 0\n",
    "    min_lr = 0.00001\n",
    "    reduce_factor = 0.2\n",
    "    for epoch in tqdm(range(1000)):\n",
    "        loss = train(model, device, train_graph_IR_loader, optimizer, criterion_fn)\n",
    "        # 检查损失并更新耐心计数\n",
    "        if loss < best_loss:\n",
    "            best_loss = loss\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "\n",
    "        if patience_counter >= patience:\n",
    "            for param_group in optimizer.param_groups:\n",
    "                new_lr = max(param_group['lr'] * reduce_factor, min_lr)\n",
    "                param_group['lr'] = new_lr\n",
    "                if patience_counter<26:\n",
    "                    print(f\"Reducing learning rate to {new_lr:.6f}\")\n",
    "                if param_group['lr']>min_lr:\n",
    "                    patience_counter = 0  # 重置耐心计数    \n",
    "\n",
    "        if (epoch + 1) % 25 == 0:\n",
    "            train_rmse = eval(model, device, train_graph_IR_loader)\n",
    "            valid_rmse = eval(model, device, valid_graph_IR_loader)\n",
    "            print('RMSE is :  ',train_rmse, valid_rmse)\n",
    "            torch.save(model.state_dict(), f'{save_path}/model_save_{epoch + 1}.pth')\n",
    "        # 检查学习率和耐心计数\n",
    "        if optimizer.param_groups[0]['lr'] <= min_lr and patience_counter >= 40:\n",
    "            print(\"Stopping training due to no improvement.\")\n",
    "            print(train_rmse, valid_rmse)\n",
    "            torch.save(model.state_dict(), f'{save_path}/model_save_{epoch + 1}.pth')\n",
    "            break\n",
    "    return model\n",
    "\n",
    "training(save_path='grid_search/GINE_h256_n1_l5',conv_type='GINE')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a693a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "metrics_df = pd.DataFrame(columns=['Epoch', 'Train_RMSE', 'R_square', 'Test_MAE', 'Test_RMSE'])\n",
    "def training(save_path='saves'):\n",
    "    # 创建保存目录\n",
    "    if not os.path.exists(save_path):\n",
    "        os.makedirs(save_path)\n",
    "    \n",
    "    # 初始化模型\n",
    "    model = GNNPredictor(node_dim=16, hidden_dim=256, num_layers=4, num_nodes=1, env_num=0, conv_type='GINE').to(device)\n",
    "    model.load_state_dict(torch.load(r'D:\\Jupyter\\IR-DIAZO-KETONE-main\\grid_search\\GINE_h256_n1\\epoch_625.pt')['model_state_dict'])\n",
    "\n",
    "    # 初始化优化器和损失函数\n",
    "    criterion_fn = torch.nn.MSELoss()\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=0.000001, weight_decay=0.0001)\n",
    "    \n",
    "    # 训练参数\n",
    "    patience = 25\n",
    "    best_loss = float('inf')\n",
    "    patience_counter = 0\n",
    "    min_lr = 0.000001\n",
    "    reduce_factor = 0.2\n",
    "\n",
    "    # 初始化DataFrame记录训练指标\n",
    "    \n",
    "    for epoch in tqdm(range(1000)):\n",
    "        # 训练\n",
    "        loss = train(model, device, train_graph_IR_loader, optimizer, criterion_fn)\n",
    "        \n",
    "        # 评估\n",
    "        # train_rmse = eval(model, device, train_graph_IR_loader)\n",
    "        _, _, R_square, test_mae, test_rmse = test(model, device, test_graph_IR_loader, 'valid_final')\n",
    "        \n",
    "        # 打印当前指标\n",
    "        print(f'Epoch {epoch + 1}: , R²: {R_square }, Test MAE: {test_mae }, Test RMSE: {test_rmse }')\n",
    "\n",
    "        # 记录指标到DataFrame\n",
    "        metrics_df.loc[len(metrics_df)] = {\n",
    "            'Epoch': epoch + 1,\n",
    "            # 'Train_RMSE': train_rmse,\n",
    "            'R_square': float(R_square),\n",
    "            'Test_MAE': float(test_mae),\n",
    "            'Test_RMSE':float(test_rmse)\n",
    "        }\n",
    "\n",
    "        # 保存模型和指标\n",
    "        torch.save(model.state_dict(), f'{save_path}/model_save_{epoch + 1}.pth')\n",
    "        \n",
    "\n",
    "        # 早停检查\n",
    "        if loss < best_loss:\n",
    "            best_loss = loss\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "\n",
    "        if R_square > 0.933:\n",
    "            print(f\"Stopping training due to high R² ({R_square} > 0.933).\")\n",
    "            # print(f\"Final Train RMSE: {train_rmse:.4f}, R²: {R_square:.4f}\")\n",
    "            torch.save(model.state_dict(), f'{save_path}/model_save_final.pth')\n",
    "            metrics_df.to_excel(f'{save_path}/training_metrics.xlsx', index=False)\n",
    "            break\n",
    "\n",
    "    return model\n",
    "\n",
    "# 调用训练函数\n",
    "training(save_path=r'saves\\fine_tune')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25690d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_df.to_excel(f'saves/fine_tune/training_metrics2.xlsx', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "044e0c4d",
   "metadata": {},
   "source": [
    "### interference test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "216a9a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_similarity(train_smiles, test_smiles):\n",
    "    \"\"\"计算训练集和测试集之间的Tanimoto相似度\"\"\"\n",
    "    train_fps = [AllChem.GetMorganFingerprint(Chem.MolFromSmiles(smile), 2) for smile in train_smiles]\n",
    "    test_fps = [AllChem.GetMorganFingerprint(Chem.MolFromSmiles(smile), 2) for smile in test_smiles]\n",
    "\n",
    "    similarity_scores = []\n",
    "    for test_fp in test_fps:\n",
    "        max_similarity = max(AllChem.DataStructs.TanimotoSimilarity(test_fp, train_fp) for train_fp in train_fps)\n",
    "        similarity_scores.append(max_similarity)\n",
    "    return similarity_scores\n",
    "\n",
    "def add_noise(data, noise_level):\n",
    "    noise = np.random.normal(0, noise_level * np.std(data), data.shape)\n",
    "    return data + noise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "655f8ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test_graph_IR_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88116828",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_smiles, test_smiles = [smile for batch in train_graph_IR_loader for smile in batch.smiles ], [mol.smiles for mol in test_graph_IR_dataset ]\n",
    "similarity_scores = calculate_similarity(train_smiles, test_smiles)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a0f9ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for score in similarity_scores:\n",
    "    if score <= 0.5:\n",
    "        i += 1\n",
    "i\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e22738d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# similarity\n",
    "similarity_threshold = [0.5,0.6,0.7,0.8,0.9,0.95]\n",
    "train_graph_IR_loader,valid_graph_IR_loader,test_graph_IR_loader,test_graph_IR_dataset=data_split(random_seed=42,train_ratio = 0.9,validate_ratio = 0.05,test_ratio=0.05)\n",
    "train_smiles, test_smiles = [smile for batch in train_graph_IR_loader for smile in batch.smiles ], [mol.smiles for mol in test_graph_IR_dataset ]\n",
    "similarity_scores = calculate_similarity(train_smiles, test_smiles)\n",
    "similarity_datasets ,metric = {} , {}\n",
    "for i,threshold in enumerate(similarity_threshold):\n",
    "    print('similaritu:',threshold)\n",
    "    similarity_datasets[threshold] = [j for j, score in enumerate(similarity_scores) if score > threshold]\n",
    "    subset = [test_graph_IR_dataset[idx] for idx in similarity_datasets[threshold]]\n",
    "    print(len(subset))\n",
    "    graph_IR_loader = DataLoader(subset, batch_size=128,shuffle=False, num_workers=1)\n",
    "    _,_,R_square,test_mae,test_rmse = test(model, device, graph_IR_loader,model_name='similarity_threshold_'+str(i))\n",
    "    metric[threshold]={'R_square': float(R_square),'MAE': float(test_mae),'RMSE': float(test_rmse)}\n",
    "df = pd.DataFrame(metric).T\n",
    "df.to_csv('interference_test/similarity.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44239071",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from matplotlib.ticker import FormatStrFormatter, FuncFormatter, MaxNLocator\n",
    "\n",
    "# 设置全局样式\n",
    "plt.style.use('seaborn')\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "# 读取数据\n",
    "df = pd.read_csv('interference_test/similarity.csv', index_col=0)\n",
    "\n",
    "# 创建图形 (6cm宽 × 7cm高)\n",
    "fig, axes = plt.subplots(3, 1, figsize=(6/2.54, 7/2.54), dpi=300, \n",
    "                         gridspec_kw={'hspace': 0.2})  # 关键修改：hspace控制子图\n",
    "# 自定义x轴百分比格式\n",
    "def percent_formatter(x, pos):\n",
    "    return f\">{int(x * 100)}%\"\n",
    "\n",
    "# 第一个子图 - R_square\n",
    "axes[0].scatter(df.index, df['R_square'], color=\"#1f53b4\", s=40, edgecolor='black', alpha=0.7, linewidths=0)\n",
    "axes[0].yaxis.set_major_formatter(FormatStrFormatter('%.2f'))\n",
    "axes[0].set_xticklabels([])  # 隐藏x轴标签\n",
    "for x, y in zip(df.index, df['R_square']):\n",
    "    axes[0].text(x, y + 0.003, f\"{y:.3f}\", ha='center', va='bottom', fontsize=7)\n",
    "\n",
    "# 第二个子图 - MAE\n",
    "axes[1].scatter(df.index, df['MAE'], color=\"#be5757\", s=40, edgecolor='black', alpha=0.7, linewidths=0)\n",
    "axes[1].yaxis.set_major_formatter(FormatStrFormatter('%.2f'))\n",
    "axes[1].set_xticklabels([])  # 隐藏x轴标签\n",
    "for x, y in zip(df.index, df['MAE']):\n",
    "    axes[1].text(x, y + 0.21, f\"{y:.3f}\", ha='center', va='bottom', fontsize=7)\n",
    "\n",
    "# 第三个子图 - RMSE\n",
    "axes[2].scatter(df.index, df['RMSE'], color=\"#70af78\", s=40, edgecolor='black', alpha=0.7, linewidths=0)\n",
    "axes[2].yaxis.set_major_formatter(FormatStrFormatter('%.2f'))\n",
    "axes[2].xaxis.set_major_formatter(FuncFormatter(percent_formatter))  # x轴百分比格式\n",
    "for x, y in zip(df.index, df['RMSE']):\n",
    "    axes[2].text(x, y + 0.4, f\"{y:.3f}\", ha='center', va='bottom', fontsize=7)\n",
    "\n",
    "# 统一设置所有子图的样式\n",
    "for ax in axes:\n",
    "    # 网格和背景\n",
    "    ax.grid(True, color='white', linestyle='-', linewidth=1, alpha=0.7, zorder=1)\n",
    "    ax.set_facecolor(\"#CCCBCB7D\")\n",
    "    \n",
    "    # 边框和刻度\n",
    "    for spine in ax.spines.values():\n",
    "        spine.set_visible(False)\n",
    "    ax.tick_params(axis='both', which='both', length=0, labelsize=8)  # 刻度字体大小\n",
    "    ax.set_xticks(df.index)  # 直接使用数据中的x值作为刻度\n",
    "    # 控制x轴主刻度数量 (5个) 并保持垂直网格线\n",
    "    \n",
    "    # 调整y轴范围\n",
    "    y_min, y_max = ax.get_ylim()\n",
    "    padding = (y_max - y_min) * 0.3\n",
    "    ax.set_ylim(y_min - padding, y_max + padding)\n",
    "    x_min, x_max = ax.get_xlim()\n",
    "    x_padding = (x_max - x_min) * 0.1   # x轴扩展比例（较小，避免过度空白）\n",
    "    ax.set_xlim(x_min - x_padding, x_max + x_padding)\n",
    "# 调整布局并保存\n",
    "plt.tight_layout()\n",
    "plt.savefig('interference_test/similarity.pdf', bbox_inches='tight', dpi=300)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ba3480",
   "metadata": {},
   "outputs": [],
   "source": [
    "# noise level\n",
    "noise_level = [i/20 for i in range(6)]\n",
    "metric = {}\n",
    "for i in noise_level:\n",
    "    print('noise_level:',i)\n",
    "    graph_IR_dataset = CarbonylIRDataset(df_unique['Canonical_SMILES'],df_unique['IR_Characteristic_Peak'],df_unique['DOI'],noise_level= i)\n",
    "    torch.save(graph_IR_dataset, f'dataset/graph_IR_dataset_neighbor_noise_{i}.pt')\n",
    "    train_graph_IR_loader,valid_graph_IR_loader,test_graph_IR_loader=data_split(random_seed=42,train_ratio = 0.9,validate_ratio = 0.05,test_ratio=0.05)\n",
    "    model = training(save_path=r'interference_test\\noise_level_'+str(i))\n",
    "    _,_,R_square,test_mae,test_rmse = test(model, device, test_graph_IR_loader,model_name='training_data_ratio_'+str(i))\n",
    "    metric[f'{i}']={'R_square': float(R_square),'MAE': float(test_mae),'RMSE': float(test_rmse)}\n",
    "df = pd.DataFrame(metric)\n",
    "df.to_csv('interference_test/noise_level.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "874dd8c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from matplotlib.ticker import FormatStrFormatter, FuncFormatter  # 导入格式化工具\n",
    "plt.style.use('seaborn')\n",
    "df = pd.read_csv('interference_test/noise_level.csv', index_col=0)\n",
    "numerical_cols = df.select_dtypes(include=['float64', 'int64']).columns\n",
    "print(type(numerical_cols),numerical_cols)\n",
    "# 创建一个3行1列的图形\n",
    "# 创建图形 (5英寸×5英寸)，设置紧凑子图间距\n",
    "fig, axes = plt.subplots(3, 1, figsize=(6/2.54, 7/2.54), dpi=300, \n",
    "                        gridspec_kw={'hspace': 0.2})\n",
    "\n",
    "# 第一个子图 - R_square\n",
    "axes[0].scatter(df.index, df['R_square'], color=\"#1f53b4\", s=40, \n",
    "               edgecolor='black', alpha=0.7, linewidths=0, zorder=2)\n",
    "axes[0].yaxis.set_major_formatter(FormatStrFormatter('%.2f'))\n",
    "axes[0].set_xticklabels([])  # 隐藏x轴标签\n",
    "for x, y in zip(df.index, df['R_square']):\n",
    "    axes[0].text(x, y + 0.005, f\"{y:.3f}\", ha='center', va='bottom', \n",
    "                fontsize=7, zorder=3)\n",
    "\n",
    "# 第二个子图 - MAE\n",
    "axes[1].scatter(df.index, df['MAE'], color=\"#be5757\", s=40, \n",
    "               edgecolor='black', alpha=0.7, linewidths=0, zorder=2)\n",
    "axes[1].yaxis.set_major_formatter(FormatStrFormatter('%.2f'))\n",
    "axes[1].set_xticklabels([])  # 隐藏x轴标签\n",
    "for x, y in zip(df.index, df['MAE']):\n",
    "    axes[1].text(x, y + 0.3, f\"{y:.3f}\", ha='center', va='bottom', \n",
    "                fontsize=7, zorder=3)\n",
    "\n",
    "    \n",
    "# 第三个子图 - RMSE\n",
    "axes[2].scatter(df.index, df['RMSE'], color=\"#70af78\", s=40, \n",
    "               edgecolor='black', alpha=0.7, linewidths=0, zorder=2)\n",
    "axes[2].yaxis.set_major_formatter(FormatStrFormatter('%.2f'))\n",
    "for x, y in zip(df.index, df['RMSE']):\n",
    "    axes[2].text(x, y + 0.4, f\"{y:.3f}\", ha='center', va='bottom', \n",
    "                fontsize=7, zorder=3)\n",
    "\n",
    "# 统一设置所有子图样式\n",
    "for ax in axes:\n",
    "    # 网格和背景\n",
    "    ax.grid(True, color='white', linestyle='-', linewidth=1, alpha=0.7, zorder=1)\n",
    "    ax.set_facecolor(\"#CCCBCB7D\")\n",
    "    \n",
    "    # 边框和刻度\n",
    "    for spine in ax.spines.values():\n",
    "        spine.set_visible(False)\n",
    "    ax.set_xticks(df.index)  # 直接使用数据中的x值作为刻度\n",
    "    ax.tick_params(axis='both', which='major', labelsize=8, length=0)  # 刻度字体大小\n",
    "    # 同步扩大x轴和y轴范围\n",
    "    y_min, y_max = ax.get_ylim()\n",
    "    y_padding = (y_max - y_min) * 0.3\n",
    "    ax.set_ylim(y_min - y_padding, y_max + y_padding)\n",
    "    \n",
    "    x_min, x_max = ax.get_xlim()\n",
    "    x_padding = (x_max - x_min) * 0.04\n",
    "    ax.set_xlim(x_min - x_padding, x_max + x_padding)\n",
    "plt.tight_layout()\n",
    "plt.savefig('interference_test/noise_level.pdf', bbox_inches='tight', dpi=300)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f6c4d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training data radio\n",
    "training_data_ratio = [0.1,0.3,0.5,0.7,0.9]\n",
    "metric= {}\n",
    "for i in training_data_ratio:\n",
    "    print('training_data_ratio:',i)\n",
    "    train_graph_IR_loader,valid_graph_IR_loader,test_graph_IR_loader=data_split(random_seed=42,train_ratio = i,validate_ratio = 0.5-i/2,test_ratio=0.5-i/2)\n",
    "    model = training(save_path=r'interference_test\\training_data_ratio_'+str(i))\n",
    "    _,_,R_square,test_mae,test_rmse = test(model, device, test_graph_IR_loader,model_name='training_data_ratio_'+str(i))\n",
    "    metric[f'{i}']={'R_square': float(R_square),'MAE': float(test_mae),'RMSE': float(test_rmse)}\n",
    "df = pd.DataFrame(metric)\n",
    "df.to_csv('interference_test/training_ratio.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "871323be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from matplotlib.ticker import FormatStrFormatter, MaxNLocator\n",
    "\n",
    "# 设置全局样式\n",
    "plt.style.use('seaborn')\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "# 读取数据\n",
    "df = pd.read_csv('interference_test/training_ratio.csv', index_col=0)\n",
    "\n",
    "# 创建图形 (5英寸×5英寸)，设置紧凑子图间距\n",
    "fig, axes = plt.subplots(3, 1, figsize=(6/2.54, 7/2.54), dpi=300, \n",
    "                        gridspec_kw={'hspace': 0.2})\n",
    "\n",
    "# 第一个子图 - R_square\n",
    "axes[0].scatter(df.index, df['R_square'], color=\"#1f53b4\", s=40, \n",
    "               edgecolor='black', alpha=0.7, linewidths=0, zorder=2)\n",
    "axes[0].yaxis.set_major_formatter(FormatStrFormatter('%.2f'))\n",
    "axes[0].set_xticklabels([])  # 隐藏x轴标签\n",
    "for x, y in zip(df.index, df['R_square']):\n",
    "    axes[0].text(x, y + 0.009, f\"{y:.3f}\", ha='center', va='bottom', \n",
    "                fontsize=7, zorder=3)\n",
    "\n",
    "# 第二个子图 - MAE\n",
    "axes[1].scatter(df.index, df['MAE'], color=\"#be5757\", s=40, \n",
    "               edgecolor='black', alpha=0.7, linewidths=0, zorder=2)\n",
    "axes[1].yaxis.set_major_formatter(FormatStrFormatter('%.2f'))\n",
    "axes[1].set_xticklabels([])  # 隐藏x轴标签\n",
    "for x, y in zip(df.index, df['MAE']):\n",
    "    axes[1].text(x, y + 0.27, f\"{y:.3f}\", ha='center', va='bottom', \n",
    "                fontsize=7, zorder=3)\n",
    "\n",
    "    \n",
    "# 第三个子图 - RMSE\n",
    "axes[2].scatter(df.index, df['RMSE'], color=\"#70af78\", s=40, \n",
    "               edgecolor='black', alpha=0.7, linewidths=0, zorder=2)\n",
    "axes[2].yaxis.set_major_formatter(FormatStrFormatter('%.2f'))\n",
    "for x, y in zip(df.index, df['RMSE']):\n",
    "    axes[2].text(x, y + 0.6, f\"{y:.3f}\", ha='center', va='bottom', \n",
    "                fontsize=7, zorder=3)\n",
    "\n",
    "# 统一设置所有子图样式\n",
    "for ax in axes:\n",
    "    # 网格和背景\n",
    "    ax.grid(True, color='white', linestyle='-', linewidth=1, alpha=0.7, zorder=1)\n",
    "    ax.set_facecolor(\"#CCCBCB7D\")\n",
    "    \n",
    "    # 边框和刻度\n",
    "    for spine in ax.spines.values():\n",
    "        spine.set_visible(False)\n",
    "    ax.set_xticks(df.index)  # 直接使用数据中的x值作为刻度\n",
    "    ax.tick_params(axis='both', which='major', labelsize=8, length=0)  # 刻度字体大小\n",
    "    # 同步扩大x轴和y轴范围\n",
    "    y_min, y_max = ax.get_ylim()\n",
    "    y_padding = (y_max - y_min) * 0.25\n",
    "    ax.set_ylim(y_min - y_padding, y_max + y_padding)\n",
    "    \n",
    "    x_min, x_max = ax.get_xlim()\n",
    "    x_padding = (x_max - x_min) * 0.1\n",
    "    ax.set_xlim(x_min - x_padding, x_max + x_padding)\n",
    "\n",
    "# 保存高清图像\n",
    "plt.tight_layout()\n",
    "plt.savefig('interference_test/training_ratio.pdf', bbox_inches='tight', dpi=300)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "041e8834",
   "metadata": {},
   "source": [
    "### grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e6073c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 绑定的超参数组合\n",
    "param_combinations = [\n",
    "    {'hidden_dim': 128, 'node_num': 2},\n",
    "    {'hidden_dim': 256, 'node_num': 1}\n",
    "]\n",
    "\n",
    "# 卷积类型列表\n",
    "conv_types = ['GATE', 'GAT', 'GCNE', 'GCN', 'GIN', 'GINE']\n",
    "\n",
    "# 训练配置\n",
    "train_config = {\n",
    "    'num_layers': 4,\n",
    "    'initial_lr': 0.01,\n",
    "    'min_lr': 1e-6,\n",
    "    'patience': 30,\n",
    "    'reduce_factor': 0.5,\n",
    "    'epochs': 1000,\n",
    "    'eval_interval': 25  # 验证间隔\n",
    "}\n",
    "\n",
    "# 主结果目录\n",
    "os.makedirs(\"grid11_search\", exist_ok=True)\n",
    "\n",
    "for params in tqdm(param_combinations, desc='Hyperparameter Combinations'):\n",
    "    hidden_dim = params['hidden_dim']\n",
    "    node_num = params['node_num']\n",
    "    \n",
    "    for conv_type in tqdm(conv_types, desc=f'h{hidden_dim}_n{node_num}', leave=False):\n",
    "        # 创建模型专属目录\n",
    "        model_name = f\"{conv_type}_h{hidden_dim}_n{node_num}\"\n",
    "        save_dir = f\"grid_search/{model_name}\"\n",
    "        os.makedirs(save_dir, exist_ok=True)\n",
    "        \n",
    "        # 初始化模型和优化器\n",
    "        model = GNNPredictor(\n",
    "            node_dim=16,\n",
    "            edge_dim=5,\n",
    "            hidden_dim=hidden_dim,\n",
    "            num_layers=train_config['num_layers'],\n",
    "            num_nodes=node_num,\n",
    "            conv_type=conv_type\n",
    "        ).to(device)\n",
    "        \n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=train_config['initial_lr'])\n",
    "        criterion_fn = torch.nn.MSELoss()\n",
    "        \n",
    "        # 初始化当前配置的结果DataFrame\n",
    "        config_results = pd.DataFrame(columns=[\n",
    "            'epoch', 'train_rmse', 'valid_rmse', 'lr', 'model_path'\n",
    "        ])\n",
    "        \n",
    "        # 训练变量初始化\n",
    "        current_lr = train_config['initial_lr']\n",
    "        patience_counter = 0\n",
    "        best_loss = float('inf')\n",
    "        \n",
    "        # 训练循环\n",
    "        for epoch in range(train_config['epochs']):\n",
    "            # 训练步骤\n",
    "            loss = train(model, device, train_graph_IR_loader, optimizer, criterion_fn)\n",
    "            \n",
    "            # 学习率调整\n",
    "            if loss < best_loss:\n",
    "                best_loss = loss\n",
    "                patience_counter = 0\n",
    "            else:\n",
    "                patience_counter += 1\n",
    "                \n",
    "            if patience_counter >= train_config['patience']:\n",
    "                current_lr = max(current_lr * train_config['reduce_factor'], train_config['min_lr'])\n",
    "                for param_group in optimizer.param_groups:\n",
    "                    param_group['lr'] = current_lr\n",
    "                if current_lr > train_config['min_lr']:\n",
    "                    patience_counter = 0\n",
    "            \n",
    "            # 验证步骤\n",
    "            if (epoch + 1) % train_config['eval_interval'] == 0 :\n",
    "                train_rmse = eval(model, device, train_graph_IR_loader)\n",
    "                valid_rmse = eval(model, device, valid_graph_IR_loader)\n",
    "                \n",
    "                # 保存模型参数\n",
    "                checkpoint_path = f\"{save_dir}/epoch_{epoch+1}.pt\"\n",
    "                torch.save(model.state_dict(),checkpoint_path)\n",
    "                \n",
    "                # 记录当前配置结果\n",
    "                config_results.loc[len(config_results)] = {\n",
    "                    'epoch': epoch + 1,\n",
    "                    'train_rmse': train_rmse,\n",
    "                    'valid_rmse': valid_rmse,\n",
    "                    'lr': current_lr,\n",
    "                    'model_path': checkpoint_path\n",
    "                }\n",
    "                \n",
    "                # 实时保存当前配置结果\n",
    "                config_results.to_excel(f\"{save_dir}/training_log.xlsx\", index=False)\n",
    "            \n",
    "            # 早停检查\n",
    "            if current_lr <= train_config['min_lr'] and patience_counter >= 50:\n",
    "                break\n",
    "\n",
    "        # 保存最终配置摘要\n",
    "        summary = {\n",
    "            'conv_type': conv_type,\n",
    "            'hidden_dim': hidden_dim,\n",
    "            'node_num': node_num,\n",
    "            'final_epoch': epoch + 1,\n",
    "            'final_train_rmse': train_rmse,\n",
    "            'final_valid_rmse': valid_rmse,\n",
    "            'min_train_rmse': config_results['train_rmse'].min(),\n",
    "            'min_valid_rmse': config_results['valid_rmse'].min()\n",
    "        }\n",
    "        pd.DataFrame([summary]).to_excel(f\"{save_dir}/config_summary.xlsx\", index=False)\n",
    "\n",
    "print(\"\\nAll configurations completed! Results saved in respective directories.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7169b794",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 卷积类型列表\n",
    "# conv_types = ['GIN', 'GINE','GAT', 'GCNE', 'GCN','GATE', ]\n",
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 超参数组合网格\n",
    "param_grid = {\n",
    "    'hidden_dim': [256,200],\n",
    "    'num_nodes': [2],\n",
    "    'num_layers': [3, 4, 5],\n",
    "    'conv_type': ['GINE']\n",
    "}\n",
    "\n",
    "# 训练配置\n",
    "train_config = {\n",
    "    'initial_lr': 0.01,\n",
    "    'min_lr': 1e-6,\n",
    "    'patience': 25,\n",
    "    'reduce_factor': 0.2,\n",
    "    'epochs': 1000,\n",
    "    'eval_interval': 25  # 验证间隔\n",
    "}\n",
    "\n",
    "# 主结果目录\n",
    "os.makedirs(\"grid_search\", exist_ok=True)\n",
    "\n",
    "# 生成所有参数组合\n",
    "all_params = []\n",
    "for hd in param_grid['hidden_dim']:\n",
    "    for n_n in param_grid['num_nodes']:\n",
    "        for nl in param_grid['num_layers']:\n",
    "            for ct in param_grid['conv_type']:\n",
    "                all_params.append({\n",
    "                    'hidden_dim': hd,\n",
    "                    'num_nodes': n_n,\n",
    "                    'num_layers': nl,\n",
    "                    'conv_type': ct\n",
    "                })\n",
    "\n",
    "for params in tqdm(all_params, desc='Grid Search Progress'):\n",
    "    hidden_dim = int(params['hidden_dim'])\n",
    "    num_nodes = int(params['num_nodes'])\n",
    "    num_layers = int(params['num_layers'])\n",
    "    conv_type = str(params['conv_type'])\n",
    "    # # 创建模型专属目录\n",
    "    model_name = f\"{conv_type}_h{hidden_dim}_n{num_nodes}_l{num_layers}\"\n",
    "    save_dir = f\"grid_search/{model_name}\"\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    \n",
    "    # 初始化模型和优化器\n",
    "    model = GNNPredictor(\n",
    "        node_dim=16,\n",
    "        edge_dim=5,\n",
    "        hidden_dim=hidden_dim,\n",
    "        num_layers=num_layers,\n",
    "        num_nodes=num_nodes,\n",
    "        env_num=0,\n",
    "        conv_type=conv_type\n",
    "    ).to(device)\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=train_config['initial_lr'])\n",
    "    criterion_fn = torch.nn.MSELoss()\n",
    "    \n",
    "    # 初始化当前配置的结果DataFrame\n",
    "    config_results = pd.DataFrame(columns=[\n",
    "        'epoch', 'train_rmse', 'valid_rmse', 'lr', 'model_path'\n",
    "    ])\n",
    "    \n",
    "    # 训练变量初始化\n",
    "    current_lr = train_config['initial_lr']\n",
    "    patience_counter = 0\n",
    "    best_loss = float('inf')\n",
    "    \n",
    "    # 训练循环\n",
    "    for epoch in range(train_config['epochs']):\n",
    "        # 训练步骤\n",
    "        loss = train(model, device, train_graph_IR_loader, optimizer, criterion_fn)\n",
    "        \n",
    "        # 学习率调整\n",
    "        if loss < best_loss:\n",
    "            best_loss = loss\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            \n",
    "        if patience_counter >= train_config['patience']:\n",
    "            current_lr = max(current_lr * train_config['reduce_factor'], train_config['min_lr'])\n",
    "            for param_group in optimizer.param_groups:\n",
    "                param_group['lr'] = current_lr\n",
    "            if current_lr > train_config['min_lr']:\n",
    "                patience_counter = 0\n",
    "        \n",
    "        # 验证步骤\n",
    "        if (epoch + 1) % train_config['eval_interval'] == 0:\n",
    "            train_rmse = eval(model, device, train_graph_IR_loader)\n",
    "            valid_rmse = eval(model, device, valid_graph_IR_loader)\n",
    "            \n",
    "            # 保存模型参数\n",
    "            checkpoint_path = f\"{save_dir}/epoch_{epoch+1}.pt\"\n",
    "            torch.save(model.state_dict(), checkpoint_path)\n",
    "            \n",
    "            # 记录当前配置结果\n",
    "            config_results.loc[len(config_results)] = {\n",
    "                'epoch': epoch + 1,\n",
    "                'train_rmse': train_rmse,\n",
    "                'valid_rmse': valid_rmse,\n",
    "                'lr': current_lr,\n",
    "                'model_path': checkpoint_path\n",
    "            }\n",
    "            \n",
    "            # 实时保存当前配置结果\n",
    "            config_results.to_excel(f\"{save_dir}/training_log.xlsx\", index=False)\n",
    "        \n",
    "        # 早停检查\n",
    "        if current_lr <= train_config['min_lr'] and patience_counter >= 40:\n",
    "            break\n",
    "\n",
    "    # 保存最终配置摘要\n",
    "    summary = {\n",
    "        'conv_type': conv_type,\n",
    "        'hidden_dim': hidden_dim,\n",
    "        'num_nodes': num_nodes,\n",
    "        'num_layers': num_layers,\n",
    "        'final_epoch': epoch + 1,\n",
    "        'final_train_rmse': train_rmse,\n",
    "        'final_valid_rmse': valid_rmse,\n",
    "        'min_train_rmse': config_results['train_rmse'].min(),\n",
    "        'min_valid_rmse': config_results['valid_rmse'].min()\n",
    "    }\n",
    "    pd.DataFrame([summary]).to_excel(f\"{save_dir}/config_summary.xlsx\", index=False)\n",
    "\n",
    "print(\"\\nAll configurations completed! Results saved in respective directories.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dff48b26",
   "metadata": {},
   "source": [
    "## metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e7823c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mname = 'ablation/GIN/model_save_50.pth'   #GINE_h128_n2   GINE_h256_n1\n",
    "mpname = mname.split('/')[1]\n",
    "model = GNNPredictor(node_dim=7, hidden_dim=256,num_layers=4,num_nodes=1,env_num=0,conv_type=mpname).to(device)\n",
    "model.load_state_dict(torch.load(mname))\n",
    "test(model, device, test_graph_IR_loader,model_name='GATE')\n",
    "# model = GNNPredictor(hidden_dim=128,num_layers=4,num_nodes=2,env_num=0,conv_type='GINE').to(device)\n",
    "# model.load_state_dict(torch.load('saves/model_save_24.pth'))\n",
    "# train_mae = eval(model, device, train_graph_IR_loader)\n",
    "# valid_mae = eval(model, device, valid_graph_IR_loader)\n",
    "# print(train_mae, valid_mae)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f727f533",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GNNPredictor(hidden_dim=256,num_layers=5,num_nodes=1,env_num=0,conv_type='GINE').to(device)\n",
    "model.load_state_dict(torch.load('grid_search/GINE_h256_n1_l5/model_save_175.pth'))\n",
    "test(model, device, test_graph_IR_loader,model_name='GATE')\n",
    "# train_mae = eval(model, device, train_graph_IR_loader)\n",
    "# valid_mae = eval(model, device, valid_graph_IR_loader)\n",
    "# print(train_mae, valid_mae)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab7ee5f1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "result= pd.DataFrame(index=['test_mae','R_square','test_rmse'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77736a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "result[f'{mpname}']=[test_mae.item(),R_square.item(),test_rmse.item()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea682ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.T.to_excel('grid_search/result.xlsx', index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44aa330c",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), f'saves/model_save_{232}.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33a9198e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "from collections import defaultdict\n",
    "\n",
    "# 假设你已经定义了 GNNPredictor 类、test 函数和绘图函数\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "def find_best_models(grid_search_dir='grid_search'):\n",
    "    # 存储所有模型配置的结果\n",
    "    results = defaultdict(list)\n",
    "    \n",
    "    # 获取所有模型配置文件夹\n",
    "    model_dirs = glob(os.path.join(grid_search_dir, 'GINE_*'))\n",
    "    \n",
    "    for model_dir in tqdm(model_dirs, desc='Processing model configurations'):\n",
    "        # 解析模型配置参数\n",
    "        mpname = os.path.basename(model_dir)\n",
    "        parts = mpname.split('_')\n",
    "        conv_type = parts[0]\n",
    "        hidden_dim = int(parts[1][1:])  # 去掉'h'后转int\n",
    "        num_nodes = int(parts[2][1:])   # 去掉'n'后转int\n",
    "        \n",
    "        # 获取该配置下所有epoch文件\n",
    "        epoch_files = glob(os.path.join(model_dir, 'epoch_*.pt'))\n",
    "        \n",
    "        best_r2 = -float('inf')\n",
    "        best_metrics = None\n",
    "        best_epoch_file = None\n",
    "        best_y_pred = None\n",
    "        best_y_true = None\n",
    "        \n",
    "        for epoch_file in tqdm(epoch_files, desc=f'Testing {mpname}', leave=False):\n",
    "            # 加载模型\n",
    "            model = GNNPredictor(\n",
    "                hidden_dim=hidden_dim,\n",
    "                num_layers=4,  # 根据你的实际情况调整\n",
    "                num_nodes=num_nodes,\n",
    "                env_num=0,\n",
    "                conv_type=conv_type\n",
    "            ).to(device)\n",
    "            \n",
    "            try:\n",
    "                state_dict = torch.load(epoch_file, map_location=device)\n",
    "                model.load_state_dict(state_dict['model_state_dict'])\n",
    "                \n",
    "                # 测试模型\n",
    "                y_pred, y_true, R_square, test_mae, test_rmse = test(\n",
    "                    model, device, test_graph_IR_loader, mpname\n",
    "                )\n",
    "                \n",
    "                # 更新最佳结果\n",
    "                if R_square > best_r2:\n",
    "                    best_r2 = R_square\n",
    "                    best_metrics = {\n",
    "                        'epoch': os.path.basename(epoch_file),\n",
    "                        'R_square': R_square,\n",
    "                        'test_mae': test_mae,\n",
    "                        'test_rmse': test_rmse\n",
    "                    }\n",
    "                    best_epoch_file = epoch_file\n",
    "                    best_y_pred = y_pred\n",
    "                    best_y_true = y_true\n",
    "            \n",
    "            except Exception as e:\n",
    "                print(f\"Error loading {epoch_file}: {str(e)}\")\n",
    "                continue\n",
    "        \n",
    "        if best_metrics:\n",
    "            # 保存最佳模型的散点图\n",
    "            model_name = f\"{mpname}_{best_metrics['epoch'].replace('.pt', '')}\"\n",
    "            \n",
    "            fig = plot_prediction_scatter(\n",
    "                best_y_true, best_y_pred, model_name, \n",
    "                figsize=(6/2.54, 6/2.54), alpha=0.2\n",
    "            )\n",
    "            fig.savefig(f'333/{model_name}.pdf', bbox_inches='tight', dpi=300)\n",
    "            plt.close(fig)\n",
    "            \n",
    "            fig = plot_prediction_scatter2(\n",
    "                best_y_true, best_y_pred, model_name, \n",
    "                figsize=(6/2.54, 6/2.54), alpha=0.2\n",
    "            )\n",
    "            fig.savefig(f'333/{model_name}_2.pdf', bbox_inches='tight', dpi=300)\n",
    "            plt.close(fig)\n",
    "            \n",
    "            # 记录结果\n",
    "            results['model_config'].append(mpname)\n",
    "            results['best_epoch'].append(best_metrics['epoch'])\n",
    "            results.update({\n",
    "                k: [v] for k, v in best_metrics.items() if k != 'epoch'\n",
    "            })\n",
    "    \n",
    "    # 转换为DataFrame并保存\n",
    "    df_results = pd.DataFrame(results)\n",
    "    df_results.to_csv('333/best_model_results.csv', index=False)\n",
    "    return df_results\n",
    "\n",
    "# 运行函数\n",
    "best_models_df = find_best_models()\n",
    "print(best_models_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f2dabf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_pred, y_true,R_square,test_mae,test_rmse = test(model, device, test_graph_IR_loader,'ne-GINE')\n",
    "print(float(R_square),float(test_mae),float(test_rmse))\n",
    "# for i in range(len(y_pred)):\n",
    "#     print(i,y_pred[i], y_true[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa79ae86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(y_true, y_pred):\n",
    "    r2 = 1 - (((y_true - y_pred) ** 2).sum() / ((y_true - y_true.mean()) ** 2).sum())\n",
    "    mae = torch.mean(torch.abs(y_true - y_pred))\n",
    "    rmse = torch.sqrt(torch.mean((y_true - y_pred) ** 2))\n",
    "    return rmse, mae, r2\n",
    "def plot_prediction_scatter(y_true, y_pred, model_name='GNN', figsize=(9/2.54, 9/2.54), alpha=0.2):\n",
    "    # 确保 y_true 和 y_pred 是张量\n",
    "    # y_true = torch.tensor(y_true)\n",
    "    # y_pred = torch.tensor(y_pred)\n",
    "    \n",
    "    # 创建图形\n",
    "    fig, ax = plt.subplots(figsize=figsize, dpi=300)\n",
    "    \n",
    "    # 设置背景色（浅灰色半透明）\n",
    "    ax.set_facecolor(\"#CCCBCB7D\")\n",
    "    # 设置网格线（白色半透明）\n",
    "    ax.grid(True, color='white', linestyle='-', linewidth=1, alpha=0.7, zorder=1)\n",
    "    # Scatter plot\n",
    "    ax.scatter(y_true.numpy(), y_pred.numpy(),color=\"#A511116F\", alpha=alpha, zorder=2)\n",
    "    \n",
    "    # Perfect prediction line\n",
    "    min_val = min(y_true.min().item(), y_pred.min().item())\n",
    "    max_val = max(y_true.max().item(), y_pred.max().item())\n",
    "    ax.plot([min_val, max_val], [min_val, max_val],color='black', linestyle='--', zorder=2)\n",
    "    \n",
    "    # 移除所有边框\n",
    "    for spine in ax.spines.values():\n",
    "        spine.set_visible(False)\n",
    "    # 隐藏刻度线\n",
    "    ax.tick_params(axis='both', which='both', length=0)\n",
    "    \n",
    "    # Labels and title\n",
    "    rmse, _, r2 = evaluate_model(y_true, y_pred)\n",
    "    # ax.legend(title=f'$R^2$={r2:.6f}\\nRMSE={rmse:.6f}',frameon=False,title_fontsize=12,fontsize=10,borderpad=1.2)\n",
    "    legend = ax.legend(title=f'$R^2$={r2:.3f}\\nRMSE={rmse:.3f}',\n",
    "                      frameon=False, title_fontsize=10, fontsize=10, borderpad=1.2)\n",
    "    legend.get_title().set_color(\"#710C0C6D\")\n",
    "    # ax.set_xlabel('Observed Value (cm$^{-1}$)')\n",
    "    # ax.set_ylabel('Predicted Value (cm$^{-1}$)')\n",
    "    ax.set_title(model_name,fontsize=8)\n",
    "    plt.yticks(fontsize=8)\n",
    "    plt.xticks(fontsize=8)\n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "def plot_prediction_scatter2(y_true, y_pred, model_name='GNN', figsize=(9/2.54, 9/2.54), alpha=0.2):\n",
    "    # 确保 y_true 和 y_pred 是张量\n",
    "    # y_true = torch.tensor(y_true)\n",
    "    # y_pred = torch.tensor(y_pred)\n",
    "    \n",
    "    # 创建图形\n",
    "    fig, ax = plt.subplots(figsize=figsize, dpi=300)\n",
    "    # 设置网格线（白色半透明）\n",
    "    ax.grid(True, color='white', linestyle='-', linewidth=1, alpha=0.7, zorder=1)\n",
    "    # 移除所有边框\n",
    "    for spine in ax.spines.values():\n",
    "        spine.set_visible(False)\n",
    "    # 隐藏刻度线\n",
    "    ax.tick_params(axis='both', which='both', length=0)\n",
    "    # 设置背景色（浅灰色半透明）\n",
    "    ax.set_facecolor(\"#CCCBCB7D\")\n",
    "\n",
    "    # Scatter plot\n",
    "    ax.scatter(y_true, y_pred, alpha=alpha, zorder=2)\n",
    "    \n",
    "    # Perfect prediction line\n",
    "    min_val = min(y_true.min().item(), y_pred.min().item())\n",
    "    max_val = max(y_true.max().item(), y_pred.max().item())\n",
    "    ax.plot([min_val, max_val], [min_val, max_val],color='black', linestyle='--', zorder=2)\n",
    "    \n",
    "    # Labels and title\n",
    "    rmse, _, r2 = evaluate_model(y_true, y_pred)\n",
    "    # ax.legend(title=f'$R^2$={r2:.6f}\\nRMSE={rmse:.6f}',frameon=False,title_fontsize=12,fontsize=10,borderpad=1.2)\n",
    "    legend = ax.legend(title=f'$R^2$={r2:.3f}\\nRMSE={rmse:.3f}',\n",
    "                      frameon=False, title_fontsize=10, fontsize=10, borderpad=1.2)\n",
    "    # legend.get_title().set_color(\"#8A0F0F6E\")\n",
    "    # ax.set_xlabel('Observed Value (cm$^{-1}$)')\n",
    "    # ax.set_ylabel('Predicted Value (cm$^{-1}$)')\n",
    "    ax.set_title(model_name,fontsize=8)\n",
    "    plt.yticks(fontsize=8)\n",
    "    plt.xticks(fontsize=8)\n",
    "    plt.tight_layout()\n",
    "    return fig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da5941e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all data\n",
    "data_source = 'experiment'\n",
    "graph_IR_list = []\n",
    "for i in range(len(graph_IR_dataset)):\n",
    "    graph_IR_list.append(graph_IR_dataset[i])\n",
    "graph_IR_loader = DataLoader(graph_IR_list, batch_size=128,shuffle=False, num_workers=1)\n",
    "y_pred, y_true, _, _ ,_ = test(model, device, graph_IR_loader,'GNN')\n",
    "df_unique['y_true']= y_true\n",
    "df_unique['y_test_pred']=y_pred\n",
    "df_unique['difference']=np.abs(y_true-y_pred)\n",
    "need_feature=['DOI','SMILES','IUPAC_NAME','IR_Characteristic_Peak','y_true','y_test_pred','difference']\n",
    "data1=df_unique[need_feature]\n",
    "data1.to_csv(f'test_data1_{data_source}_{total_num}.csv')\n",
    "data1[data1['difference'] > 30].to_csv(f'test_data1_{data_source}_{total_num}_bad_pre.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd1b3a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# 读取Excel文件\n",
    "df = pd.read_excel(r'D:\\Jupyter\\IR-DIAZO-KETONE-main\\grid_search1\\result111 - 副本.xlsx', index_col=0)\n",
    "\n",
    "# 获取模型名称和对应的性能指标\n",
    "models = [model.split('_')[0] for model in df.index.tolist()]\n",
    "r_square = df['R_square'].tolist()\n",
    "test_rmse = df['test_rmse'].tolist()\n",
    "\n",
    "# 将数据转换为DataFrame并按RMSE升序排序\n",
    "data = pd.DataFrame({\n",
    "    'Model': models,\n",
    "    'R_square': r_square,\n",
    "    'RMSE': test_rmse\n",
    "}).sort_values('RMSE', ascending=False)  # 按RMSE升序排序\n",
    "\n",
    "# 更新排序后的数据\n",
    "models_sorted = data['Model'].tolist()\n",
    "r_square_sorted = data['R_square'].tolist()\n",
    "test_rmse_sorted = data['RMSE'].tolist()\n",
    "\n",
    "# 计算柱子的位置\n",
    "x = np.arange(len(models_sorted))\n",
    "bar_width = 0.4\n",
    "\n",
    "# 创建图形\n",
    "fig, ax1 = plt.subplots(figsize=(9/2.54, 8/2.54), dpi=300)\n",
    "plt.rcParams['figure.dpi'] = 300\n",
    "\n",
    "# 设置背景色和网格线\n",
    "ax1.set_facecolor(\"#CCCBCB7D\")\n",
    "ax1.grid(True, color='white', linestyle='-', linewidth=1, alpha=0.7, zorder=1)\n",
    "\n",
    "# 绘制test_rmse的柱状图（按RMSE升序排列）\n",
    "# 修改点1：柱状图颜色改为 skyblue\n",
    "bars = ax1.bar(x, test_rmse_sorted, bar_width, label='RMSE', color=\"#789FDA\", zorder=2)\n",
    "# ax1.set_ylabel('RMSE')\n",
    "ax1.set_xticks(x)\n",
    "ax1.set_xticklabels(models_sorted)\n",
    "ax1.legend(loc='upper left')\n",
    "plt.yticks(fontsize=8)\n",
    "plt.xticks(fontsize=8)  # 旋转标签避免重叠\n",
    "ax1.tick_params(axis='x', which='both', length=0)  # 刻度线长度设为0\n",
    "ax1.tick_params(axis='y', which='both', length=1.2)  # 刻度线长度设为0\n",
    "# ax1.set_xlabel('Model algorithm')\n",
    "\n",
    "# 创建第二个y轴用于R_square的折线图（与柱状图顺序一致）\n",
    "ax2 = ax1.twinx()\n",
    "# 修改点2：折线图颜色改为 salmon\n",
    "ax2.plot(x, r_square_sorted, 'salmon', linestyle='--', marker='o', label='$R^2$', zorder=2)\n",
    "# ax2.set_ylabel('$R^2$')\n",
    "ax2.legend(loc='upper right')\n",
    "ax2.tick_params(axis='y', which='both', length=1.2)  # 刻度线长度设为0\n",
    "plt.yticks(fontsize=8)\n",
    "plt.xticks(fontsize=8)\n",
    "\n",
    "# 标注数值\n",
    "for bar, rmse in zip(bars, test_rmse_sorted):\n",
    "    height = bar.get_height()\n",
    "    ax1.text(bar.get_x() + bar.get_width()/2, height, f'{rmse:.3f}', \n",
    "             ha='center', va='bottom', fontsize=8)\n",
    "\n",
    "for x_val, y_val in zip(x, r_square_sorted):\n",
    "    ax2.text(x_val, y_val + 0.009 if y_val >= 0 else y_val - 0.01, f'{y_val:.3f}', \n",
    "             ha='center', va='bottom', fontsize=8)\n",
    "\n",
    "# 设置y轴范围\n",
    "buffer = 0.1\n",
    "max_test_rmse = max(test_rmse_sorted) * (1 + buffer)\n",
    "max_r_square = max(r_square_sorted) * (1 + buffer) if max(r_square_sorted) > 0 else 1\n",
    "ax1.set_ylim(0, max_test_rmse + 10)  # 微调范围\n",
    "ax2.set_ylim(0, max_r_square + 0.15)\n",
    "\n",
    "# 移除所有边框\n",
    "for spine in ax1.spines.values():\n",
    "    spine.set_visible(False)\n",
    "for spine in ax2.spines.values():\n",
    "    spine.set_visible(False)\n",
    "\n",
    "# 调整布局\n",
    "plt.tight_layout()\n",
    "\n",
    "# 保存图表\n",
    "fig.savefig(r'D:\\Jupyter\\IR-DIAZO-KETONE-main\\333\\Model_performance_comparison_sorted.pdf', bbox_inches='tight', dpi=600)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58d5a46e",
   "metadata": {},
   "source": [
    "## visualize_tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b0f89ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "device = 'cuda' if not torch.cuda.is_available() else 'cpu'\n",
    "# original_model = GNNPredictor2(hidden_dim=128,num_layers=4,num_nodes=2,env_num=2)\n",
    "# original_model.load_state_dict(torch.load('saves/model_save_24.pth'))\n",
    "state_dict = torch.load(r'D:\\Jupyter\\IR-DIAZO-KETONE-main\\grid_search\\GINE_h256_n1\\epoch_625.pt')['model_state_dict']\n",
    "# 2. 过滤 predict 相关参数\n",
    "filtered_state_dict = OrderedDict()\n",
    "for k, v in state_dict.items():\n",
    "    if not k.startswith('predict.'):\n",
    "        filtered_state_dict[k] = v\n",
    "        \n",
    "# 3. 初始化模型\n",
    "model = GNNGraph(hidden_dim=256, num_layers=4, num_nodes=1,node_dim=16).to(device)\n",
    "\n",
    "# 4. 加载参数（允许部分加载）\n",
    "model.load_state_dict(filtered_state_dict, strict=False)\n",
    "\n",
    "# 5. 验证\n",
    "model.eval()\n",
    "print(\"Model loaded successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a64ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from torch_geometric.data import Batch\n",
    "\n",
    "def cluster_molecules(model, molecules, eps=0.5, min_samples=5):\n",
    "    \"\"\"\n",
    "    在模型的潜在空间中对分子进行DBSCAN聚类\n",
    "    \n",
    "    参数:\n",
    "        model: 训练好的图神经网络模型\n",
    "        molecules: 分子图列表(Data对象)\n",
    "        eps: DBSCAN邻域半径\n",
    "        min_samples: 核心点最小邻域样本数\n",
    "    \n",
    "    返回:\n",
    "        tuple: (聚类标签数组, 原始潜在空间嵌入, 聚类统计信息)\n",
    "    \"\"\"\n",
    "    # 模型推理\n",
    "    model.eval()\n",
    "    batch = Batch.from_data_list(molecules).to(device)\n",
    "    with torch.no_grad():\n",
    "        embeddings = model(batch.x, batch.edge_index, batch.edge_attr, batch).numpy()\n",
    "    print(embeddings.shape)\n",
    "    # 标准化\n",
    "    scaler = StandardScaler()\n",
    "    embeddings_scaled = scaler.fit_transform(embeddings)\n",
    "    \n",
    "    # DBSCAN聚类\n",
    "    clusters = DBSCAN(eps=eps, min_samples=min_samples).fit_predict(embeddings_scaled)\n",
    "    \n",
    "    # 统计信息\n",
    "    unique_clusters = np.unique(clusters)\n",
    "    n_clusters = len(unique_clusters) - (1 if -1 in unique_clusters else 0)\n",
    "    noise_ratio = np.sum(clusters == -1) / len(clusters)\n",
    "    stats = {\n",
    "        'n_clusters': n_clusters,\n",
    "        'noise_ratio': noise_ratio,\n",
    "        'cluster_distribution': {c: np.sum(clusters == c) for c in unique_clusters}\n",
    "    }\n",
    "    \n",
    "    return clusters, embeddings, stats\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "# from umap import UMAP\n",
    "from matplotlib.colors import ListedColormap\n",
    "import seaborn as sns\n",
    "\n",
    "def visualize_clusters(embeddings, clusters, method='pca', n_components=2,\n",
    "                     title='Clustering Visualization', color_palette='husl',\n",
    "                     alpha=0.7, marker_size=50, random_state=42):\n",
    "    \"\"\"\n",
    "    降维可视化聚类结果\n",
    "    \n",
    "    参数:\n",
    "        embeddings: 原始高维嵌入 (n_samples, n_features)\n",
    "        clusters: 聚类标签数组\n",
    "        method: 降维方法 ('pca', 'tsne', 'umap')\n",
    "        n_components: 可视化维度 (2或3)\n",
    "        title: 图表标题\n",
    "        color_palette: 颜色主题\n",
    "        alpha: 点透明度\n",
    "        marker_size: 点大小\n",
    "        random_state: 随机种子\n",
    "    \n",
    "    返回:\n",
    "        matplotlib Figure对象\n",
    "    \"\"\"\n",
    "    # 降维\n",
    "    if method.lower() == 'pca':\n",
    "        reducer = PCA(n_components=n_components, random_state=random_state)\n",
    "    elif method.lower() == 'tsne':\n",
    "        reducer = TSNE(n_components=n_components, random_state=random_state)\n",
    "    elif method.lower() == 'umap':\n",
    "        reducer = UMAP(n_components=n_components, random_state=random_state)\n",
    "    else:\n",
    "        raise ValueError(\"Method must be 'pca', 'tsne' or 'umap'\")\n",
    "    \n",
    "    low_dim = reducer.fit_transform(embeddings)\n",
    "    \n",
    "    # 可视化设置\n",
    "    unique_clusters = np.unique(clusters)\n",
    "    palette = sns.color_palette(color_palette, len(unique_clusters))\n",
    "    cmap = ListedColormap(palette)\n",
    "    \n",
    "    fig = plt.figure(figsize=(10, 8))\n",
    "    \n",
    "    # 2D/3D绘图\n",
    "    if n_components == 2:\n",
    "        scatter = plt.scatter(low_dim[:, 0], low_dim[:, 1], \n",
    "                            c=clusters, cmap=cmap, s=marker_size, \n",
    "                            alpha=alpha, edgecolor='white', linewidth=0.5)\n",
    "        plt.xlabel('Component 1', fontsize=12)\n",
    "        plt.ylabel('Component 2', fontsize=12)\n",
    "    else:\n",
    "        ax = fig.add_subplot(111, projection='3d')\n",
    "        scatter = ax.scatter(low_dim[:, 0], low_dim[:, 1], low_dim[:, 2],\n",
    "                           c=clusters, cmap=cmap, s=marker_size,\n",
    "                           alpha=alpha, edgecolor='white', linewidth=0.5)\n",
    "        ax.set_xlabel('Component 1', fontsize=12)\n",
    "        ax.set_ylabel('Component 2', fontsize=12)\n",
    "        ax.set_zlabel('Component 3', fontsize=12)\n",
    "    \n",
    "    # 图例\n",
    "    legend_elements = [\n",
    "        plt.Line2D([], [], marker='o', color=palette[i], linestyle='',\n",
    "                  markersize=10, label=f'Cluster {c}' if c != -1 else 'Noise')\n",
    "        for i, c in enumerate(unique_clusters)\n",
    "    ]\n",
    "    \n",
    "    plt.legend(handles=legend_elements, bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    plt.title(title, pad=20)\n",
    "    plt.grid(alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    return fig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f32bfae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 假设已有模型和分子数据\n",
    "# molecules = [mol for mol in graph_IR_dataset]  # 分子图列表\n",
    "\n",
    "# 步骤1: 聚类\n",
    "clusters, embeddings, stats = cluster_molecules(\n",
    "    model, \n",
    "    molecules,\n",
    "    eps=6, \n",
    "    min_samples=15\n",
    ")\n",
    "print(f\"聚类统计: {stats}\")\n",
    "\n",
    "# 步骤2: 可视化\n",
    "fig = visualize_clusters(\n",
    "    embeddings,\n",
    "    clusters,\n",
    "    method='tsne',\n",
    "    title=f\"Molecular Clusters (Found {stats['n_clusters']} clusters)\",\n",
    "    color_palette='viridis'\n",
    ")\n",
    "\n",
    "plt.show()\n",
    "fig.savefig(f'333\\\\visualize.pdf', bbox_inches='tight', dpi=300)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b0c343",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6783997",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "841c57e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_tensors(tensors, labels, method='umap', n_components=2,\n",
    "                     title='Clustered Tensor Visualization', \n",
    "                     color_palette='tab10', alpha=0.6, marker_size=80,\n",
    "                     random_state=40, class_names=None, **kwargs):\n",
    "    \"\"\"\n",
    "    优化后的可视化函数，使同类点更聚集\n",
    "    \n",
    "    参数:\n",
    "        class_names: 自定义类别名称列表（如 ['Amide', 'Ether', 'Acyl halide'])\n",
    "        **kwargs: 传递给降维算法的参数(如perplexity, n_neighbors等)\n",
    "    \"\"\"\n",
    "    # 检查输入\n",
    "    if len(tensors) != len(labels):\n",
    "        raise ValueError(\"tensors和labels的长度必须相同\")\n",
    "    \n",
    "    # 展平数据\n",
    "    tensors_flat = tensors.reshape(tensors.shape[0], -1) if len(tensors.shape) > 2 else tensors\n",
    "    \n",
    "    # 标准化\n",
    "    # from sklearn.preprocessing import StandardScaler\n",
    "    # scaler = StandardScaler()\n",
    "    # tensors_flat = scaler.fit_transform(tensors_flat)\n",
    "    \n",
    "    # 降维\n",
    "    if method.lower() == 'pca':\n",
    "        from sklearn.decomposition import PCA\n",
    "        reducer = PCA(n_components=n_components, random_state=random_state)\n",
    "    elif method.lower() == 'tsne':\n",
    "        from sklearn.manifold import TSNE\n",
    "        reducer = TSNE(n_components=n_components, random_state=random_state,\n",
    "                      perplexity=kwargs.get('perplexity', 50),\n",
    "                      learning_rate=kwargs.get('learning_rate', 150),\n",
    "                      n_iter=kwargs.get('n_iter', 2000))\n",
    "    elif method.lower() == 'umap':\n",
    "        from umap import UMAP\n",
    "        reducer = UMAP(n_components=n_components, random_state=random_state,\n",
    "                      n_neighbors=kwargs.get('n_neighbors', 10),\n",
    "                      min_dist=kwargs.get('min_dist', 0.05))\n",
    "    else:\n",
    "        raise ValueError(\"method必须是'pca'、'tsne'或'umap'\")\n",
    "    \n",
    "    embeddings = reducer.fit_transform(tensors_flat)\n",
    "    \n",
    "    # 可视化\n",
    "    import seaborn as sns\n",
    "    # import  pyplot as plt\n",
    "    from matplotlib.colors import ListedColormap\n",
    "    \n",
    "    unique_labels = np.unique(labels)\n",
    "    colors = sns.color_palette(color_palette, n_colors=len(unique_labels))\n",
    "    cmap = ListedColormap(colors)\n",
    "    \n",
    "    fig = plt.figure(figsize=(9/2.54, 9/2.54))\n",
    "    \n",
    "    if n_components == 2:\n",
    "        scatter = plt.scatter(embeddings[:, 0], embeddings[:, 1], \n",
    "                            c=labels, cmap=cmap, alpha=alpha, s=marker_size,\n",
    "                            edgecolor='white', linewidth=0.32)\n",
    "        plt.xlabel('Principle Component 1', fontsize=9)\n",
    "        plt.ylabel('Principle Component 2', fontsize=9)\n",
    "    else:\n",
    "        ax = fig.add_subplot(111, projection='3d')\n",
    "        scatter = ax.scatter(embeddings[:, 0], embeddings[:, 1], embeddings[:, 2],\n",
    "                           c=labels, cmap=cmap, alpha=alpha, s=marker_size,\n",
    "                           edgecolor='white', linewidth=0.32)\n",
    "        ax.set_xlabel('Component 1', fontsize=12)\n",
    "        ax.set_ylabel('Component 2', fontsize=12)\n",
    "        ax.set_zlabel('Component 3', fontsize=12)\n",
    "    \n",
    "    # plt.title(title, fontsize=10, pad=8)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.yticks(fontsize=8)\n",
    "    plt.xticks(fontsize=8)\n",
    "    # 创建图例（支持自定义标签）\n",
    "    if class_names is None:\n",
    "        class_names = [f'Class {label}' for label in unique_labels]\n",
    "    elif len(class_names) != len(unique_labels):\n",
    "        raise ValueError(\"class_names的长度必须与唯一标签的数量相同\")\n",
    "\n",
    "    handles = [plt.Line2D([0], [0], marker='o', color='w', markerfacecolor=colors[i],\n",
    "                        markersize=6, label=class_names[i])  # 缩小标记大小\n",
    "              for i in range(len(unique_labels))]\n",
    "\n",
    "    # 调整图例样式（字体8号，缩小边框和间距）\n",
    "    plt.legend(\n",
    "        handles=handles,\n",
    "        loc='upper right',\n",
    "        framealpha=0.9,\n",
    "        fontsize=8,                  # 图例文字大小\n",
    "        handletextpad=0.5,           # 标记与文字的间距\n",
    "        borderpad=0.5,               # 边框与内容的间距\n",
    "        labelspacing=0.5,            # 标签间的垂直间距\n",
    "        handlelength=1.5             # 标记的长度\n",
    "    )\n",
    "    plt.tight_layout()\n",
    "    return fig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a402b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import Batch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def process_and_visualize(new_model, amide_moleculesN, amide_moleculesO, amide_moleculesF):\n",
    "    # 确保模型在评估模式\n",
    "    new_model.eval()\n",
    "    \n",
    "    # 准备标签 (0: N, 1: O, 2: F)\n",
    "    labels = torch.cat([\n",
    "        torch.zeros(len(amide_moleculesN)),  # N类标签为0\n",
    "        torch.ones(len(amide_moleculesO)),   # O类标签为1\n",
    "        torch.full((len(amide_moleculesF),), 2)  # F类标签为2\n",
    "    ])\n",
    "    \n",
    "    # 合并所有分子图\n",
    "    all_molecules = amide_moleculesN + amide_moleculesO + amide_moleculesF\n",
    "    \n",
    "    # 创建批次数据\n",
    "    batch_data = Batch.from_data_list(all_molecules)\n",
    "    \n",
    "    # 获取模型输出 (不需要梯度)\n",
    "    with torch.no_grad():\n",
    "        outputs = new_model(batch_data.x, batch_data.edge_index, batch_data.edge_attr, batch_data)\n",
    "    \n",
    "    # 沿axis=0拼接所有输出 (63×d_model)\n",
    "    tensors = outputs.cpu().numpy()\n",
    "    \n",
    "    # 可视化\n",
    "    fig = visualize_tensors(\n",
    "        tensors, \n",
    "        labels, \n",
    "        method='tsne', \n",
    "        n_components=2, \n",
    "        title='Tensor Visualization', \n",
    "        color_palette='viridis', \n",
    "        alpha=0.6, \n",
    "        marker_size=30, \n",
    "        random_state=42, \n",
    "\n",
    "        perplexity=200, \n",
    "        learning_rate=200, \n",
    "        n_iter=600, \n",
    "        \n",
    "        n_neighbors=27, \n",
    "        min_dist=0.07,\n",
    "        class_names=['Amide', 'Ether', 'Acyl halide']  # 直接传入自定义标签\n",
    "    )\n",
    "    return fig\n",
    "\n",
    "# 可视化\n",
    "fig = process_and_visualize(model, amide_moleculesN, amide_moleculesO, amide_moleculesF)\n",
    "plt.show()\n",
    "fig.savefig(f'333\\\\visualize.pdf', bbox_inches='tight', dpi=300)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5559c0b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "from math import sqrt\n",
    "from inspect import signature\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import MessagePassing\n",
    "from torch_geometric.utils import to_networkx\n",
    "\n",
    "EPS = 1e-15\n",
    "\n",
    "class GNNExplainer(torch.nn.Module):\n",
    "    coeffs = {\n",
    "        'node_feat_reduction': 'mean',\n",
    "        'node_feat_size': 1.0,\n",
    "        'node_feat_ent': 0.1,\n",
    "        'edge_reduction': 'sum',\n",
    "        'edge_size': 0.004,\n",
    "        'edge_ent': 1.0,\n",
    "        'edge_feat_reduction': 'mean',  # 新增边特征归约方式\n",
    "        'edge_feat_size': 1.0,  # 新增边特征大小正则化系数\n",
    "        'edge_feat_ent': 0.1,  # 新增边特征熵正则化系数\n",
    "    }\n",
    "\n",
    "    def __init__(self, model, epochs: int = 100, lr: float = 0.01,\n",
    "                 num_hops: Optional[int] = None, return_type: str = 'log_prob',\n",
    "                 feat_mask_type: str = 'feature', allow_edge_mask: bool = True,\n",
    "                 log: bool = True, **kwargs):\n",
    "        super().__init__()\n",
    "        assert return_type in ['log_prob', 'prob', 'raw', 'regression']\n",
    "        assert feat_mask_type in ['feature', 'individual_feature', 'scalar']\n",
    "        self.model = model\n",
    "        self.epochs = epochs\n",
    "        self.lr = lr\n",
    "        self.__num_hops__ = num_hops\n",
    "        self.return_type = return_type\n",
    "        self.log = log\n",
    "        self.allow_edge_mask = allow_edge_mask\n",
    "        self.feat_mask_type = feat_mask_type\n",
    "        self.coeffs.update(kwargs)\n",
    "\n",
    "    def __set_masks__(self, x, edge_index, edge_attr=None, init=\"normal\"):\n",
    "        (N, F), E = x.size(), edge_index.size(1)\n",
    "\n",
    "        std = 0.1\n",
    "        # 节点特征掩码\n",
    "        if self.feat_mask_type == 'individual_feature':\n",
    "            self.node_feat_mask = torch.nn.Parameter(torch.randn(N, F) * std)\n",
    "        elif self.feat_mask_type == 'scalar':\n",
    "            self.node_feat_mask = torch.nn.Parameter(torch.randn(N, 1) * std)\n",
    "        else:\n",
    "            self.node_feat_mask = torch.nn.Parameter(torch.randn(1, F) * std)\n",
    "\n",
    "        # 边掩码\n",
    "        std_edge = torch.nn.init.calculate_gain('relu') * sqrt(2.0 / (2 * N))\n",
    "        self.edge_mask = torch.nn.Parameter(torch.randn(E) * std_edge)\n",
    "        if not self.allow_edge_mask:\n",
    "            self.edge_mask.requires_grad_(False)\n",
    "            self.edge_mask.fill_(float('inf'))\n",
    "        self.loop_mask = edge_index[0] != edge_index[1]\n",
    "\n",
    "        # 边特征掩码\n",
    "        self.edge_feat_mask = None\n",
    "        if edge_attr is not None:\n",
    "            F_edge = edge_attr.size(1)\n",
    "            if self.feat_mask_type == 'individual_feature':\n",
    "                self.edge_feat_mask = torch.nn.Parameter(torch.randn(E, F_edge) * std)\n",
    "            elif self.feat_mask_type == 'scalar':\n",
    "                self.edge_feat_mask = torch.nn.Parameter(torch.randn(E, 1) * std)\n",
    "            else:\n",
    "                self.edge_feat_mask = torch.nn.Parameter(torch.randn(1, F_edge) * std)\n",
    "\n",
    "        for module in self.model.modules():\n",
    "            if isinstance(module, MessagePassing):\n",
    "                module.__explain__ = True\n",
    "                module.__edge_mask__ = self.edge_mask\n",
    "                module.__loop_mask__ = self.loop_mask\n",
    "\n",
    "    def __clear_masks__(self):\n",
    "        for module in self.model.modules():\n",
    "            if isinstance(module, MessagePassing):\n",
    "                module.__explain__ = False\n",
    "                module.__edge_mask__ = None\n",
    "                module.__loop_mask__ = None\n",
    "        self.node_feat_mask = None\n",
    "        self.edge_mask = None\n",
    "        self.edge_feat_mask = None\n",
    "        self.loop_mask = None\n",
    "\n",
    "    @property\n",
    "    def num_hops(self):\n",
    "        if self.__num_hops__ is not None:\n",
    "            return self.__num_hops__\n",
    "\n",
    "        k = 0\n",
    "        for module in self.model.modules():\n",
    "            if isinstance(module, MessagePassing):\n",
    "                k += 1\n",
    "        return k\n",
    "\n",
    "    def __flow__(self):\n",
    "        for module in self.model.modules():\n",
    "            if isinstance(module, MessagePassing):\n",
    "                return module.flow\n",
    "        return 'source_to_target'\n",
    "\n",
    "    def __subgraph__(self, node_idx, x, edge_index, **kwargs):\n",
    "        num_nodes, num_edges = x.size(0), edge_index.size(1)\n",
    "\n",
    "        subset, edge_index, mapping, edge_mask = k_hop_subgraph(\n",
    "            node_idx, self.num_hops, edge_index, relabel_nodes=True,\n",
    "            num_nodes=num_nodes, flow=self.__flow__())\n",
    "\n",
    "        x = x[subset]\n",
    "        for key, item in kwargs.items():\n",
    "            if torch.is_tensor(item) and item.size(0) == num_nodes:\n",
    "                item = item[subset]\n",
    "            elif torch.is_tensor(item) and item.size(0) == num_edges:\n",
    "                item = item[edge_mask]\n",
    "            kwargs[key] = item\n",
    "\n",
    "        return x, edge_index, mapping, edge_mask, subset, kwargs\n",
    "\n",
    "    def __loss__(self, node_idx, log_logits, pred_label):\n",
    "        if self.return_type == 'regression':\n",
    "            loss = -torch.cdist(log_logits[node_idx], pred_label[node_idx]) if node_idx != -1 else -torch.norm(log_logits-pred_label, p=2)\n",
    "        else:\n",
    "            loss = -log_logits[node_idx, pred_label[node_idx]] if node_idx != -1 else -log_logits[0, pred_label[0]]\n",
    "\n",
    "        # 节点特征掩码正则化\n",
    "        m_node = self.node_feat_mask.sigmoid()\n",
    "        node_feat_reduce = getattr(torch, self.coeffs['node_feat_reduction'])\n",
    "        loss = loss + self.coeffs['node_feat_size'] * node_feat_reduce(m_node)\n",
    "        ent_node = -m_node * torch.log(m_node + EPS) - (1 - m_node) * torch.log(1 - m_node + EPS)\n",
    "        loss = loss + self.coeffs['node_feat_ent'] * ent_node.mean()\n",
    "\n",
    "        # 边掩码正则化\n",
    "        m_edge = self.edge_mask.sigmoid()\n",
    "        edge_reduce = getattr(torch, self.coeffs['edge_reduction'])\n",
    "        loss = loss + self.coeffs['edge_size'] * edge_reduce(m_edge)\n",
    "        ent_edge = -m_edge * torch.log(m_edge + EPS) - (1 - m_edge) * torch.log(1 - m_edge + EPS)\n",
    "        loss = loss + self.coeffs['edge_ent'] * ent_edge.mean()\n",
    "\n",
    "        # 边特征掩码正则化 (如果存在)\n",
    "        if self.edge_feat_mask is not None:\n",
    "            m_edge_feat = self.edge_feat_mask.sigmoid()\n",
    "            edge_feat_reduce = getattr(torch, self.coeffs['edge_feat_reduction'])\n",
    "            loss = loss + self.coeffs['edge_feat_size'] * edge_feat_reduce(m_edge_feat)\n",
    "            ent_edge_feat = -m_edge_feat * torch.log(m_edge_feat + EPS) - (1 - m_edge_feat) * torch.log(1 - m_edge_feat + EPS)\n",
    "            loss = loss + self.coeffs['edge_feat_ent'] * ent_edge_feat.mean()\n",
    "\n",
    "        return loss\n",
    "    \n",
    "    def __to_log_prob__(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = x.log_softmax(dim=-1) if self.return_type == 'raw' else x\n",
    "        x = x.log() if self.return_type == 'prob' else x\n",
    "        return x\n",
    "\n",
    "    def explain_graph(self, x, edge_index, edge_attr=None, **kwargs):\n",
    "        self.model.eval()\n",
    "        self.__clear_masks__()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            out = self.model(x=x, edge_index=edge_index, edge_attr=edge_attr, **kwargs)\n",
    "            if self.return_type == 'regression':\n",
    "                prediction = out\n",
    "            else:\n",
    "                log_logits = self.__to_log_prob__(out)\n",
    "                pred_label = log_logits.argmax(dim=-1)\n",
    "\n",
    "        self.__set_masks__(x, edge_index, edge_attr)\n",
    "        self.to(x.device)\n",
    "        \n",
    "        parameters = [self.node_feat_mask, self.edge_mask] if self.allow_edge_mask else [self.node_feat_mask]\n",
    "        if self.edge_feat_mask is not None:\n",
    "            parameters.append(self.edge_feat_mask)\n",
    "        optimizer = torch.optim.Adam(parameters, lr=self.lr)\n",
    "\n",
    "        if self.log:\n",
    "            pbar = tqdm(total=self.epochs)\n",
    "            pbar.set_description('Explain graph')\n",
    "\n",
    "        for epoch in range(1, self.epochs + 1):\n",
    "            optimizer.zero_grad()\n",
    "            h = x * self.node_feat_mask.sigmoid()\n",
    "            h_edge = edge_attr * self.edge_feat_mask.sigmoid() if edge_attr is not None else None\n",
    "            \n",
    "            out = self.model(x=h, edge_index=edge_index, edge_attr=h_edge, **kwargs)\n",
    "            \n",
    "            if self.return_type == 'regression':\n",
    "                loss = self.__loss__(-1, out, prediction)\n",
    "            else:\n",
    "                log_logits = self.__to_log_prob__(out)\n",
    "                loss = self.__loss__(-1, log_logits, pred_label)\n",
    "                \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            if self.log:\n",
    "                pbar.update(1)\n",
    "        if self.log:\n",
    "            pbar.close()\n",
    "\n",
    "        node_feat_mask = self.node_feat_mask.detach().sigmoid().squeeze()\n",
    "        edge_mask = self.edge_mask.detach().sigmoid()\n",
    "        edge_feat_mask = self.edge_feat_mask.detach().sigmoid() if self.edge_feat_mask is not None else None\n",
    "\n",
    "        self.__clear_masks__()\n",
    "        return node_feat_mask, edge_mask, edge_feat_mask\n",
    "\n",
    "    def explain_node(self, node_idx, x, edge_index, edge_attr=None, **kwargs):\n",
    "        self.model.eval()\n",
    "        self.__clear_masks__()\n",
    "\n",
    "        num_edges = edge_index.size(1)\n",
    "        # 提取子图 (包含边特征处理)\n",
    "        x, edge_index, mapping, hard_edge_mask, subset, kwargs = \\\n",
    "            self.__subgraph__(node_idx, x, edge_index, **kwargs)\n",
    "        \n",
    "        # 处理边特征\n",
    "        if edge_attr is not None:\n",
    "            edge_attr_sub = edge_attr[hard_edge_mask]\n",
    "        else:\n",
    "            edge_attr_sub = None\n",
    "\n",
    "        with torch.no_grad():\n",
    "            out = self.model(x=x, edge_index=edge_index, edge_attr=edge_attr_sub, **kwargs)\n",
    "            if self.return_type == 'regression':\n",
    "                prediction = out\n",
    "            else:\n",
    "                log_logits = self.__to_log_prob__(out)\n",
    "                pred_label = log_logits.argmax(dim=-1)\n",
    "\n",
    "        self.__set_masks__(x, edge_index, edge_attr_sub)\n",
    "        self.to(x.device)\n",
    "        \n",
    "        parameters = [self.node_feat_mask, self.edge_mask]\n",
    "        if self.edge_feat_mask is not None:\n",
    "            parameters.append(self.edge_feat_mask)\n",
    "        optimizer = torch.optim.Adam(parameters, lr=self.lr)\n",
    "\n",
    "        if self.log:\n",
    "            pbar = tqdm(total=self.epochs)\n",
    "            pbar.set_description(f'Explain node {node_idx}')\n",
    "\n",
    "        for epoch in range(1, self.epochs + 1):\n",
    "            optimizer.zero_grad()\n",
    "            h = x * self.node_feat_mask.sigmoid()\n",
    "            h_edge = edge_attr_sub * self.edge_feat_mask.sigmoid() if edge_attr_sub is not None else None\n",
    "            \n",
    "            out = self.model(x=h, edge_index=edge_index, edge_attr=h_edge, **kwargs)\n",
    "            \n",
    "            if self.return_type == 'regression':\n",
    "                loss = self.__loss__(mapping, out, prediction)\n",
    "            else:\n",
    "                log_logits = self.__to_log_prob__(out)\n",
    "                loss = self.__loss__(mapping, log_logits, pred_label)\n",
    "                \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            if self.log:\n",
    "                pbar.update(1)\n",
    "        if self.log:\n",
    "            pbar.close()\n",
    "\n",
    "        # 处理节点特征掩码\n",
    "        node_feat_mask = self.node_feat_mask.detach().sigmoid()\n",
    "        if self.feat_mask_type != 'feature':\n",
    "            new_mask = x.new_zeros(x.size(0), node_feat_mask.size(1))\n",
    "            new_mask[subset] = node_feat_mask\n",
    "            node_feat_mask = new_mask\n",
    "        node_feat_mask = node_feat_mask.squeeze()\n",
    "\n",
    "        # 处理边掩码\n",
    "        full_edge_mask = self.edge_mask.new_zeros(num_edges)\n",
    "        full_edge_mask[hard_edge_mask] = self.edge_mask.detach().sigmoid()\n",
    "\n",
    "        # 处理边特征掩码\n",
    "        if self.edge_feat_mask is not None:\n",
    "            edge_feat_mask = self.edge_feat_mask.new_zeros(num_edges, edge_attr.size(1))\n",
    "            edge_feat_mask[hard_edge_mask] = self.edge_feat_mask.detach().sigmoid()\n",
    "        else:\n",
    "            edge_feat_mask = None\n",
    "\n",
    "        self.__clear_masks__()\n",
    "        return node_feat_mask, full_edge_mask, edge_feat_mask\n",
    "\n",
    "    def visualize_subgraph(self, node_idx, edge_index, edge_mask, y=None,\n",
    "                           threshold=None, edge_y=None, node_alpha=None,\n",
    "                           seed=10, **kwargs):\n",
    "        r\"\"\"Visualizes the subgraph given an edge mask\n",
    "        :attr:`edge_mask`.\n",
    "\n",
    "        Args:\n",
    "            node_idx (int): The node id to explain.\n",
    "                Set to :obj:`-1` to explain graph.\n",
    "            edge_index (LongTensor): The edge indices.\n",
    "            edge_mask (Tensor): The edge mask.\n",
    "            y (Tensor, optional): The ground-truth node-prediction labels used\n",
    "                as node colorings. All nodes will have the same color\n",
    "                if :attr:`node_idx` is :obj:`-1`.(default: :obj:`None`).\n",
    "            threshold (float, optional): Sets a threshold for visualizing\n",
    "                important edges. If set to :obj:`None`, will visualize all\n",
    "                edges with transparancy indicating the importance of edges.\n",
    "                (default: :obj:`None`)\n",
    "            edge_y (Tensor, optional): The edge labels used as edge colorings.\n",
    "            node_alpha (Tensor, optional): Tensor of floats (0 - 1) indicating\n",
    "                transparency of each node.\n",
    "            seed (int, optional): Random seed of the :obj:`networkx` node\n",
    "                placement algorithm. (default: :obj:`10`)\n",
    "            **kwargs (optional): Additional arguments passed to\n",
    "                :func:`nx.draw`.\n",
    "\n",
    "        :rtype: :class:`matplotlib.axes.Axes`, :class:`networkx.DiGraph`\n",
    "        \"\"\"\n",
    "        import networkx as nx\n",
    "        import matplotlib.pyplot as plt\n",
    "\n",
    "        assert edge_mask.size(0) == edge_index.size(1)\n",
    "\n",
    "        if node_idx == -1:\n",
    "            hard_edge_mask = torch.BoolTensor([True] * edge_index.size(1),\n",
    "                                              device=edge_mask.device)\n",
    "            subset = torch.arange(edge_index.max().item() + 1,\n",
    "                                  device=edge_index.device)\n",
    "            y = None\n",
    "\n",
    "        else:\n",
    "            # Only operate on a k-hop subgraph around `node_idx`.\n",
    "            subset, edge_index, _, hard_edge_mask = k_hop_subgraph(\n",
    "                node_idx, self.num_hops, edge_index, relabel_nodes=True,\n",
    "                num_nodes=None, flow=self.__flow__())\n",
    "\n",
    "        edge_mask = edge_mask[hard_edge_mask]\n",
    "\n",
    "        if threshold is not None:\n",
    "            edge_mask = (edge_mask >= threshold).to(torch.float)\n",
    "\n",
    "        if y is None:\n",
    "            y = torch.zeros(edge_index.max().item() + 1,\n",
    "                            device=edge_index.device)\n",
    "        else:\n",
    "            y = y[subset].to(torch.float) / y.max().item()\n",
    "\n",
    "        if edge_y is None:\n",
    "            edge_color = ['black'] * edge_index.size(1)\n",
    "        else:\n",
    "            colors = list(plt.rcParams['axes.prop_cycle'])\n",
    "            edge_color = [\n",
    "                colors[i % len(colors)]['color']\n",
    "                for i in edge_y[hard_edge_mask]\n",
    "            ]\n",
    "\n",
    "        data = Data(edge_index=edge_index, att=edge_mask,\n",
    "                    edge_color=edge_color, y=y, num_nodes=y.size(0)).to('cpu')\n",
    "        G = to_networkx(data, node_attrs=['y'],\n",
    "                        edge_attrs=['att', 'edge_color'])\n",
    "        mapping = {k: i for k, i in enumerate(subset.tolist())}\n",
    "        G = nx.relabel_nodes(G, mapping)\n",
    "\n",
    "        node_args = set(signature(nx.draw_networkx_nodes).parameters.keys())\n",
    "        node_kwargs = {k: v for k, v in kwargs.items() if k in node_args}\n",
    "        node_kwargs['node_size'] = kwargs.get('node_size') or 800\n",
    "        node_kwargs['cmap'] = kwargs.get('cmap') or 'cool'\n",
    "\n",
    "        label_args = set(signature(nx.draw_networkx_labels).parameters.keys())\n",
    "        label_kwargs = {k: v for k, v in kwargs.items() if k in label_args}\n",
    "        label_kwargs['font_size'] = kwargs.get('font_size') or 10\n",
    "\n",
    "        pos = nx.spring_layout(G, seed=seed)\n",
    "        ax = plt.gca()\n",
    "        for source, target, data in G.edges(data=True):\n",
    "            ax.annotate(\n",
    "                '', xy=pos[target], xycoords='data', xytext=pos[source],\n",
    "                textcoords='data', arrowprops=dict(\n",
    "                    arrowstyle=\"->\",\n",
    "                    alpha=max(data['att'], 0.1),\n",
    "                    color=data['edge_color'],\n",
    "                    shrinkA=sqrt(node_kwargs['node_size']) / 2.0,\n",
    "                    shrinkB=sqrt(node_kwargs['node_size']) / 2.0,\n",
    "                    connectionstyle=\"arc3,rad=0.1\",\n",
    "                ))\n",
    "\n",
    "        if node_alpha is None:\n",
    "            nx.draw_networkx_nodes(G, pos, node_color=y.tolist(),\n",
    "                                   **node_kwargs)\n",
    "        else:\n",
    "            node_alpha_subset = node_alpha[subset]\n",
    "            assert ((node_alpha_subset >= 0) & (node_alpha_subset <= 1)).all()\n",
    "            nx.draw_networkx_nodes(G, pos, alpha=node_alpha_subset.tolist(),\n",
    "                                   node_color=y.tolist(), **node_kwargs)\n",
    "\n",
    "        nx.draw_networkx_labels(G, pos, **label_kwargs)\n",
    "\n",
    "        return ax, G\n",
    "\n",
    "def k_hop_subgraph(node_idx, num_hops, edge_index, relabel_nodes=False,\n",
    "                   num_nodes=None, flow='source_to_target'):\n",
    "    r\"\"\"Computes the :math:`k`-hop subgraph of :obj:`edge_index` around node\n",
    "    :attr:`node_idx`.\n",
    "    It returns (1) the nodes involved in the subgraph, (2) the filtered\n",
    "    :obj:`edge_index` connectivity, (3) the mapping from node indices in\n",
    "    :obj:`node_idx` to their new location, and (4) the edge mask indicating\n",
    "    which edges were preserved.\n",
    "\n",
    "    Args:\n",
    "        node_idx (int, list, tuple or :obj:`torch.Tensor`): The central\n",
    "            node(s).\n",
    "        num_hops: (int): The number of hops :math:`k`.\n",
    "        edge_index (LongTensor): The edge indices.\n",
    "        relabel_nodes (bool, optional): If set to :obj:`True`, the resulting\n",
    "            :obj:`edge_index` will be relabeled to hold consecutive indices\n",
    "            starting from zero. (default: :obj:`False`)\n",
    "        num_nodes (int, optional): The number of nodes, *i.e.*\n",
    "            :obj:`max_val + 1` of :attr:`edge_index`. (default: :obj:`None`)\n",
    "        flow (string, optional): The flow direction of :math:`k`-hop\n",
    "            aggregation (:obj:`\"source_to_target\"` or\n",
    "            :obj:`\"target_to_source\"`). (default: :obj:`\"source_to_target\"`)\n",
    "\n",
    "    :rtype: (:class:`LongTensor`, :class:`LongTensor`, :class:`LongTensor`,\n",
    "             :class:`BoolTensor`)\n",
    "    \"\"\"\n",
    "\n",
    "    num_nodes = num_nodes if num_nodes is not None else edge_index.max().item() + 1\n",
    "\n",
    "    assert flow in ['source_to_target', 'target_to_source']\n",
    "    if flow == 'target_to_source':\n",
    "        row, col = edge_index\n",
    "    else:\n",
    "        col, row = edge_index\n",
    "\n",
    "    node_mask = row.new_empty(num_nodes, dtype=torch.bool)\n",
    "    edge_mask = row.new_empty(row.size(0), dtype=torch.bool)\n",
    "\n",
    "    if isinstance(node_idx, (int, list, tuple)):\n",
    "        node_idx = torch.tensor([node_idx], device=row.device).flatten()\n",
    "    else:\n",
    "        node_idx = node_idx.to(row.device)\n",
    "\n",
    "    subsets = [node_idx]\n",
    "\n",
    "    for _ in range(num_hops):\n",
    "        node_mask.fill_(False)\n",
    "        node_mask[subsets[-1]] = True\n",
    "        torch.index_select(node_mask, 0, row, out=edge_mask)\n",
    "        subsets.append(col[edge_mask])\n",
    "\n",
    "    subset, inv = torch.cat(subsets).unique(return_inverse=True)\n",
    "    inv = inv[:node_idx.numel()]\n",
    "\n",
    "    node_mask.fill_(False)\n",
    "    node_mask[subset] = True\n",
    "    edge_mask = node_mask[row] & node_mask[col]\n",
    "\n",
    "    edge_index = edge_index[:, edge_mask]\n",
    "\n",
    "    if relabel_nodes:\n",
    "        node_idx = row.new_full((num_nodes, ), -1)\n",
    "        node_idx[subset] = torch.arange(subset.size(0), device=row.device)\n",
    "        edge_index = node_idx[edge_index]\n",
    "\n",
    "    return subset, edge_index, inv, edge_mask\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6378a75b",
   "metadata": {},
   "source": [
    "## GNNexplainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a4b210",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from gnnexplainer import GNNExplainer\n",
    "from GNNexplainer import GNNExplainer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac0f41b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "from math import sqrt\n",
    "from inspect import signature\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import MessagePassing\n",
    "from torch_geometric.utils import to_networkx\n",
    "\n",
    "EPS = 1e-15\n",
    "\n",
    "class GNNExplainer(torch.nn.Module):\n",
    "    coeffs = {\n",
    "        'node_feat_reduction': 'mean',\n",
    "        'node_feat_size': 1.0,\n",
    "        'node_feat_ent': 0.1,\n",
    "        'edge_reduction': 'sum',\n",
    "        'edge_size': 0.004,\n",
    "        'edge_ent': 1.0,\n",
    "        'edge_feat_reduction': 'mean',  # 新增边特征归约方式\n",
    "        'edge_feat_size': 1.0,  # 新增边特征大小正则化系数\n",
    "        'edge_feat_ent': 0.1,  # 新增边特征熵正则化系数\n",
    "    }\n",
    "\n",
    "    def __init__(self, model, epochs: int = 100, lr: float = 0.01,\n",
    "                 num_hops: Optional[int] = None, return_type: str = 'log_prob',\n",
    "                 feat_mask_type: str = 'feature', allow_edge_mask: bool = True,\n",
    "                 log: bool = True, **kwargs):\n",
    "        super().__init__()\n",
    "        assert return_type in ['log_prob', 'prob', 'raw', 'regression']\n",
    "        assert feat_mask_type in ['feature', 'individual_feature', 'scalar']\n",
    "        self.model = model\n",
    "        self.epochs = epochs\n",
    "        self.lr = lr\n",
    "        self.__num_hops__ = num_hops\n",
    "        self.return_type = return_type\n",
    "        self.log = log\n",
    "        self.allow_edge_mask = allow_edge_mask\n",
    "        self.feat_mask_type = feat_mask_type\n",
    "        self.coeffs.update(kwargs)\n",
    "\n",
    "    def __set_masks__(self, x, edge_index, edge_attr=None, init=\"normal\"):\n",
    "        (N, F), E = x.size(), edge_index.size(1)\n",
    "\n",
    "        std = 0.1\n",
    "        # 节点特征掩码\n",
    "        if self.feat_mask_type == 'individual_feature':\n",
    "            self.node_feat_mask = torch.nn.Parameter(torch.randn(N, F) * std)\n",
    "        elif self.feat_mask_type == 'scalar':\n",
    "            self.node_feat_mask = torch.nn.Parameter(torch.randn(N, 1) * std)\n",
    "        else:\n",
    "            self.node_feat_mask = torch.nn.Parameter(torch.randn(1, F) * std)\n",
    "\n",
    "        # 边掩码\n",
    "        std_edge = torch.nn.init.calculate_gain('relu') * sqrt(2.0 / (2 * N))\n",
    "        self.edge_mask = torch.nn.Parameter(torch.randn(E) * std_edge)\n",
    "        if not self.allow_edge_mask:\n",
    "            self.edge_mask.requires_grad_(False)\n",
    "            self.edge_mask.fill_(float('inf'))\n",
    "        self.loop_mask = edge_index[0] != edge_index[1]\n",
    "\n",
    "        # 边特征掩码\n",
    "        self.edge_feat_mask = None\n",
    "        if edge_attr is not None:\n",
    "            F_edge = edge_attr.size(1)\n",
    "            if self.feat_mask_type == 'individual_feature':\n",
    "                self.edge_feat_mask = torch.nn.Parameter(torch.randn(E, F_edge) * std)\n",
    "            elif self.feat_mask_type == 'scalar':\n",
    "                self.edge_feat_mask = torch.nn.Parameter(torch.randn(E, 1) * std)\n",
    "            else:\n",
    "                self.edge_feat_mask = torch.nn.Parameter(torch.randn(1, F_edge) * std)\n",
    "\n",
    "        for module in self.model.modules():\n",
    "            if isinstance(module, MessagePassing):\n",
    "                module.__explain__ = True\n",
    "                module.__edge_mask__ = self.edge_mask\n",
    "                module.__loop_mask__ = self.loop_mask\n",
    "\n",
    "    def __clear_masks__(self):\n",
    "        for module in self.model.modules():\n",
    "            if isinstance(module, MessagePassing):\n",
    "                module.__explain__ = False\n",
    "                module.__edge_mask__ = None\n",
    "                module.__loop_mask__ = None\n",
    "        self.node_feat_mask = None\n",
    "        self.edge_mask = None\n",
    "        self.edge_feat_mask = None\n",
    "        self.loop_mask = None\n",
    "\n",
    "    @property\n",
    "    def num_hops(self):\n",
    "        if self.__num_hops__ is not None:\n",
    "            return self.__num_hops__\n",
    "\n",
    "        k = 0\n",
    "        for module in self.model.modules():\n",
    "            if isinstance(module, MessagePassing):\n",
    "                k += 1\n",
    "        return k\n",
    "\n",
    "    def __flow__(self):\n",
    "        for module in self.model.modules():\n",
    "            if isinstance(module, MessagePassing):\n",
    "                return module.flow\n",
    "        return 'source_to_target'\n",
    "\n",
    "    def __subgraph__(self, node_idx, x, edge_index, **kwargs):\n",
    "        num_nodes, num_edges = x.size(0), edge_index.size(1)\n",
    "\n",
    "        subset, edge_index, mapping, edge_mask = k_hop_subgraph(\n",
    "            node_idx, self.num_hops, edge_index, relabel_nodes=True,\n",
    "            num_nodes=num_nodes, flow=self.__flow__())\n",
    "\n",
    "        x = x[subset]\n",
    "        for key, item in kwargs.items():\n",
    "            if torch.is_tensor(item) and item.size(0) == num_nodes:\n",
    "                item = item[subset]\n",
    "            elif torch.is_tensor(item) and item.size(0) == num_edges:\n",
    "                item = item[edge_mask]\n",
    "            kwargs[key] = item\n",
    "\n",
    "        return x, edge_index, mapping, edge_mask, subset, kwargs\n",
    "\n",
    "    def __loss__(self, node_idx, log_logits, pred_label):\n",
    "        if self.return_type == 'regression':\n",
    "            loss = -torch.cdist(log_logits[node_idx], pred_label[node_idx]) if node_idx != -1 else -torch.norm(log_logits-pred_label, p=2)\n",
    "        else:\n",
    "            loss = -log_logits[node_idx, pred_label[node_idx]] if node_idx != -1 else -log_logits[0, pred_label[0]]\n",
    "\n",
    "        # 节点特征掩码正则化\n",
    "        m_node = self.node_feat_mask.sigmoid()\n",
    "        node_feat_reduce = getattr(torch, self.coeffs['node_feat_reduction'])\n",
    "        loss = loss + self.coeffs['node_feat_size'] * node_feat_reduce(m_node)\n",
    "        ent_node = -m_node * torch.log(m_node + EPS) - (1 - m_node) * torch.log(1 - m_node + EPS)\n",
    "        loss = loss + self.coeffs['node_feat_ent'] * ent_node.mean()\n",
    "\n",
    "        # 边掩码正则化\n",
    "        m_edge = self.edge_mask.sigmoid()\n",
    "        edge_reduce = getattr(torch, self.coeffs['edge_reduction'])\n",
    "        loss = loss + self.coeffs['edge_size'] * edge_reduce(m_edge)\n",
    "        ent_edge = -m_edge * torch.log(m_edge + EPS) - (1 - m_edge) * torch.log(1 - m_edge + EPS)\n",
    "        loss = loss + self.coeffs['edge_ent'] * ent_edge.mean()\n",
    "\n",
    "        # 边特征掩码正则化 (如果存在)\n",
    "        if self.edge_feat_mask is not None:\n",
    "            m_edge_feat = self.edge_feat_mask.sigmoid()\n",
    "            edge_feat_reduce = getattr(torch, self.coeffs['edge_feat_reduction'])\n",
    "            loss = loss + self.coeffs['edge_feat_size'] * edge_feat_reduce(m_edge_feat)\n",
    "            ent_edge_feat = -m_edge_feat * torch.log(m_edge_feat + EPS) - (1 - m_edge_feat) * torch.log(1 - m_edge_feat + EPS)\n",
    "            loss = loss + self.coeffs['edge_feat_ent'] * ent_edge_feat.mean()\n",
    "\n",
    "        return loss\n",
    "    \n",
    "    def __to_log_prob__(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = x.log_softmax(dim=-1) if self.return_type == 'raw' else x\n",
    "        x = x.log() if self.return_type == 'prob' else x\n",
    "        return x\n",
    "\n",
    "    def explain_graph(self, x, edge_index, edge_attr=None, **kwargs):\n",
    "        self.model.eval()\n",
    "        self.__clear_masks__()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            out = self.model(x=x, edge_index=edge_index, edge_attr=edge_attr, **kwargs)\n",
    "            if self.return_type == 'regression':\n",
    "                prediction = out\n",
    "            else:\n",
    "                log_logits = self.__to_log_prob__(out)\n",
    "                pred_label = log_logits.argmax(dim=-1)\n",
    "\n",
    "        self.__set_masks__(x, edge_index, edge_attr)\n",
    "        self.to(x.device)\n",
    "        \n",
    "        parameters = [self.node_feat_mask, self.edge_mask] if self.allow_edge_mask else [self.node_feat_mask]\n",
    "        if self.edge_feat_mask is not None:\n",
    "            parameters.append(self.edge_feat_mask)\n",
    "        optimizer = torch.optim.Adam(parameters, lr=self.lr)\n",
    "\n",
    "        if self.log:\n",
    "            pbar = tqdm(total=self.epochs)\n",
    "            pbar.set_description('Explain graph')\n",
    "\n",
    "        for epoch in range(1, self.epochs + 1):\n",
    "            optimizer.zero_grad()\n",
    "            h = x * self.node_feat_mask.sigmoid()\n",
    "            h_edge = edge_attr * self.edge_feat_mask.sigmoid() if edge_attr is not None else None\n",
    "            \n",
    "            out = self.model(x=h, edge_index=edge_index, edge_attr=h_edge, **kwargs)\n",
    "            \n",
    "            if self.return_type == 'regression':\n",
    "                loss = self.__loss__(-1, out, prediction)\n",
    "            else:\n",
    "                log_logits = self.__to_log_prob__(out)\n",
    "                loss = self.__loss__(-1, log_logits, pred_label)\n",
    "                \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            if self.log:\n",
    "                pbar.update(1)\n",
    "        if self.log:\n",
    "            pbar.close()\n",
    "\n",
    "        node_feat_mask = self.node_feat_mask.detach().sigmoid().squeeze()\n",
    "        edge_mask = self.edge_mask.detach().sigmoid()\n",
    "        edge_feat_mask = self.edge_feat_mask.detach().sigmoid() if self.edge_feat_mask is not None else None\n",
    "\n",
    "        self.__clear_masks__()\n",
    "        return node_feat_mask, edge_mask, edge_feat_mask\n",
    "\n",
    "    def explain_node(self, node_idx, x, edge_index, edge_attr=None, **kwargs):\n",
    "        self.model.eval()\n",
    "        self.__clear_masks__()\n",
    "\n",
    "        num_edges = edge_index.size(1)\n",
    "        # 提取子图 (包含边特征处理)\n",
    "        x, edge_index, mapping, hard_edge_mask, subset, kwargs = \\\n",
    "            self.__subgraph__(node_idx, x, edge_index, **kwargs)\n",
    "        \n",
    "        # 处理边特征\n",
    "        if edge_attr is not None:\n",
    "            edge_attr_sub = edge_attr[hard_edge_mask]\n",
    "        else:\n",
    "            edge_attr_sub = None\n",
    "\n",
    "        with torch.no_grad():\n",
    "            out = self.model(x=x, edge_index=edge_index, edge_attr=edge_attr_sub, **kwargs)\n",
    "            if self.return_type == 'regression':\n",
    "                prediction = out\n",
    "            else:\n",
    "                log_logits = self.__to_log_prob__(out)\n",
    "                pred_label = log_logits.argmax(dim=-1)\n",
    "\n",
    "        self.__set_masks__(x, edge_index, edge_attr_sub)\n",
    "        self.to(x.device)\n",
    "        \n",
    "        parameters = [self.node_feat_mask, self.edge_mask]\n",
    "        if self.edge_feat_mask is not None:\n",
    "            parameters.append(self.edge_feat_mask)\n",
    "        optimizer = torch.optim.Adam(parameters, lr=self.lr)\n",
    "\n",
    "        if self.log:\n",
    "            pbar = tqdm(total=self.epochs)\n",
    "            pbar.set_description(f'Explain node {node_idx}')\n",
    "\n",
    "        for epoch in range(1, self.epochs + 1):\n",
    "            optimizer.zero_grad()\n",
    "            h = x * self.node_feat_mask.sigmoid()\n",
    "            h_edge = edge_attr_sub * self.edge_feat_mask.sigmoid() if edge_attr_sub is not None else None\n",
    "            \n",
    "            out = self.model(x=h, edge_index=edge_index, edge_attr=h_edge, **kwargs)\n",
    "            \n",
    "            if self.return_type == 'regression':\n",
    "                loss = self.__loss__(mapping, out, prediction)\n",
    "            else:\n",
    "                log_logits = self.__to_log_prob__(out)\n",
    "                loss = self.__loss__(mapping, log_logits, pred_label)\n",
    "                \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            if self.log:\n",
    "                pbar.update(1)\n",
    "        if self.log:\n",
    "            pbar.close()\n",
    "\n",
    "        # 处理节点特征掩码\n",
    "        node_feat_mask = self.node_feat_mask.detach().sigmoid()\n",
    "        if self.feat_mask_type != 'feature':\n",
    "            new_mask = x.new_zeros(x.size(0), node_feat_mask.size(1))\n",
    "            new_mask[subset] = node_feat_mask\n",
    "            node_feat_mask = new_mask\n",
    "        node_feat_mask = node_feat_mask.squeeze()\n",
    "\n",
    "        # 处理边掩码\n",
    "        full_edge_mask = self.edge_mask.new_zeros(num_edges)\n",
    "        full_edge_mask[hard_edge_mask] = self.edge_mask.detach().sigmoid()\n",
    "\n",
    "        # 处理边特征掩码\n",
    "        if self.edge_feat_mask is not None:\n",
    "            edge_feat_mask = self.edge_feat_mask.new_zeros(num_edges, edge_attr.size(1))\n",
    "            edge_feat_mask[hard_edge_mask] = self.edge_feat_mask.detach().sigmoid()\n",
    "        else:\n",
    "            edge_feat_mask = None\n",
    "\n",
    "        self.__clear_masks__()\n",
    "        return node_feat_mask, full_edge_mask, edge_feat_mask\n",
    "    \n",
    "\n",
    "    def visualize_subgraph(self, node_idx, edge_index, edge_mask, y=None,\n",
    "                          threshold=None, edge_y=None, node_alpha=None,\n",
    "                          seed=10, save_path=None, **kwargs):\n",
    "        r\"\"\"Visualizes the subgraph with low-saturation blue nodes and PDF saving.\n",
    "        \n",
    "        Args:\n",
    "            save_path (str, optional): Path to save the figure as PDF. If None, won't save.\n",
    "            Other args same as original.\n",
    "        \"\"\"\n",
    "        import networkx as nx\n",
    "        import matplotlib.pyplot as plt\n",
    "        from matplotlib.colors import LinearSegmentedColormap\n",
    "\n",
    "        assert edge_mask.size(0) == edge_index.size(1)\n",
    "\n",
    "        # Create figure with white background\n",
    "        plt.figure(facecolor='white',figsize=(15/2.54, 12/2.54))\n",
    "        \n",
    "        if node_idx == -1:\n",
    "            hard_edge_mask = torch.BoolTensor([True] * edge_index.size(1),\n",
    "                                              device=edge_mask.device)\n",
    "            subset = torch.arange(edge_index.max().item() + 1,\n",
    "                                  device=edge_index.device)\n",
    "            y = None\n",
    "        else:\n",
    "            subset, edge_index, _, hard_edge_mask = k_hop_subgraph(\n",
    "                node_idx, self.num_hops, edge_index, relabel_nodes=True,\n",
    "                num_nodes=None, flow=self.__flow__())\n",
    "\n",
    "        edge_mask = edge_mask[hard_edge_mask]\n",
    "\n",
    "        if threshold is not None:\n",
    "            edge_mask = (edge_mask >= threshold).to(torch.float)\n",
    "\n",
    "        # Node coloring with low-saturation blue\n",
    "        if y is None:\n",
    "            y = torch.zeros(edge_index.max().item() + 1,\n",
    "                            device=edge_index.device)\n",
    "        else:\n",
    "            y = y[subset].to(torch.float)\n",
    "            if y.max().item() > 0:  # Normalize if not all zeros\n",
    "                y = y / y.max().item()\n",
    "        \n",
    "        # Create custom low-saturation blue colormap\n",
    "        blue_cmap = LinearSegmentedColormap.from_list(\n",
    "            'low_sat_blue', ['#e6f2ff', '#0066cc'])  # Light to medium blue\n",
    "\n",
    "        if edge_y is None:\n",
    "            edge_color = ['#5c5c5c'] * edge_index.size(1)  # Gray edges\n",
    "        else:\n",
    "            colors = list(plt.rcParams['axes.prop_cycle'])\n",
    "            edge_color = [\n",
    "                colors[i % len(colors)]['color']\n",
    "                for i in edge_y[hard_edge_mask]\n",
    "            ]\n",
    "\n",
    "        data = Data(edge_index=edge_index, att=edge_mask,\n",
    "                    edge_color=edge_color, y=y, num_nodes=y.size(0)).to('cpu')\n",
    "        G = to_networkx(data, node_attrs=['y'],\n",
    "                        edge_attrs=['att', 'edge_color'])\n",
    "        mapping = {k: i for k, i in enumerate(subset.tolist())}\n",
    "        G = nx.relabel_nodes(G, mapping)\n",
    "\n",
    "        node_args = set(signature(nx.draw_networkx_nodes).parameters.keys())\n",
    "        node_kwargs = {k: v for k, v in kwargs.items() if k in node_args}\n",
    "        node_kwargs.update({\n",
    "            'node_size': kwargs.get('node_size', 800),\n",
    "            'cmap': blue_cmap,\n",
    "            'vmin': 0,\n",
    "            'vmax': 1,\n",
    "            'edgecolors': '#333333',\n",
    "            'linewidths': 1.0\n",
    "        })\n",
    "\n",
    "        label_args = set(signature(nx.draw_networkx_labels).parameters.keys())\n",
    "        label_kwargs = {k: v for k, v in kwargs.items() if k in label_args}\n",
    "        label_kwargs.update({\n",
    "            'font_size': kwargs.get('font_size', 10),\n",
    "            'font_color': 'black'\n",
    "        })\n",
    "\n",
    "        pos = nx.spring_layout(G, seed=seed)\n",
    "        ax = plt.gca()\n",
    "        \n",
    "        # Draw edges with adjusted styling\n",
    "        for source, target, data in G.edges(data=True):\n",
    "            ax.annotate(\n",
    "                '', xy=pos[target], xycoords='data', xytext=pos[source],\n",
    "                textcoords='data', arrowprops=dict(\n",
    "                    arrowstyle=\"->\",\n",
    "                    alpha=max(data['att'], 0.2),  # Increased minimum alpha\n",
    "                    color=data['edge_color'],\n",
    "                    shrinkA=sqrt(node_kwargs['node_size']) / 2.0,\n",
    "                    shrinkB=sqrt(node_kwargs['node_size']) / 2.0,\n",
    "                    connectionstyle=\"arc3,rad=0.1\",\n",
    "                ))\n",
    "\n",
    "        # Draw nodes with new color scheme\n",
    "        if node_alpha is None:\n",
    "            nx.draw_networkx_nodes(G, pos, node_color=y.tolist(),\n",
    "                                  **node_kwargs)\n",
    "        else:\n",
    "            node_alpha_subset = node_alpha[subset]\n",
    "            assert ((node_alpha_subset >= 0) & (node_alpha_subset <= 1)).all()\n",
    "            nx.draw_networkx_nodes(G, pos, alpha=node_alpha_subset.tolist(),\n",
    "                                  node_color=y.tolist(), **node_kwargs)\n",
    "\n",
    "        nx.draw_networkx_labels(G, pos, **label_kwargs)\n",
    "        \n",
    "        plt.axis('off')\n",
    "        plt.tight_layout(pad=1.0)  # 增加图形内部的padding\n",
    "        # Save to PDF if path is provided\n",
    "        if save_path is not None:\n",
    "            plt.savefig(save_path ,dpi=300)\n",
    "            print(f\"Graph saved to {save_path}\")\n",
    "\n",
    "        return ax, G\n",
    "\n",
    "\n",
    "def k_hop_subgraph(node_idx, num_hops, edge_index, relabel_nodes=False,\n",
    "                   num_nodes=None, flow='source_to_target'):\n",
    "    r\"\"\"Computes the :math:`k`-hop subgraph of :obj:`edge_index` around node\n",
    "    :attr:`node_idx`.\n",
    "    It returns (1) the nodes involved in the subgraph, (2) the filtered\n",
    "    :obj:`edge_index` connectivity, (3) the mapping from node indices in\n",
    "    :obj:`node_idx` to their new location, and (4) the edge mask indicating\n",
    "    which edges were preserved.\n",
    "\n",
    "    Args:\n",
    "        node_idx (int, list, tuple or :obj:`torch.Tensor`): The central\n",
    "            node(s).\n",
    "        num_hops: (int): The number of hops :math:`k`.\n",
    "        edge_index (LongTensor): The edge indices.\n",
    "        relabel_nodes (bool, optional): If set to :obj:`True`, the resulting\n",
    "            :obj:`edge_index` will be relabeled to hold consecutive indices\n",
    "            starting from zero. (default: :obj:`False`)\n",
    "        num_nodes (int, optional): The number of nodes, *i.e.*\n",
    "            :obj:`max_val + 1` of :attr:`edge_index`. (default: :obj:`None`)\n",
    "        flow (string, optional): The flow direction of :math:`k`-hop\n",
    "            aggregation (:obj:`\"source_to_target\"` or\n",
    "            :obj:`\"target_to_source\"`). (default: :obj:`\"source_to_target\"`)\n",
    "\n",
    "    :rtype: (:class:`LongTensor`, :class:`LongTensor`, :class:`LongTensor`,\n",
    "             :class:`BoolTensor`)\n",
    "    \"\"\"\n",
    "\n",
    "    num_nodes = num_nodes if num_nodes is not None else edge_index.max().item() + 1\n",
    "\n",
    "    assert flow in ['source_to_target', 'target_to_source']\n",
    "    if flow == 'target_to_source':\n",
    "        row, col = edge_index\n",
    "    else:\n",
    "        col, row = edge_index\n",
    "\n",
    "    node_mask = row.new_empty(num_nodes, dtype=torch.bool)\n",
    "    edge_mask = row.new_empty(row.size(0), dtype=torch.bool)\n",
    "\n",
    "    if isinstance(node_idx, (int, list, tuple)):\n",
    "        node_idx = torch.tensor([node_idx], device=row.device).flatten()\n",
    "    else:\n",
    "        node_idx = node_idx.to(row.device)\n",
    "\n",
    "    subsets = [node_idx]\n",
    "\n",
    "    for _ in range(num_hops):\n",
    "        node_mask.fill_(False)\n",
    "        node_mask[subsets[-1]] = True\n",
    "        torch.index_select(node_mask, 0, row, out=edge_mask)\n",
    "        subsets.append(col[edge_mask])\n",
    "\n",
    "    subset, inv = torch.cat(subsets).unique(return_inverse=True)\n",
    "    inv = inv[:node_idx.numel()]\n",
    "\n",
    "    node_mask.fill_(False)\n",
    "    node_mask[subset] = True\n",
    "    edge_mask = node_mask[row] & node_mask[col]\n",
    "\n",
    "    edge_index = edge_index[:, edge_mask]\n",
    "\n",
    "    if relabel_nodes:\n",
    "        node_idx = row.new_full((num_nodes, ), -1)\n",
    "        node_idx[subset] = torch.arange(subset.size(0), device=row.device)\n",
    "        edge_index = node_idx[edge_index]\n",
    "\n",
    "    return subset, edge_index, inv, edge_mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad5183f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建新模型\n",
    "state_dict = torch.load('grid_search/GINE_h256_n1/epoch_600.pt')['model_state_dict']\n",
    "model = GNNPredictor(hidden_dim=256,num_layers=4,num_nodes=1,env_num=0)\n",
    "# 过滤参数\n",
    "# 将参数赋值给新模型\n",
    "model.load_state_dict(state_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f78ba2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model = model.to('cpu')\n",
    "data = test_graph_IR_dataset[208].to('cpu')\n",
    "# data = test_graph_IR_dataset[1].to('cpu')\n",
    "display(Chem.MolFromSmiles(data.smiles))\n",
    "# model = model.to(device)\n",
    "# data = graph_IR_dataset[0].to(device)\n",
    "# data = test_graph_IR_dataset[0].to(device)\n",
    "explainer = GNNExplainer(model, epochs=200, return_type='regression',feat_mask_type = 'feature', allow_edge_mask=True, log=False,num_hops=3)\n",
    "# 'feature', 'individual_feature', 'scalar'\n",
    "node_feat_mask, edge_mask, edge_feat_mask = explainer.explain_graph(data.x, data.edge_index, edge_attr=data.edge_attr,data=data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08cb9a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_feat_mask, edge_mask, edge_feat_mask   # [0.2271, 0.3311, 0.1334, 0.2512, 0.5029, 0.5175, 0.2904, 0.2586, 0.1412,0.6207, 0.7926, 0.2727, 0.3876, 0.3404, 0.2489, 0.1364]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3904f6d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_feat_mask, edge_mask, edge_feat_mask = explainer.explain_node(11,data.x, data.edge_index, edge_attr=data.edge_attr,data=data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eccd1e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit import Chem\n",
    "from rdkit.Chem import Draw\n",
    "ax,G = explainer.visualize_subgraph(9, data.edge_index,edge_mask,threshold=0.1, save_path = r'D:\\Jupyter\\IR-DIAZO-KETONE-main\\asds.pdf') # threshold=0.1\n",
    "mol = Chem.MolFromSmiles(data.smiles)\n",
    "# mol = Chem.AddHs(mol)\n",
    "for atom in mol.GetAtoms():\n",
    "    atom.SetAtomMapNum(atom.GetIdx())\n",
    "\n",
    "display(mol)\n",
    "Draw.MolToFile(mol, r'D:\\Jupyter\\IR-DIAZO-KETONE-main\\molecule2.svg')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa75b769",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# 原始数据\n",
    "importance_scores = node_feat_mask\n",
    "x_labels = ['Atomic Number', 'Connectivity', 'Implicit Valence', \n",
    "            'In Ring', 'Hybridization', 'Electronegativity', 'Covalent Radius',\n",
    "            'Aromaticity', 'Formal Charge', 'Ring Size',\n",
    "            'Neighbor Electronegativity', 'Neighbor Degree', 'Neighbor Aromaticity',\n",
    "            'Neighbor in Ring', 'Neighbor Double Bond', 'Neighbor Triple Bond']\n",
    "\n",
    "# 将数据和标签组合并按分值降序排序\n",
    "features = list(zip(importance_scores, x_labels))\n",
    "features.sort(reverse=True)  # 按分值从大到小排序\n",
    "top_features = features[:10]  # 取前10个\n",
    "\n",
    "# 分离排序后的分数和标签（反转顺序使最高分在上方）\n",
    "top_scores = [x[0] for x in top_features][::-1]  # 反转顺序\n",
    "top_labels = [x[1] for x in top_features][::-1]  # 反转顺序\n",
    "\n",
    "# 创建图形\n",
    "plt.figure(figsize=(9/2.54, 6/2.54), dpi=300)\n",
    "ax = plt.gca()\n",
    "\n",
    "# 设置颜色（从高到低渐变）\n",
    "colors = plt.cm.viridis(np.linspace(0.2, 0.8, len(top_scores)))\n",
    "\n",
    "# 绘制水平条形图（最高分在最上方）\n",
    "bars = ax.barh(range(len(top_labels)), top_scores, color=colors, height=0.6)\n",
    "\n",
    "# 自定义Y轴刻度\n",
    "ax.set_yticks(range(len(top_labels)))\n",
    "ax.set_yticklabels(top_labels, fontsize=8)\n",
    "\n",
    "# 添加数值标签\n",
    "for i, bar in enumerate(bars):\n",
    "    width = bar.get_width()\n",
    "    ax.text(width + 0.01,  # 数值标签向右偏移\n",
    "            bar.get_y() + bar.get_height()/2,\n",
    "            f'{width:.3f}',\n",
    "            va='center', ha='left',\n",
    "            fontsize=8)\n",
    "\n",
    "# 美化图形\n",
    "plt.xlabel('Importance Score', fontsize=8)\n",
    "plt.title('Top 10 Feature Importance Scores (Highest at Top)', fontsize=8, pad=5)\n",
    "plt.xlim(0, max(top_scores)*1.25)  # 扩展x轴范围留出标签空间\n",
    "# plt.grid(axis='x', linestyle='--', alpha=0.3)  # 添加辅助网格线\n",
    "plt.yticks(fontsize=6)\n",
    "plt.xticks(fontsize=8)\n",
    "plt.tight_layout()\n",
    "plt.savefig('top10_feature_importance_ordered2.pdf', bbox_inches='tight', dpi=300)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "074c5f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# 原始数据\n",
    "importance_scores = edge_feat_mask.squeeze()\n",
    "x_labels = ['Bond type', 'Conjugation status', 'Ring membership', 'Aromaticity', 'Polarity']\n",
    "\n",
    "# 将数据和标签组合并按分值降序排序\n",
    "features = list(zip(importance_scores, x_labels))\n",
    "features.sort(reverse=True)  # 按分值从大到小排序\n",
    "top_features = features[:5]  # 取前10个\n",
    "\n",
    "# 分离排序后的分数和标签（反转顺序使最高分在上方）\n",
    "top_scores = [x[0] for x in top_features][::-1]  # 反转顺序\n",
    "top_labels = [x[1] for x in top_features][::-1]  # 反转顺序\n",
    "\n",
    "# 创建图形\n",
    "plt.figure(figsize=(9/2.54, 6/2.54), dpi=300)\n",
    "ax = plt.gca()\n",
    "\n",
    "# 设置颜色（从高到低渐变）\n",
    "colors = plt.cm.viridis(np.linspace(0.2, 0.8, len(top_scores)))\n",
    "\n",
    "# 绘制水平条形图（最高分在最上方）\n",
    "bars = ax.barh(range(len(top_labels)), top_scores, color=colors, height=0.6)\n",
    "\n",
    "# 自定义Y轴刻度\n",
    "ax.set_yticks(range(len(top_labels)))\n",
    "ax.set_yticklabels(top_labels, fontsize=8)\n",
    "\n",
    "# 添加数值标签\n",
    "for i, bar in enumerate(bars):\n",
    "    width = bar.get_width()\n",
    "    ax.text(width + 0.01,  # 数值标签向右偏移\n",
    "            bar.get_y() + bar.get_height()/2,\n",
    "            f'{width:.3f}',\n",
    "            va='center', ha='left',\n",
    "            fontsize=8)\n",
    "\n",
    "# 美化图形\n",
    "plt.xlabel('Importance Score', fontsize=8)\n",
    "plt.title('Top 10 Feature Importance Scores (Highest at Top)', fontsize=8, pad=5)\n",
    "plt.xlim(0, max(top_scores)*1.25)  # 扩展x轴范围留出标签空间\n",
    "# plt.grid(axis='x', linestyle='--', alpha=0.3)  # 添加辅助网格线\n",
    "plt.yticks(fontsize=6)\n",
    "plt.xticks(fontsize=8)\n",
    "plt.tight_layout()\n",
    "# plt.savefig('top10_feature_importance_ordered2.pdf', bbox_inches='tight', dpi=300)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12ae2ef7",
   "metadata": {},
   "source": [
    "## compare the model with tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cfb009a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 特征工程\n",
    "def carbonyl_process_smiles(smiles_str):\n",
    "    try:\n",
    "        mol = Chem.MolFromSmiles(smiles_str)\n",
    "        mol = Chem.AddHs(mol)\n",
    "\n",
    "        # Find the carbonyl group\n",
    "        carbonyl_atom = None\n",
    "        for atom in mol.GetAtoms():\n",
    "            if atom.GetSymbol() == \"C\":\n",
    "                for neighbor in atom.GetNeighbors():\n",
    "                    if neighbor.GetSymbol() == \"O\" and neighbor.GetTotalNumHs() == 0:\n",
    "                        # Check if the bond between C and O is a double bond\n",
    "                        bond = mol.GetBondBetweenAtoms(atom.GetIdx(), neighbor.GetIdx())\n",
    "                        if bond and bond.GetBondType() == Chem.BondType.DOUBLE:\n",
    "                            carbonyl_atom = neighbor\n",
    "                            break\n",
    "                if carbonyl_atom:\n",
    "                    break\n",
    "\n",
    "        if not carbonyl_atom:\n",
    "            return None, None, None, None\n",
    "\n",
    "        # Find the carbon atom connected to the carbonyl group\n",
    "        carbon_neighbors = [neighbor for neighbor in carbonyl_atom.GetNeighbors() if neighbor.GetSymbol() == \"C\"]\n",
    "        if not carbon_neighbors:\n",
    "            return \"NoCarbonFound\", None, None, None\n",
    "        carbon = carbon_neighbors[0]\n",
    "\n",
    "\n",
    "        # Find other atoms connected to the carbon\n",
    "        connected_atoms = [neighbor for neighbor in carbon.GetNeighbors() if neighbor.GetIdx() != carbonyl_atom.GetIdx()]\n",
    "\n",
    "\n",
    "        # Priority order for connected atoms\n",
    "        priority_order = [\n",
    "            ('Cl', 'SINGLE'), ('S', 'AROMATIC'), ('S', 'SINGLE'), ('F', 'SINGLE'),\n",
    "            ('O', 'AROMATIC'), ('O', 'DOUBLE'), ('O', 'SINGLE'),\n",
    "            ('N', 'TRIPLE'), ('N', 'AROMATIC'), ('N', 'DOUBLE'), ('N', 'SINGLE'),\n",
    "            ('C', 'TRIPLE'), ('C', 'AROMATIC'), ('C', 'DOUBLE'), ('C', 'SINGLE'),\n",
    "            ('H', 'SINGLE')\n",
    "        ]\n",
    "\n",
    "        # Create a list to store atom atomic number and connections\n",
    "        connections_list = []\n",
    "        for atom in connected_atoms:\n",
    "            atomic_num = atom.GetAtomicNum()\n",
    "            connected_atom_symbol = atom.GetSymbol()\n",
    "            neighbors_info = []\n",
    "            for neighbor in atom.GetNeighbors():\n",
    "                if neighbor.GetIdx() != carbon.GetIdx():\n",
    "                    neighbor_symbol = neighbor.GetSymbol()\n",
    "                    bond = mol.GetBondBetweenAtoms(atom.GetIdx(), neighbor.GetIdx())\n",
    "                    bond_type_str = str(bond.GetBondType())\n",
    "                    neighbors_info.append((neighbor_symbol, bond_type_str))\n",
    "\n",
    "            connections_dict = {'atomic_num': atomic_num, 'connections': {connected_atom_symbol: neighbors_info}}\n",
    "            connections_list.append(connections_dict)\n",
    "\n",
    "        # Determine R1 and R2 based on atomic number and connection priority\n",
    "        connections_list.sort(key=lambda x: x['atomic_num'], reverse=True)\n",
    "        if len(connections_list) > 1 and connections_list[0]['atomic_num'] == connections_list[1]['atomic_num']:\n",
    "#             if atomic numbers are the same, sort by connection priority\n",
    "            connections_list.sort(key=lambda x: min(priority_order.index(y) if y in priority_order else len(priority_order)\n",
    "                                                    for y in [item for sublist in x['connections'].values() for item in sublist]))\n",
    "\n",
    "        R1, R2 = connections_list[0], connections_list[1] if len(connections_list) > 1 else None\n",
    "        atomic_number_R1 = R1['atomic_num']\n",
    "        atomic_number_R2 = R2['atomic_num'] if R2 else None\n",
    "\n",
    "        return R1, R2, atomic_number_R1, atomic_number_R2\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return None, None, None, None\n",
    "def calculate_molecular_weight(smiles):\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    if mol is not None:\n",
    "        return Descriptors.MolWt(mol)\n",
    "    else:\n",
    "        return 0\n",
    "def calculate_morgan_fingerprint(smiles, n_bits=2048):\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    fp = AllChem.GetMorganFingerprintAsBitVect(mol, radius=2, nBits=n_bits)\n",
    "    return list(fp)\n",
    "def Feature_Engineering(df_unique):\n",
    "\n",
    "    possible_columns = [\n",
    "        'Cl_SINGLE_R1', 'Cl_SINGLE_R2', 'S_AROMATIC_R1', 'S_AROMATIC_R2', 'S_SINGLE_R1', 'S_SINGLE_R2',\n",
    "         'F_SINGLE_R1',  'F_SINGLE_R2', 'O_AROMATIC_R1', 'O_AROMATIC_R2', 'O_DOUBLE_R1', 'O_DOUBLE_R2', 'O_SINGLE_R1', 'O_SINGLE_R2',\n",
    "        'N_TRIPLE_R2', 'N_TRIPLE_R1', 'N_AROMATIC_R1', 'N_AROMATIC_R2', 'N_DOUBLE_R1', 'N_DOUBLE_R2', 'N_SINGLE_R1', 'N_SINGLE_R2',\n",
    "         'C_TRIPLE_R1', 'C_TRIPLE_R2', 'C_AROMATIC_R2', 'C_AROMATIC_R1',  'C_DOUBLE_R1',  'C_DOUBLE_R2',  'C_SINGLE_R1', 'C_SINGLE_R2',\n",
    "          'H_SINGLE_R1', 'H_SINGLE_R2','P_SINGLE_R1','P_SINGLE_R2','Br_SINGLE_R1','Br_SINGLE_R2','I_SINGLE_R1','I_SINGLE_R2','P_SINGLE_R1','P_SINGLE_R2'\n",
    "        ,'P_DOUBLE_R1','P_DOUBLE_R2','Si_SINGLE_R1','Si_SINGLE_R2'\n",
    "    ]\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for index, row in df_unique.iterrows():\n",
    "        smiles_str = row['SMILES']\n",
    "        R1, R2, atomic_number_R1, atomic_number_R2 = carbonyl_process_smiles(smiles_str)#here to process target FG\n",
    "        # 初始化计数字典\n",
    "#         counts = {'R1' : R1, 'R2' : R2, 'atomic_number_R1': atomic_number_R1, 'atomic_number_R2': atomic_number_R2, 'SMILES': smiles_str, 'IR_Characteristic_Peak': row['IR_Characteristic_Peak']}\n",
    "#         counts = {'R1' : R1, 'R2' : R2, 'atomic_number_R1': atomic_number_R1, 'atomic_number_R2': atomic_number_R2, 'SMILES': smiles_str, 'IR_Characteristic_Peak': row['IR_Characteristic_Peak'], 'DOI' : row['DOI'], 'IUPAC_NAME': row['IUPAC_NAME']}\n",
    "        counts = {'R1' : R1, 'R2' : R2, 'atomic_number_R1': atomic_number_R1, 'atomic_number_R2': atomic_number_R2, 'SMILES': smiles_str, 'IR_Characteristic_Peak': row['IR_Characteristic_Peak'],'DOI' : row['DOI']}\n",
    "    \n",
    "        #         counts['mol_weight'] = calculate_molecular_weight(smiles_str)\n",
    "        counts.update({col: 0 for col in possible_columns})\n",
    "\n",
    "        if R1 == \"NoCarbonFound\":\n",
    "            continue\n",
    "\n",
    "        fingerprint = calculate_morgan_fingerprint(smiles_str)\n",
    "        for i, bit in enumerate(fingerprint):\n",
    "            counts[f'Fingerprint_{i}'] = bit\n",
    "\n",
    "        for suffix, connections in [('R1', R1), ('R2', R2)]:\n",
    "            if connections:\n",
    "                for connection in connections['connections'].values():\n",
    "                    for bond in connection:\n",
    "                        bond_type_str = f'{bond[0]}_{bond[1]}'\n",
    "                        counts[f'{bond_type_str}_{suffix}'] = counts.get(f'{bond_type_str}_{suffix}', 0) + 1\n",
    "\n",
    "        results.append(counts)\n",
    "\n",
    "\n",
    "    results_df = pd.DataFrame(results)\n",
    "    results_df_filled = results_df.fillna(0)\n",
    "    \n",
    "    electronegativity_dict = {\n",
    "    1: 2.20, 5: 2.04, 6: 2.55, 7: 3.04, 8: 3.44, 9: 3.98, 14: 1.90, 15: 2.19, 16: 2.58, 17: 3.16 , 19: 0.82,26: 1.83,32:2.01,34:2.55, 35: 2.96,50: 1.96,52:2.1, 53: 2.66\n",
    "    }\n",
    "\n",
    "# Define the covalent radius dictionary\n",
    "    covalent_radius_dict = {\n",
    "    1: 37, 5: 82, 6: 77, 7: 75, 8: 73, 9: 71, 14: 111, 15: 106, 16: 102, 17: 99 , 19: 227,26:126 ,32:122 , 34:198 , 35: 114 ,50:140,52:140, 53: 133\n",
    "    }\n",
    "    \n",
    "    # Add electronegativity and covalent radius columns\n",
    "    results_df_filled['electronegativity_R1'] = results_df_filled['atomic_number_R1'].map(electronegativity_dict)\n",
    "    results_df_filled['electronegativity_R2'] = results_df_filled['atomic_number_R2'].map(electronegativity_dict)\n",
    "    results_df_filled['covalent_radius_R1'] = results_df_filled['atomic_number_R1'].map(covalent_radius_dict)\n",
    "    results_df_filled['covalent_radius_R2'] = results_df_filled['atomic_number_R2'].map(covalent_radius_dict)\n",
    "\n",
    "    # Replace NaN values if necessary (optional)\n",
    "    results_df_filled['electronegativity_R1'].fillna(0, inplace=True)\n",
    "    results_df_filled['electronegativity_R2'].fillna(0, inplace=True)\n",
    "    results_df_filled['covalent_radius_R1'].fillna(0, inplace=True)\n",
    "    results_df_filled['covalent_radius_R2'].fillna(0, inplace=True)\n",
    "\n",
    "    print(\"FE Processing complete.\")\n",
    "    return results_df_filled\n",
    "\n",
    "def train_evaluate_model(model, X_train, y_train, X_test, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Predict on training and test sets\n",
    "    y_train_pred = model.predict(X_train).ravel()\n",
    "    y_test_pred = model.predict(X_test).ravel()\n",
    "\n",
    "    # Compute performance metrics\n",
    "    rmse_train = mean_squared_error(y_train, y_train_pred, squared=False)\n",
    "    r2_train = r2_score(y_train, y_train_pred)\n",
    "    rmse_test = mean_squared_error(y_test, y_test_pred, squared=False)\n",
    "    r2_test = r2_score(y_test, y_test_pred)\n",
    "\n",
    "    return model, y_train_pred, rmse_train, r2_train, y_test_pred, rmse_test, r2_test\n",
    "\n",
    "def evaluate_model(y_true, y_pred):\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    return rmse, mae, r2\n",
    "def calculate_similarity(train_smiles, test_smiles):\n",
    "    \"\"\"计算训练集和测试集之间的Tanimoto相似度\"\"\"\n",
    "    train_fps = [AllChem.GetMorganFingerprint(Chem.MolFromSmiles(smile), 2) for smile in train_smiles]\n",
    "    test_fps = [AllChem.GetMorganFingerprint(Chem.MolFromSmiles(smile), 2) for smile in test_smiles]\n",
    "\n",
    "    similarity_scores = []\n",
    "    for test_fp in test_fps:\n",
    "        max_similarity = max(AllChem.DataStructs.TanimotoSimilarity(test_fp, train_fp) for train_fp in train_fps)\n",
    "        similarity_scores.append(max_similarity)\n",
    "    return similarity_scores\n",
    "\n",
    "def add_noise(data, noise_level):\n",
    "    noise = np.random.normal(0, noise_level * np.std(data), data.shape)\n",
    "    return data + noise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e37faa4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch_geometric.data import DataLoader\n",
    "model=model.cuda()\n",
    "def compare_models(model, model_dir, scaler, dataset, mean, std):\n",
    "    # 获取所有以8072_experiment2开头的模型文件\n",
    "    model_files = glob.glob(os.path.join(model_dir, '8072_experiment2_*.joblib'))\n",
    "    \n",
    "    # 初始化DataFrame\n",
    "    df_unique = pd.DataFrame({\n",
    "        'DOI': [getattr(d, 'doi', None) for d in dataset],\n",
    "        'SMILES': [getattr(d, 'smiles', None) for d in dataset],\n",
    "        'IR_Characteristic_Peak': [getattr(d, 'y', None) for d in dataset],\n",
    "        'Carbonyl_Atom_Feature_11': [\n",
    "            d.x[d.carbonyl_mask == 0.6][0][9].item() if hasattr(d, 'carbonyl_mask') and hasattr(d, 'x') and d.carbonyl_mask is not None and d.x is not None else None \n",
    "            for d in dataset\n",
    "        ]\n",
    "    })\n",
    "    df = Feature_Engineering(df_unique)\n",
    "\n",
    "    feature = ['electronegativity_R1', 'electronegativity_R2', 'covalent_radius_R1', 'covalent_radius_R2',\n",
    "              'Cl_SINGLE_R1', 'Cl_SINGLE_R2', 'S_AROMATIC_R1', 'S_AROMATIC_R2', 'S_SINGLE_R1', 'S_SINGLE_R2',\n",
    "            'F_SINGLE_R1',  'F_SINGLE_R2', 'O_AROMATIC_R1', 'O_AROMATIC_R2', 'O_DOUBLE_R1', 'O_DOUBLE_R2', 'O_SINGLE_R1', 'O_SINGLE_R2',\n",
    "            'N_TRIPLE_R2', 'N_TRIPLE_R1', 'N_AROMATIC_R1', 'N_AROMATIC_R2', 'N_DOUBLE_R1', 'N_DOUBLE_R2', 'N_SINGLE_R1', 'N_SINGLE_R2',\n",
    "            'C_TRIPLE_R1', 'C_TRIPLE_R2', 'C_AROMATIC_R2', 'C_AROMATIC_R1',  'C_DOUBLE_R1',  'C_DOUBLE_R2',  'C_SINGLE_R1', 'C_SINGLE_R2',\n",
    "              'H_SINGLE_R1', 'H_SINGLE_R2','Br_SINGLE_R1','Br_SINGLE_R2','I_SINGLE_R1','I_SINGLE_R2','P_SINGLE_R1','P_SINGLE_R2'\n",
    "            ,'P_DOUBLE_R1','P_DOUBLE_R2','Si_SINGLE_R1','Si_SINGLE_R2'\n",
    "              ]\n",
    "    Morgan_features = [f'Fingerprint_{i}' for i in range(2048)]\n",
    "    all_features = feature + Morgan_features\n",
    "    X = df[all_features].values\n",
    "    \n",
    "    # 缩放特征\n",
    "    X_all_scaled = scaler.transform(X)\n",
    "    \n",
    "    # GNN模型预测\n",
    "    model.eval()\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    datasee_loader = DataLoader(dataset, batch_size=128, shuffle=False, num_workers=1)\n",
    "    with torch.no_grad():\n",
    "        for _, batch in enumerate(datasee_loader):\n",
    "            batch_atom_bond = batch\n",
    "            batch_atom_bond = batch_atom_bond.to(device)\n",
    "            pred = model(batch_atom_bond.x, batch_atom_bond.edge_index, batch_atom_bond.edge_attr, batch_atom_bond)\n",
    "            y_true.append(batch_atom_bond.y.detach().cpu().reshape(-1))\n",
    "            y_pred.append(pred[:].detach().cpu())\n",
    "    y_true = torch.cat(y_true, dim=0) * std + mean\n",
    "    y_pred = torch.cat(y_pred, dim=0) * std + mean\n",
    "\n",
    "    df_unique['IR_Characteristic_Peak']= y_true.numpy()\n",
    "    df_unique['GNN_pred'] = y_pred.numpy()\n",
    "    df_unique['GNN_difference'] = np.abs(df_unique['IR_Characteristic_Peak'] - y_pred.numpy())\n",
    "\n",
    "    # 加载并运行所有树模型\n",
    "    for model_file in model_files:\n",
    "        # 加载模型\n",
    "        tree_model = joblib.load(model_file)\n",
    "        \n",
    "        # 获取模型名称（不带路径和扩展名）\n",
    "        model_name = os.path.splitext(os.path.basename(model_file))[0].split('8072_experiment2_')[-1]\n",
    "        \n",
    "        # 预测\n",
    "        y_pred = tree_model.predict(X_all_scaled)\n",
    "        \n",
    "        # 添加到DataFrame\n",
    "        df_unique[f'{model_name}_pred'] = y_pred\n",
    "        df_unique[f'{model_name}_difference'] = np.abs(df_unique['IR_Characteristic_Peak'] - y_pred)\n",
    "    \n",
    "    # 计算所有模型与GNN的差异\n",
    "    for model_file in model_files:\n",
    "        model_name = os.path.splitext(os.path.basename(model_file))[0].split('8072_experiment2_')[-1]\n",
    "        df_unique[f'{model_name}_vs_GNN'] = df_unique[f'{model_name}_difference'] - df_unique['GNN_difference']\n",
    "    \n",
    "    # 保存结果\n",
    "    data1 = df_unique.copy()\n",
    "    data1.to_csv(f'test_data_compare_test_{total_num}.csv', index=False)\n",
    "\n",
    "model_dir = './models/'\n",
    "scaler = joblib.load('./scaler/8072_experiment2_scaler.joblib')\n",
    "compare_models(model, model_dir, scaler, test_graph_IR_dataset,graph_IR_dataset.mean ,graph_IR_dataset.std)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c560eb8f",
   "metadata": {},
   "source": [
    "## with tree model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e0d08b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from .modules import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0986ffa2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = Feature_Engineering(df_unique,graph_IR_dataset, model)\n",
    "# df.to_csv('output3.csv')\n",
    "failed_rows=[]\n",
    "for index, row in df.iterrows():\n",
    "    if row['R1']==0 or row['IR_Characteristic_Peak'] == 0:\n",
    "        # 如果第一列的元素为0，记录下该行的索引\n",
    "        failed_rows.append(index)\n",
    "df.iloc[failed_rows].to_excel('D:\\\\1 ir amide\\\\failed_rows.xlsx', index=False)\n",
    "df = df[~df.index.isin(failed_rows)]\n",
    "# 重置索引\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "print(len(df))\n",
    "df.to_csv('all_feature.csv')\n",
    "# df = df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "y = df['IR_Characteristic_Peak'].values\n",
    "\n",
    "feature = ['electronegativity_R1', 'electronegativity_R2', 'covalent_radius_R1', 'covalent_radius_R2',\n",
    "           'Cl_SINGLE_R1', 'Cl_SINGLE_R2', 'S_AROMATIC_R1', 'S_AROMATIC_R2', 'S_SINGLE_R1', 'S_SINGLE_R2',\n",
    "         'F_SINGLE_R1',  'F_SINGLE_R2', 'O_AROMATIC_R1', 'O_AROMATIC_R2', 'O_DOUBLE_R1', 'O_DOUBLE_R2', 'O_SINGLE_R1', 'O_SINGLE_R2',\n",
    "        'N_TRIPLE_R2', 'N_TRIPLE_R1', 'N_AROMATIC_R1', 'N_AROMATIC_R2', 'N_DOUBLE_R1', 'N_DOUBLE_R2', 'N_SINGLE_R1', 'N_SINGLE_R2',\n",
    "         'C_TRIPLE_R1', 'C_TRIPLE_R2', 'C_AROMATIC_R2', 'C_AROMATIC_R1',  'C_DOUBLE_R1',  'C_DOUBLE_R2',  'C_SINGLE_R1', 'C_SINGLE_R2',\n",
    "          'H_SINGLE_R1', 'H_SINGLE_R2','Br_SINGLE_R1','Br_SINGLE_R2','I_SINGLE_R1','I_SINGLE_R2','P_SINGLE_R1','P_SINGLE_R2'\n",
    "        ,'P_DOUBLE_R1','P_DOUBLE_R2','Si_SINGLE_R1','Si_SINGLE_R2'\n",
    "           ]\n",
    "Morgan_features = [f'Fingerprint_{i}' for i in range(2048)]\n",
    "gin_features = [f'gin_{i}' for i in range(520)]\n",
    "all_features = feature + Morgan_features\n",
    "X = df[all_features].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abaa0df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "gin_features = [f'gin_{i}' for i in range(520)]\n",
    "all_features = feature + gin_features\n",
    "X = df[all_features].values\n",
    "y = df['IR_Characteristic_Peak'].values/1000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff445f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_val, X_test = X , X\n",
    "# y_train_val, y_test = y, y\n",
    "\n",
    "X_train_val, X_test, y_train_val, y_test, indices_train_val, indices_test = train_test_split(\n",
    "    X, y, df.index , test_size=0.25, random_state=42)  # df 要改\n",
    "# import csv\n",
    "# data = np.vstack((X_train_val, X_test))\n",
    "# filename = 'output.csv'\n",
    "# with open(filename, mode='w', newline='') as file:\n",
    "#     writer = csv.writer(file)\n",
    "#     for row in data:\n",
    "#         writer.writerow(row)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_val = scaler.fit_transform(X_train_val)\n",
    "X_test = scaler.transform(X_test)\n",
    "X_all_scaled = scaler.transform(X)\n",
    "\n",
    "data_source = 'experiment'  #'experiment','computed'\n",
    "number=len(df) # df , df_small\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc2b5965",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "base_models = [\n",
    "    ('rf', RandomForestRegressor(random_state=42)),\n",
    "    ('gb', GradientBoostingRegressor(random_state=42)),\n",
    "    ('xgb', XGBRegressor(random_state=42)),\n",
    "    ('lgbm', lgb.LGBMRegressor(random_state=42)),\n",
    "    ('CatBoost', CatBoostRegressor(random_state=42))\n",
    "]\n",
    "\n",
    "# Define stacked regressor\n",
    "stacked_model = StackingRegressor(\n",
    "    estimators=base_models,\n",
    "    final_estimator=BayesianRidge()\n",
    ")\n",
    "\n",
    "models = {\n",
    "    \"Random Forest\": RandomForestRegressor(random_state=42),\n",
    "    \"Gradient Boosting\": GradientBoostingRegressor(random_state=42),\n",
    "    'Bayesian Ridge Regression': BayesianRidge(),\n",
    "    \"XGBoost\": XGBRegressor(random_state=42),\n",
    "    \"LightGBM\": lgb.LGBMRegressor(random_state=42),\n",
    "    \"CatBoost\": CatBoostRegressor(random_state=42),\n",
    "    \"stacked_model\": stacked_model\n",
    "}\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    \n",
    "    print(f'\\nTraining {model_name} with 5-Fold Cross Validation...')\n",
    "    rmse_scores = []\n",
    "    r2_scores = []\n",
    "    for train_index, val_index in kf.split(X_train_val):\n",
    "        X_train, X_val = X_train_val[train_index], X_train_val[val_index]\n",
    "        y_train, y_val = y_train_val[train_index], y_train_val[val_index]\n",
    "\n",
    "        model.fit(X_train, y_train)\n",
    "        y_val_pred = model.predict(X_val)\n",
    "\n",
    "        rmse = mean_squared_error(y_val, y_val_pred, squared=False)\n",
    "        r2 = r2_score(y_val, y_val_pred)\n",
    "\n",
    "        rmse_scores.append(rmse)\n",
    "        r2_scores.append(r2)\n",
    "\n",
    "    print(f'{model_name} - Mean RMSE: {np.mean(rmse_scores)}, Mean R2: {np.mean(r2_scores)}')\n",
    "\n",
    "    model.fit(X_train_val, y_train_val)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    rmse_test = mean_squared_error(y_test, y_test_pred, squared=False)\n",
    "    r2_test = r2_score(y_test, y_test_pred)\n",
    "    print(f'{model_name} - Test RMSE: {rmse_test}, Test R2: {r2_test}')\n",
    "\n",
    "    pic=plot_prediction_scatter(y_test, y_test_pred, f'{number}_{data_source}_{model_name}', figsize=(5, 5), alpha=0.2)\n",
    "    plt.savefig(f'./figures/{number}_{data_source}_{model_name}.png', dpi=600)  # df\n",
    "\n",
    "    print(f'{model_name} Model saving')\n",
    "    dump(model, f'./models/{number}_{data_source}_{model_name}.joblib')\n",
    "    dump(scaler, f'./scaler/{number}_{data_source}_scaler.joblib')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "527c4ebf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b113e9e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
